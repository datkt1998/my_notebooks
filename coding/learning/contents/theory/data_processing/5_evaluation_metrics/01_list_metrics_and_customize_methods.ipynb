{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28599e82-8e33-4434-8b9b-d7435516c4f8",
   "metadata": {},
   "source": [
    "# Define scorer\n",
    "make score metrics for the `scoring` parameter that controls what metric they apply to the estimators evaluated, in **`model_selection.GridSearchCV`** and **`model_selection.cross_val_score`**\n",
    "\n",
    "**1. Methods**\n",
    "|   |   |\n",
    "|---|---|\n",
    "|__metrics.get_scorer__(scoring)| Get a scorer from scorer name in `metrics.get_scorer_names()` |\n",
    "|__metrics.make_scorer__(score_func, *[, ...]) | Make a scorer from a performance metric or loss function in `metrics` class |\n",
    "\n",
    "**2. Scorer names**\n",
    "\n",
    "__Classification__ \n",
    "\n",
    "|Index| Scorer name                         | Function                                   |\n",
    "|---:|:-------------------------------------|:-------------------------------------------|\n",
    "|  0 | accuracy                           | `metrics.accuracy_score`                 |\n",
    "|  1 | balanced_accuracy                  | `metrics.balanced_accuracy_score`        |\n",
    "|  2 | top_k_accuracy                     | `metrics.top_k_accuracy_score`           |\n",
    "|  3 | average_precision                  | `metrics.average_precision_score`        |\n",
    "|  4 | neg_brier_score                    | `metrics.brier_score_loss`               |\n",
    "|  5 | f1                                 | `metrics.f1_score`                       |\n",
    "|  6 | f1_micro                           | `metrics.f1_score`                       |\n",
    "|  7 | f1_macro                           | `metrics.f1_score`                       |\n",
    "|  8 | f1_weighted                        | `metrics.f1_score`                       |\n",
    "|  9 | f1_samples                         | `metrics.f1_score`                       |\n",
    "| 10 | neg_log_loss                       | `metrics.log_loss`                       |\n",
    "| 11 | precision                          | `metrics.precision_score`                |\n",
    "| 12 | recall                             | `metrics.recall_score`                   |\n",
    "| 13 | jaccard                            | `metrics.jaccard_score`                  |\n",
    "| 14 | roc_auc                            | `metrics.roc_auc_score`                  |\n",
    "| 15 | roc_auc_ovr                        | `metrics.roc_auc_score`                  |\n",
    "| 16 | roc_auc_ovo                        | `metrics.roc_auc_score`                  |\n",
    "| 17 | roc_auc_ovr_weighted               | `metrics.roc_auc_score`                  |\n",
    "| 18 | roc_auc_ovo_weighted               | `metrics.roc_auc_score`                  |\n",
    "\n",
    "__Clustering__ \n",
    "\n",
    "|Index| Scorer name                         | Function                                   |\n",
    "|---:|:-------------------------------------|:-------------------------------------------|\n",
    "| 19 | adjusted_mutual_info_score         | `metrics.adjusted_mutual_info_score`     |\n",
    "| 20 | adjusted_rand_score                | `metrics.adjusted_rand_score`            |\n",
    "| 21 | completeness_score                 | `metrics.completeness_score`             |\n",
    "| 22 | fowlkes_mallows_score              | `metrics.fowlkes_mallows_score`          |\n",
    "| 23 | homogeneity_score                  | `metrics.homogeneity_score`              |\n",
    "| 24 | mutual_info_score                  | `metrics.mutual_info_score`              |\n",
    "| 25 | normalized_mutual_info_score       | `metrics.normalized_mutual_info_score`   |\n",
    "| 26 | rand_score                         | `metrics.rand_score`                     |\n",
    "| 27 | v_measure_score                    | `metrics.v_measure_score`                |\n",
    "\n",
    "__Regression__ \n",
    "\n",
    "|Index| Scorer name                         | Function                                   |\n",
    "|---:|:-------------------------------------|:-------------------------------------------|\n",
    "| 28 | explained_variance                 | `metrics.explained_variance_score`       |\n",
    "| 29 | max_error                          | `metrics.max_error`                      |\n",
    "| 30 | neg_mean_absolute_error            | `metrics.mean_absolute_error`            |\n",
    "| 31 | neg_mean_squared_error             | `metrics.mean_squared_error`             |\n",
    "| 32 | neg_root_mean_squared_error        | `metrics.mean_squared_error`             |\n",
    "| 33 | neg_mean_squared_log_error         | `metrics.mean_squared_log_error`         |\n",
    "| 34 | neg_median_absolute_error          | `metrics.median_absolute_error`          |\n",
    "| 35 | r2                                 | `metrics.r2_score`                       |\n",
    "| 36 | neg_mean_poisson_deviance          | `metrics.mean_poisson_deviance`          |\n",
    "| 37 | neg_mean_gamma_deviance            | `metrics.mean_gamma_deviance`            |\n",
    "| 38 | neg_mean_absolute_percentage_error | `metrics.mean_absolute_percentage_error` |\n",
    "| 39 | d2_absolute_error_score            | `metrics.d2_absolute_error_score`        |\n",
    "| 40 | d2_pinball_score                   | `metrics.d2_pinball_score`               |\n",
    "| 41 | d2_tweedie_score                   | `metrics.d2_tweedie_score`               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72ae5ec0-61ab-4ae4-878e-2f4f2c38ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "clf = svm.SVC(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9910d535-bced-4a52-9989-916d7cb3f013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 0.96666667, 0.96666667, 0.93333333, 1.        ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_scorer with score name\n",
    "\n",
    "from sklearn.metrics import get_scorer\n",
    "score = get_scorer('accuracy')\n",
    "cross_val_score(clf, X, y, cv=5, scoring=score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "213079a3-726b-4895-99d0-a54fffc8490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_scorer\n",
    "\n",
    "from sklearn.metrics import make_scorer, fbeta_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "grid = GridSearchCV(LinearSVC(), param_grid={'C': [1, 10]}, cv=5, scoring=ftwo_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afb878bd-6dc2-4cf5-90f6-a19240ce1369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_scorer with define function score\n",
    "\n",
    "def fbeta(y_true, y_pred):\n",
    "    return fbeta_score(y_true, y_pred, beta = np.sqrt(5))\n",
    "\n",
    "fbeta_scorer = make_scorer(fbeta)\n",
    "grid = GridSearchCV(LinearSVC(), param_grid={'C': [1, 10]}, cv=5, scoring=fbeta_scorer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
