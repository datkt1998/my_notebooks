{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagging - POS\n",
    "\n",
    "**Parts of speed tagging** - Gán nhãn loại từ:\n",
    "\n",
    "- *POS Tagging* là quá trình gán nhãn (label) loại từ cho mỗi từ trong một câu, ví dụ như danh từ (N), động từ (V), tính từ (ADJ), trạng từ (ADV), giới từ (PREP), liên từ (CONJ), v.v.\n",
    "- *Mục tiêu*: Từ một chuỗi các từ, dự đoán lớp từ tương ứng sao cho phản ánh đúng ngữ pháp và ngữ nghĩa trong ngôn ngữ đó.\n",
    "\n",
    "**Ý nghĩa**\n",
    "\n",
    "- Xác định loại từ là bước cơ bản và cần thiết trong nhiều ứng dụng NLP phức tạp hơn, ví dụ:\n",
    "    - *Parsing*: Xây dựng cây phân tích cú pháp (syntactic parsing).\n",
    "    - *Dịch máy*: Hỗ trợ xác định cấu trúc ngữ pháp, lựa chọn từ tương ứng chính xác.\n",
    "    - *Trích xuất thông tin*: Hỗ trợ nhận diện và phân loại từ, cụm từ đặc biệt.\n",
    "- POS Tagging giúp máy tính hiểu được chức năng ngữ pháp của từ trong câu, từ đó xử lý ngôn ngữ hiệu quả hơn.\n",
    "\n",
    "**Phương pháp**\n",
    "\n",
    "- *Thống kê cổ điển (HMM, CRF)*: Các mô hình ẩn Markov (HMM) và Mô hình trường ngẫu nhiên có điều kiện (CRF) dựa vào xác suất chuyển tiếp giữa các nhãn và xác suất quan sát từ để dự đoán nhãn POS.\n",
    "- *Học sâu (Deep Learning)*: Các mô hình mạng nơ-ron (RNN, LSTM, BiLSTM, Transformers) kết hợp với embeddings (như Word2Vec, GloVe, hay contextual embeddings như BERT) cũng có thể được huấn luyện để gán nhãn POS một cách chính xác hơn, nhất là với những ngôn ngữ giàu ngữ cảnh như tiếng Việt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\n",
    "    r\"contents\\theory\\aiml_algorithms\\dl_nlp\\data\\94 - bbc-news.csv\"\n",
    ")\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "titles = data[[\"title\"]].copy()\n",
    "\n",
    "# lower case\n",
    "titles[\"preprocessed\"] = titles[\"title\"].str.lower()\n",
    "\n",
    "# stop word removal\n",
    "en_stopwords = stopwords.words(\"english\")\n",
    "titles[\"preprocessed\"] = titles[\"preprocessed\"].apply(\n",
    "    lambda x: \" \".join(\n",
    "        [word for word in x.split() if word not in en_stopwords]\n",
    "    )\n",
    ")\n",
    "\n",
    "# punctation removal\n",
    "titles[\"preprocessed\"] = titles[\"preprocessed\"].apply(\n",
    "    lambda x: re.sub(r\"[^\\w\\s]\", \"\", x)\n",
    ")\n",
    "\n",
    "# word tokenization\n",
    "titles[\"tokens_raw\"] = titles[\"title\"].apply(word_tokenize)\n",
    "titles[\"tokens_preprocessed\"] = titles[\"preprocessed\"].apply(word_tokenize)\n",
    "\n",
    "# lemmatizing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "titles[\"tokens_lemmatized\"] = titles[\"tokens_preprocessed\"].apply(\n",
    "    lambda x: [lemmatizer.lemmatize(word) for word in x]\n",
    ")\n",
    "\n",
    "# create lists for just our tokens\n",
    "tokens_raw_list = sum(\n",
    "    titles[\"tokens_raw\"], []\n",
    ")  # unpack our lists into a single list\n",
    "tokens_clean_list = sum(titles[\"tokens_lemmatized\"], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spacy doc from our raw text - better for pos tagging\n",
    "spacy_doc = nlp(\" \".join(tokens_raw_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can</td>\n",
       "      <td>AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>refuse</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>work</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token pos_tag\n",
       "0     Can     AUX\n",
       "1       I    PRON\n",
       "2  refuse    VERB\n",
       "3      to    PART\n",
       "4    work    VERB"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS Tagging\n",
    "pos = [{\"token\": token.text, \"pos_tag\": token.pos_} for token in spacy_doc]\n",
    "pd.DataFrame(pos).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagging - NER\n",
    "\n",
    "**Named Entity Recognition** – Nhận diện thực thể có tên\n",
    "\n",
    "- *NER* là quá trình tự động phát hiện (dò tìm) và phân loại các thực thể “có tên” trong văn bản, ví dụ như tên người, tên địa điểm, tổ chức, thời gian, sự kiện, v.v.\n",
    "- *Mục tiêu*: Xác định đâu là thực thể đặc biệt trong câu và chúng thuộc loại thực thể nào.\n",
    "```text\n",
    "Ví dụ câu tiếng Việt: “Ông Nguyễn Văn A làm việc tại Công ty Bkav ở Hà Nội.”\n",
    "“Nguyễn Văn A” → Người (Person)\n",
    "“Công ty Bkav” → Tổ chức (Organization)\n",
    "“Hà Nội” → Địa điểm (Location)\n",
    "```\n",
    "\n",
    "**Ý nghĩa** \n",
    "\n",
    "NER là một bước quan trọng trong trích xuất thông tin:\n",
    "\n",
    "- *Tìm kiếm và tổng hợp thông tin*: Cho phép hệ thống hiểu được đối tượng nào đang được đề cập đến (ví dụ, tìm tất cả các tin tức có nhắc đến một người/tổ chức cụ thể).\n",
    "- *Hỏi đáp tự động (Question Answering)*: Giúp xác định câu trả lời chính xác khi câu hỏi hướng đến các thực thể (Ví dụ: “Ai là CEO của Google?”).\n",
    "- *Phân tích ý kiến (Sentiment Analysis)*: Xem ý kiến của người dùng nhắm vào thực thể nào (nhãn hàng, địa điểm, cá nhân).\n",
    "\n",
    "**Phương pháp**\n",
    "\n",
    "- *Rule-based*: Sử dụng luật ngôn ngữ hoặc biểu thức chính quy (regex), kết hợp danh sách các thực thể đã biết. Cách này mang tính đặc thù, thiếu linh hoạt.\n",
    "- *Thống kê/học máy cổ điển*: CRF, MaxEnt (Maximum Entropy), SVM… sử dụng đặc trưng (feature) về từ, ngữ cảnh, chữ hoa/thường, tiền tố/hậu tố, v.v.\n",
    "- *Học sâu (Deep Learning)*:\n",
    "    - Mô hình mạng nơ-ron nhiều tầng (BiLSTM + CRF) hoặc Transformers (BERT, XLM-R, PhoBERT…) huấn luyện đặc trưng tự động, thay vì thủ công.\n",
    "    - Kết quả NER hiện nay cải thiện rất nhiều nhờ áp dụng mô hình Transformer, đặc biệt khi có dữ liệu gắn nhãn đủ lớn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>ner_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liz Truss</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rationing</td>\n",
       "      <td>PRODUCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>superyachts</td>\n",
       "      <td>CARDINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Russian</td>\n",
       "      <td>NORP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token   ner_tag\n",
       "0    Liz Truss    PERSON\n",
       "1           UK       GPE\n",
       "2    Rationing   PRODUCT\n",
       "3  superyachts  CARDINAL\n",
       "4      Russian      NORP"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = [\n",
    "    {\"token\": token.text, \"ner_tag\": token.label_} for token in spacy_doc.ents\n",
    "]\n",
    "df = pd.DataFrame(ner).head()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Can I refuse to work ? '\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Liz Truss\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " the Brief ? ' World reacts to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    UK\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " political turmoil \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Rationing\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " energy is nothing new for off-grid community The hunt for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    superyachts\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of sanctioned \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Russian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " oligarchs Platinum Jubilee : \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    70 years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " of the Queen in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    70 seconds\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Red Bull\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " found guilty of breaking \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Formula 1 's\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " budget cap \n",
       "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    World Triathlon Championship Series\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
       "</mark>\n",
       " : \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Flora Duffy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " beats \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Georgia Taylor-Brown\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " to women 's title \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Terry Hall\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " : Coventry scooter ride-out pays tribute to singer \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Post Office\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Fujitsu\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " to face inquiry over \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Horizon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " scandal 'Pavement parking frightens me ' \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    UK\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " interest rates : How will the rise affect you and how high could it go ? They stayed for the storm - what happens now ? \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Six\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " Nations : Can \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Scotland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " 's best since \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    '99\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(spacy_doc[:150], style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spacy_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "**Mục tiêu**: Nhằm gán nhãn (label) “tích cực”, “tiêu cực” hoặc “trung tính” cho một đoạn văn, câu, hoặc thậm chí ở mức độ chi tiết hơn (từng ý hoặc từ).\n",
    "\n",
    "**Ứng dụng thực tế**:\n",
    "- Phân tích phản hồi (review) sản phẩm, khách sạn, nhà hàng.\n",
    "- Khai thác ý kiến trên mạng xã hội (Twitter, Facebook, v.v.).\n",
    "- Xây dựng hệ thống hỗ trợ chăm sóc khách hàng tự động.\n",
    "- Theo dõi và quản trị danh tiếng thương hiệu.\n",
    "\n",
    "**Các phương pháp phổ biến trong Sentiment Analysis**\n",
    "\n",
    "*1. Phương pháp dựa trên từ điển/ngữ nghĩa (Rule-based / Lexicon-based)*\n",
    "\n",
    "- Từ điển cảm xúc (sentiment lexicon): Là bộ danh sách gồm các từ ngữ chứa hàm ý cảm xúc (từ tích cực như “tuyệt vời”, “đẹp”, “xuất sắc”, từ tiêu cực như “tệ”, “xấu”, “kinh khủng”,...). Mỗi từ thường gắn với một trọng số (score) phản ánh mức độ tích cực hoặc tiêu cực.\n",
    "- Luật và quy tắc (rule): Áp dụng các quy tắc (ví dụ: nếu một câu có nhiều từ ngữ tiêu cực hơn thì khả năng cao câu đó mang nghĩa tiêu cực).\n",
    "\n",
    "Ưu điểm:\n",
    "- Dễ triển khai khi có sẵn từ điển cảm xúc.\n",
    "- Giải thích được kết quả (biết từ nào quyết định cảm xúc).\n",
    "\n",
    "Nhược điểm:\n",
    "- Độ bao phủ (coverage) giới hạn nếu từ điển không đầy đủ.\n",
    "- Khó nắm bắt bối cảnh (context) phức tạp, ví dụ mệnh đề phủ định hay các câu mỉa mai, châm biếm (sarcasm).\n",
    "- Khó bảo trì và mở rộng từ điển theo ngôn ngữ, ngữ cảnh mới.\n",
    "\n",
    "*2. Phương pháp Deep Learning Transformer*\n",
    "\n",
    "- Transformer-based Models (BERT, RoBERTa, GPT, XLM-R, PhoBERT với tiếng Việt, v.v.)\n",
    "- Transformer đã trở thành kiến trúc chuẩn cho nhiều bài toán NLP, bao gồm Sentiment Analysis.\n",
    "- Các mô hình Pre-trained như BERT có khả năng biểu diễn ngôn ngữ tự nhiên rất tốt nhờ quá trình huấn luyện trên dữ liệu cực lớn.\n",
    "- Khi fine-tuning cho bài toán phân tích cảm xúc, mô hình có thể đạt kết quả cao vượt trội.\n",
    "\n",
    "Ưu điểm:\n",
    "- Khả năng nắm bắt ngữ cảnh và mối quan hệ giữa các từ tốt hơn so với phương pháp cổ điển.\n",
    "- Tính khái quát cao, mở rộng được cho các ngôn ngữ, miền dữ liệu khác nhau.\n",
    "\n",
    "Nhược điểm:\n",
    "- Đòi hỏi dữ liệu huấn luyện lớn, tài nguyên phần cứng (GPU/TPU) mạnh.\n",
    "- Khó giải thích kết quả hơn so với phương pháp rule-based hay machine learning truyền thống.\n",
    "\n",
    "**Quy trình triển khai một hệ thống Sentiment Analysis**\n",
    "1. Thu thập dữ liệu: Lấy dữ liệu đánh giá, phản hồi, bình luận, v.v.\n",
    "2. Tiền xử lý & Chuẩn hóa: Làm sạch, tách câu/từ, loại bỏ nhiễu, xử lý ký tự đặc biệt.\n",
    "3. Chọn chiến lược tiếp cận:\n",
    "- Rule-based / Lexicon-based: Cần có bộ từ điển cảm xúc phong phú, các quy tắc xử lý ngôn ngữ phù hợp.\n",
    "- Machine Learning: Cần gán nhãn dữ liệu, trích xuất đặc trưng và huấn luyện.\n",
    "- Deep Learning: Áp dụng mô hình embedding, RNN/CNN/Transformer, fine-tuning.\n",
    "4. Huấn luyện và đánh giá:\n",
    "- Chia dữ liệu thành các bộ train/validation/test.\n",
    "- Đánh giá mô hình qua các chỉ số: Accuracy, Precision, Recall, F1-score.\n",
    "5. Triển khai và giám sát:\n",
    "- Đưa mô hình vào môi trường chạy thật.\n",
    "- Thu thập phản hồi, đánh giá và tiếp tục cải thiện."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T08:06:10.311425Z",
     "start_time": "2025-02-27T08:06:10.300961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = [\n",
    "    {\n",
    "        \"text\": \"Sản phẩm này quá tuyệt vời, rất đáng đồng tiền.\",\n",
    "        \"sentiment\": \"positive\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Thật sự thất vọng, chất lượng kém hơn mong đợi.\",\n",
    "        \"sentiment\": \"negative\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Chưa biết xài sao, mới mua thôi, chắc ổn.\",\n",
    "        \"sentiment\": \"neutral\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Quá chán, mất thời gian, không đáng tiền chút nào.\",\n",
    "        \"sentiment\": \"negative\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Khá tốt, giá hợp lý, nhưng giao hàng hơi chậm.\",\n",
    "        \"sentiment\": \"neutral\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Thiết kế đẹp, màu sắc đúng ý, sẽ mua lại nếu cần.\",\n",
    "        \"sentiment\": \"positive\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Tuy sản phẩm không đẹp,  nhưng hài lòng chất lượng.\",\n",
    "        \"sentiment\": \"positive\",\n",
    "    },\n",
    "]\n",
    "\n",
    "label2id = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "id2label = {v: k for k, v in label2id.items()}\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Pre-trained model"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T06:55:42.344761Z",
     "start_time": "2025-02-27T06:55:31.372229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_path = '5CD-AI/Vietnamese-Sentiment-visobert'\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model_path,\n",
    "    tokenizer=model_path\n",
    ")\n",
    "\n",
    "for item in data:\n",
    "    result = sentiment_pipeline(item[\"text\"])[0]\n",
    "    item[\"predicted_sentiment\"] = result[\"label\"]\n",
    "    item[\"score\"] = result[\"score\"]\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(data)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/958 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39569870d581463a96e867d3cf4b7965"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/390M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "25979e457d34453e96946209f68d8d82"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d59805266db499b8735d7996da8121c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/471k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6cb3804f51654435bda8f7f5ccebab97"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.10M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de934eb589904e7d9b2f25840a5c0ed8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b319d8d2e0443b497540de459e69ddb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                text sentiment  \\\n",
       "0    Sản phẩm này quá tuyệt vời, rất đáng đồng tiền.  positive   \n",
       "1    Thật sự thất vọng, chất lượng kém hơn mong đợi.  negative   \n",
       "2          Chưa biết xài sao, mới mua thôi, chắc ổn.   neutral   \n",
       "3  Quá chán, mất thời gian, không đáng tiền chút ...  negative   \n",
       "4     Khá tốt, giá hợp lý, nhưng giao hàng hơi chậm.   neutral   \n",
       "5  Thiết kế đẹp, màu sắc đúng ý, sẽ mua lại nếu cần.  positive   \n",
       "6  Tuy sản phẩm không đẹp,  nhưng hài lòng chất l...  positive   \n",
       "\n",
       "  predicted_sentiment     score  \n",
       "0                 POS  0.998884  \n",
       "1                 NEG  0.998847  \n",
       "2                 POS  0.659783  \n",
       "3                 NEG  0.999171  \n",
       "4                 POS  0.726378  \n",
       "5                 POS  0.993708  \n",
       "6                 NEU  0.678071  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sản phẩm này quá tuyệt vời, rất đáng đồng tiền.</td>\n",
       "      <td>positive</td>\n",
       "      <td>POS</td>\n",
       "      <td>0.998884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thật sự thất vọng, chất lượng kém hơn mong đợi.</td>\n",
       "      <td>negative</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0.998847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chưa biết xài sao, mới mua thôi, chắc ổn.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>POS</td>\n",
       "      <td>0.659783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quá chán, mất thời gian, không đáng tiền chút ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0.999171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Khá tốt, giá hợp lý, nhưng giao hàng hơi chậm.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>POS</td>\n",
       "      <td>0.726378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thiết kế đẹp, màu sắc đúng ý, sẽ mua lại nếu cần.</td>\n",
       "      <td>positive</td>\n",
       "      <td>POS</td>\n",
       "      <td>0.993708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tuy sản phẩm không đẹp,  nhưng hài lòng chất l...</td>\n",
       "      <td>positive</td>\n",
       "      <td>NEU</td>\n",
       "      <td>0.678071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Custom model"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "train test split"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T08:06:22.595489Z",
     "start_time": "2025-02-27T08:06:15.051948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Chuyển data sang list\n",
    "data_list = list(data)\n",
    "\n",
    "# Bước 1: tách train (khoảng 60%) và tạm_thời (40%)\n",
    "train_data, temp_data = train_test_split(data_list, test_size=0.4, random_state=42, shuffle=True)\n",
    "\n",
    "# Bước 2: từ temp_data tách ra validation (50%) và test (50%)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "print(\"Train size:\", len(train_data))\n",
    "print(\"Val size:\", len(val_data))\n",
    "print(\"Test size:\", len(test_data))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4\n",
      "Val size: 1\n",
      "Test size: 2\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tạo Dataset cho Hugging Face"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T08:06:29.464270Z",
     "start_time": "2025-02-27T08:06:24.574264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, label2id, max_len=64):\n",
    "        \"\"\"\n",
    "        data: list of dict, mỗi dict có {\"text\": str, \"sentiment\": str}\n",
    "        tokenizer: tokenizer từ Hugging Face (AutoTokenizer, v.v.)\n",
    "        label2id: dict ánh xạ từ sentiment (str) -> id (int)\n",
    "        max_len: chiều dài tối đa khi tokenize\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label2id = label2id\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        text = sample[\"text\"]\n",
    "        sentiment = sample[\"sentiment\"]\n",
    "        label_id = self.label2id[sentiment]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # Mặc định, tokenizer trả về:\n",
    "        #   encoding[\"input_ids\"], encoding[\"attention_mask\"], (có thể có token_type_ids)\n",
    "        # Ta squeeze(0) để loại bỏ chiều batch (vì mỗi mẫu chỉ có 1)\n",
    "        input_ids = encoding[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = encoding[\"attention_mask\"].squeeze(0)\n",
    "\n",
    "        # Tạo dict kết quả\n",
    "        item = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": torch.tensor(label_id, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "        return item\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T08:06:46.725183Z",
     "start_time": "2025-02-27T08:06:30.415860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_path = \"5CD-AI/Vietnamese-Sentiment-visobert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "train_dataset = SentimentDataset(train_data, tokenizer, label2id, max_len=64)\n",
    "val_dataset   = SentimentDataset(val_data,   tokenizer, label2id, max_len=64)\n",
    "test_dataset  = SentimentDataset(test_data,  tokenizer, label2id, max_len=64)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Metrics for evaluation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T08:11:40.076916Z",
     "start_time": "2025-02-27T08:11:40.069590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_function(eval_pred):\n",
    "    logits, labels = eval_pred  # logits, labels đều là numpy.ndarray\n",
    "    # Dùng np.argmax thay vì torch.argmax\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Tính metric (VD: accuracy, f1...)\n",
    "    # Ví dụ dùng scikit-learn hoặc huggingface metric\n",
    "    # Ở đây minh hoạ load_metric(\"accuracy\") và load_metric(\"f1\")\n",
    "    # (Bạn có thể thay bằng metric tuỳ ý)\n",
    "\n",
    "    import evaluate\n",
    "\n",
    "    accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "    acc = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc[\"accuracy\"],\n",
    "        \"f1\": f1[\"f1\"]\n",
    "    }\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T08:12:20.487695Z",
     "start_time": "2025-02-27T08:11:43.915723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output/visobert-finetuned\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    logging_dir=\"./output/logs\",\n",
    "    logging_steps=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,  # dùng để validate\n",
    "    processing_class=tokenizer,       # Trainer sẽ tự động batch & pad\n",
    "    compute_metrics=evaluate_function\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/6 00:00 < 00:02, 1.16 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2cbde87e4086408894e15091163762dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>5.580416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>8.432305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>8.990547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\datkt\\Desktop\\Working\\notebooks\\coding\\learning\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:397: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "  warnings.warn(\n",
      "C:\\Users\\datkt\\Desktop\\Working\\notebooks\\coding\\learning\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:397: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "  warnings.warn(\n",
      "C:\\Users\\datkt\\Desktop\\Working\\notebooks\\coding\\learning\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:397: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "  warnings.warn(\n",
      "C:\\Users\\datkt\\Desktop\\Working\\notebooks\\coding\\learning\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:397: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6, training_loss=0.0007009292385191657, metrics={'train_runtime': 35.6154, 'train_samples_per_second': 0.337, 'train_steps_per_second': 0.168, 'total_flos': 394670126592.0, 'train_loss': 0.0007009292385191657, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T08:13:16.573780Z",
     "start_time": "2025-02-27T08:13:13.673492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_metrics = trainer.evaluate(test_dataset)\n",
    "print(\"Test metrics:\", test_metrics)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: {'eval_loss': 3.8895528316497803, 'eval_accuracy': 0.5, 'eval_f1': 0.5, 'eval_runtime': 2.8813, 'eval_samples_per_second': 0.694, 'eval_steps_per_second': 0.347, 'epoch': 3.0}\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T08:13:47.292793Z",
     "start_time": "2025-02-27T08:13:47.217221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_text = \"Hàng giao nhanh, chất lượng vừa ý.\"\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    pred_id = logits.argmax(dim=-1).item()\n",
    "\n",
    "print(\"Text:\", test_text)\n",
    "print(\"Predicted sentiment:\", id2label[pred_id])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Hàng giao nhanh, chất lượng vừa ý.\n",
      "Predicted sentiment: neutral\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
