{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagging - POS\n",
    "\n",
    "**Parts of speed tagging** - Gán nhãn loại từ:\n",
    "\n",
    "- *POS Tagging* là quá trình gán nhãn (label) loại từ cho mỗi từ trong một câu, ví dụ như danh từ (N), động từ (V), tính từ (ADJ), trạng từ (ADV), giới từ (PREP), liên từ (CONJ), v.v.\n",
    "- *Mục tiêu*: Từ một chuỗi các từ, dự đoán lớp từ tương ứng sao cho phản ánh đúng ngữ pháp và ngữ nghĩa trong ngôn ngữ đó.\n",
    "\n",
    "**Ý nghĩa**\n",
    "\n",
    "- Xác định loại từ là bước cơ bản và cần thiết trong nhiều ứng dụng NLP phức tạp hơn, ví dụ:\n",
    "    - *Parsing*: Xây dựng cây phân tích cú pháp (syntactic parsing).\n",
    "    - *Dịch máy*: Hỗ trợ xác định cấu trúc ngữ pháp, lựa chọn từ tương ứng chính xác.\n",
    "    - *Trích xuất thông tin*: Hỗ trợ nhận diện và phân loại từ, cụm từ đặc biệt.\n",
    "- POS Tagging giúp máy tính hiểu được chức năng ngữ pháp của từ trong câu, từ đó xử lý ngôn ngữ hiệu quả hơn.\n",
    "\n",
    "**Phương pháp**\n",
    "\n",
    "- *Thống kê cổ điển (HMM, CRF)*: Các mô hình ẩn Markov (HMM) và Mô hình trường ngẫu nhiên có điều kiện (CRF) dựa vào xác suất chuyển tiếp giữa các nhãn và xác suất quan sát từ để dự đoán nhãn POS.\n",
    "- *Học sâu (Deep Learning)*: Các mô hình mạng nơ-ron (RNN, LSTM, BiLSTM, Transformers) kết hợp với embeddings (như Word2Vec, GloVe, hay contextual embeddings như BERT) cũng có thể được huấn luyện để gán nhãn POS một cách chính xác hơn, nhất là với những ngôn ngữ giàu ngữ cảnh như tiếng Việt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\n",
    "    r\"contents\\theory\\aiml_algorithms\\dl_nlp\\data\\94 - bbc-news.csv\"\n",
    ")\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "titles = data[[\"title\"]].copy()\n",
    "\n",
    "# lower case\n",
    "titles[\"preprocessed\"] = titles[\"title\"].str.lower()\n",
    "\n",
    "# stop word removal\n",
    "en_stopwords = stopwords.words(\"english\")\n",
    "titles[\"preprocessed\"] = titles[\"preprocessed\"].apply(\n",
    "    lambda x: \" \".join(\n",
    "        [word for word in x.split() if word not in en_stopwords]\n",
    "    )\n",
    ")\n",
    "\n",
    "# punctation removal\n",
    "titles[\"preprocessed\"] = titles[\"preprocessed\"].apply(\n",
    "    lambda x: re.sub(r\"[^\\w\\s]\", \"\", x)\n",
    ")\n",
    "\n",
    "# word tokenization\n",
    "titles[\"tokens_raw\"] = titles[\"title\"].apply(word_tokenize)\n",
    "titles[\"tokens_preprocessed\"] = titles[\"preprocessed\"].apply(word_tokenize)\n",
    "\n",
    "# lemmatizing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "titles[\"tokens_lemmatized\"] = titles[\"tokens_preprocessed\"].apply(\n",
    "    lambda x: [lemmatizer.lemmatize(word) for word in x]\n",
    ")\n",
    "\n",
    "# create lists for just our tokens\n",
    "tokens_raw_list = sum(\n",
    "    titles[\"tokens_raw\"], []\n",
    ")  # unpack our lists into a single list\n",
    "tokens_clean_list = sum(titles[\"tokens_lemmatized\"], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spacy doc from our raw text - better for pos tagging\n",
    "spacy_doc = nlp(\" \".join(tokens_raw_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can</td>\n",
       "      <td>AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>refuse</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>work</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token pos_tag\n",
       "0     Can     AUX\n",
       "1       I    PRON\n",
       "2  refuse    VERB\n",
       "3      to    PART\n",
       "4    work    VERB"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS Tagging\n",
    "pos = [{\"token\": token.text, \"pos_tag\": token.pos_} for token in spacy_doc]\n",
    "pd.DataFrame(pos).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagging - NER\n",
    "\n",
    "**Named Entity Recognition** – Nhận diện thực thể có tên\n",
    "\n",
    "- *NER* là quá trình tự động phát hiện (dò tìm) và phân loại các thực thể “có tên” trong văn bản, ví dụ như tên người, tên địa điểm, tổ chức, thời gian, sự kiện, v.v.\n",
    "- *Mục tiêu*: Xác định đâu là thực thể đặc biệt trong câu và chúng thuộc loại thực thể nào.\n",
    "```text\n",
    "Ví dụ câu tiếng Việt: “Ông Nguyễn Văn A làm việc tại Công ty Bkav ở Hà Nội.”\n",
    "“Nguyễn Văn A” → Người (Person)\n",
    "“Công ty Bkav” → Tổ chức (Organization)\n",
    "“Hà Nội” → Địa điểm (Location)\n",
    "```\n",
    "\n",
    "**Ý nghĩa** \n",
    "\n",
    "NER là một bước quan trọng trong trích xuất thông tin:\n",
    "\n",
    "- *Tìm kiếm và tổng hợp thông tin*: Cho phép hệ thống hiểu được đối tượng nào đang được đề cập đến (ví dụ, tìm tất cả các tin tức có nhắc đến một người/tổ chức cụ thể).\n",
    "- *Hỏi đáp tự động (Question Answering)*: Giúp xác định câu trả lời chính xác khi câu hỏi hướng đến các thực thể (Ví dụ: “Ai là CEO của Google?”).\n",
    "- *Phân tích ý kiến (Sentiment Analysis)*: Xem ý kiến của người dùng nhắm vào thực thể nào (nhãn hàng, địa điểm, cá nhân).\n",
    "\n",
    "**Phương pháp**\n",
    "\n",
    "- *Rule-based*: Sử dụng luật ngôn ngữ hoặc biểu thức chính quy (regex), kết hợp danh sách các thực thể đã biết. Cách này mang tính đặc thù, thiếu linh hoạt.\n",
    "- *Thống kê/học máy cổ điển*: CRF, MaxEnt (Maximum Entropy), SVM… sử dụng đặc trưng (feature) về từ, ngữ cảnh, chữ hoa/thường, tiền tố/hậu tố, v.v.\n",
    "- *Học sâu (Deep Learning)*:\n",
    "    - Mô hình mạng nơ-ron nhiều tầng (BiLSTM + CRF) hoặc Transformers (BERT, XLM-R, PhoBERT…) huấn luyện đặc trưng tự động, thay vì thủ công.\n",
    "    - Kết quả NER hiện nay cải thiện rất nhiều nhờ áp dụng mô hình Transformer, đặc biệt khi có dữ liệu gắn nhãn đủ lớn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>ner_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liz Truss</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rationing</td>\n",
       "      <td>PRODUCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>superyachts</td>\n",
       "      <td>CARDINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Russian</td>\n",
       "      <td>NORP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token   ner_tag\n",
       "0    Liz Truss    PERSON\n",
       "1           UK       GPE\n",
       "2    Rationing   PRODUCT\n",
       "3  superyachts  CARDINAL\n",
       "4      Russian      NORP"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = [\n",
    "    {\"token\": token.text, \"ner_tag\": token.label_} for token in spacy_doc.ents\n",
    "]\n",
    "df = pd.DataFrame(ner).head()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Can I refuse to work ? '\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Liz Truss\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " the Brief ? ' World reacts to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    UK\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " political turmoil \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Rationing\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " energy is nothing new for off-grid community The hunt for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    superyachts\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of sanctioned \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Russian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " oligarchs Platinum Jubilee : \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    70 years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " of the Queen in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    70 seconds\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Red Bull\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " found guilty of breaking \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Formula 1 's\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " budget cap \n",
       "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    World Triathlon Championship Series\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
       "</mark>\n",
       " : \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Flora Duffy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " beats \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Georgia Taylor-Brown\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " to women 's title \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Terry Hall\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " : Coventry scooter ride-out pays tribute to singer \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Post Office\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Fujitsu\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " to face inquiry over \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Horizon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " scandal 'Pavement parking frightens me ' \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    UK\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " interest rates : How will the rise affect you and how high could it go ? They stayed for the storm - what happens now ? \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Six\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " Nations : Can \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Scotland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " 's best since \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    '99\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(spacy_doc[:150], style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spacy_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "**Mục tiêu**: Nhằm gán nhãn (label) “tích cực”, “tiêu cực” hoặc “trung tính” cho một đoạn văn, câu, hoặc thậm chí ở mức độ chi tiết hơn (từng ý hoặc từ).\n",
    "\n",
    "**Ứng dụng thực tế**:\n",
    "- Phân tích phản hồi (review) sản phẩm, khách sạn, nhà hàng.\n",
    "- Khai thác ý kiến trên mạng xã hội (Twitter, Facebook, v.v.).\n",
    "- Xây dựng hệ thống hỗ trợ chăm sóc khách hàng tự động.\n",
    "- Theo dõi và quản trị danh tiếng thương hiệu.\n",
    "\n",
    "**Các phương pháp phổ biến trong Sentiment Analysis**\n",
    "\n",
    "*1. Phương pháp dựa trên từ điển/ngữ nghĩa (Rule-based / Lexicon-based)*\n",
    "\n",
    "- Từ điển cảm xúc (sentiment lexicon): Là bộ danh sách gồm các từ ngữ chứa hàm ý cảm xúc (từ tích cực như “tuyệt vời”, “đẹp”, “xuất sắc”, từ tiêu cực như “tệ”, “xấu”, “kinh khủng”,...). Mỗi từ thường gắn với một trọng số (score) phản ánh mức độ tích cực hoặc tiêu cực.\n",
    "- Luật và quy tắc (rule): Áp dụng các quy tắc (ví dụ: nếu một câu có nhiều từ ngữ tiêu cực hơn thì khả năng cao câu đó mang nghĩa tiêu cực).\n",
    "\n",
    "Ưu điểm:\n",
    "- Dễ triển khai khi có sẵn từ điển cảm xúc.\n",
    "- Giải thích được kết quả (biết từ nào quyết định cảm xúc).\n",
    "\n",
    "Nhược điểm:\n",
    "- Độ bao phủ (coverage) giới hạn nếu từ điển không đầy đủ.\n",
    "- Khó nắm bắt bối cảnh (context) phức tạp, ví dụ mệnh đề phủ định hay các câu mỉa mai, châm biếm (sarcasm).\n",
    "- Khó bảo trì và mở rộng từ điển theo ngôn ngữ, ngữ cảnh mới.\n",
    "\n",
    "*2. Phương pháp Deep Learning Transformer*\n",
    "\n",
    "- Transformer-based Models (BERT, RoBERTa, GPT, XLM-R, PhoBERT với tiếng Việt, v.v.)\n",
    "- Transformer đã trở thành kiến trúc chuẩn cho nhiều bài toán NLP, bao gồm Sentiment Analysis.\n",
    "- Các mô hình Pre-trained như BERT có khả năng biểu diễn ngôn ngữ tự nhiên rất tốt nhờ quá trình huấn luyện trên dữ liệu cực lớn.\n",
    "- Khi fine-tuning cho bài toán phân tích cảm xúc, mô hình có thể đạt kết quả cao vượt trội.\n",
    "\n",
    "Ưu điểm:\n",
    "- Khả năng nắm bắt ngữ cảnh và mối quan hệ giữa các từ tốt hơn so với phương pháp cổ điển.\n",
    "- Tính khái quát cao, mở rộng được cho các ngôn ngữ, miền dữ liệu khác nhau.\n",
    "\n",
    "Nhược điểm:\n",
    "- Đòi hỏi dữ liệu huấn luyện lớn, tài nguyên phần cứng (GPU/TPU) mạnh.\n",
    "- Khó giải thích kết quả hơn so với phương pháp rule-based hay machine learning truyền thống.\n",
    "\n",
    "**Quy trình triển khai một hệ thống Sentiment Analysis**\n",
    "1. Thu thập dữ liệu: Lấy dữ liệu đánh giá, phản hồi, bình luận, v.v.\n",
    "2. Tiền xử lý & Chuẩn hóa: Làm sạch, tách câu/từ, loại bỏ nhiễu, xử lý ký tự đặc biệt.\n",
    "3. Chọn chiến lược tiếp cận:\n",
    "- Rule-based / Lexicon-based: Cần có bộ từ điển cảm xúc phong phú, các quy tắc xử lý ngôn ngữ phù hợp.\n",
    "- Machine Learning: Cần gán nhãn dữ liệu, trích xuất đặc trưng và huấn luyện.\n",
    "- Deep Learning: Áp dụng mô hình embedding, RNN/CNN/Transformer, fine-tuning.\n",
    "4. Huấn luyện và đánh giá:\n",
    "- Chia dữ liệu thành các bộ train/validation/test.\n",
    "- Đánh giá mô hình qua các chỉ số: Accuracy, Precision, Recall, F1-score.\n",
    "5. Triển khai và giám sát:\n",
    "- Đưa mô hình vào môi trường chạy thật.\n",
    "- Thu thập phản hồi, đánh giá và tiếp tục cải thiện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T08:06:10.311425Z",
     "start_time": "2025-02-27T08:06:10.300961Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"text\": \"Sản phẩm này quá tuyệt vời, rất đáng đồng tiền.\",\n",
    "        \"sentiment\": \"positive\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Thật sự thất vọng, chất lượng kém hơn mong đợi.\",\n",
    "        \"sentiment\": \"negative\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Chưa biết xài sao, mới mua thôi, chắc ổn.\",\n",
    "        \"sentiment\": \"neutral\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Quá chán, mất thời gian, không đáng tiền chút nào.\",\n",
    "        \"sentiment\": \"negative\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Khá tốt, giá hợp lý, nhưng giao hàng hơi chậm.\",\n",
    "        \"sentiment\": \"neutral\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Thiết kế đẹp, màu sắc đúng ý, sẽ mua lại nếu cần.\",\n",
    "        \"sentiment\": \"positive\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Tuy sản phẩm không đẹp,  nhưng hài lòng chất lượng.\",\n",
    "        \"sentiment\": \"positive\",\n",
    "    },\n",
    "]\n",
    "\n",
    "label2id = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "id2label = {v: k for k, v in label2id.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T06:55:42.344761Z",
     "start_time": "2025-02-27T06:55:31.372229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39569870d581463a96e867d3cf4b7965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/958 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25979e457d34453e96946209f68d8d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/390M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d59805266db499b8735d7996da8121c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb3804f51654435bda8f7f5ccebab97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/471k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de934eb589904e7d9b2f25840a5c0ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b319d8d2e0443b497540de459e69ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sản phẩm này quá tuyệt vời, rất đáng đồng tiền.</td>\n",
       "      <td>positive</td>\n",
       "      <td>POS</td>\n",
       "      <td>0.998884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thật sự thất vọng, chất lượng kém hơn mong đợi.</td>\n",
       "      <td>negative</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0.998847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chưa biết xài sao, mới mua thôi, chắc ổn.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>POS</td>\n",
       "      <td>0.659783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quá chán, mất thời gian, không đáng tiền chút ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0.999171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Khá tốt, giá hợp lý, nhưng giao hàng hơi chậm.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>POS</td>\n",
       "      <td>0.726378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thiết kế đẹp, màu sắc đúng ý, sẽ mua lại nếu cần.</td>\n",
       "      <td>positive</td>\n",
       "      <td>POS</td>\n",
       "      <td>0.993708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tuy sản phẩm không đẹp,  nhưng hài lòng chất l...</td>\n",
       "      <td>positive</td>\n",
       "      <td>NEU</td>\n",
       "      <td>0.678071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  \\\n",
       "0    Sản phẩm này quá tuyệt vời, rất đáng đồng tiền.  positive   \n",
       "1    Thật sự thất vọng, chất lượng kém hơn mong đợi.  negative   \n",
       "2          Chưa biết xài sao, mới mua thôi, chắc ổn.   neutral   \n",
       "3  Quá chán, mất thời gian, không đáng tiền chút ...  negative   \n",
       "4     Khá tốt, giá hợp lý, nhưng giao hàng hơi chậm.   neutral   \n",
       "5  Thiết kế đẹp, màu sắc đúng ý, sẽ mua lại nếu cần.  positive   \n",
       "6  Tuy sản phẩm không đẹp,  nhưng hài lòng chất l...  positive   \n",
       "\n",
       "  predicted_sentiment     score  \n",
       "0                 POS  0.998884  \n",
       "1                 NEG  0.998847  \n",
       "2                 POS  0.659783  \n",
       "3                 NEG  0.999171  \n",
       "4                 POS  0.726378  \n",
       "5                 POS  0.993708  \n",
       "6                 NEU  0.678071  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_path = \"5CD-AI/Vietnamese-Sentiment-visobert\"\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\", model=model_path, tokenizer=model_path\n",
    ")\n",
    "\n",
    "for item in data:\n",
    "    result = sentiment_pipeline(item[\"text\"])[0]\n",
    "    item[\"predicted_sentiment\"] = result[\"label\"]\n",
    "    item[\"score\"] = result[\"score\"]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T08:06:22.595489Z",
     "start_time": "2025-02-27T08:06:15.051948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4\n",
      "Val size: 1\n",
      "Test size: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Chuyển data sang list\n",
    "data_list = list(data)\n",
    "\n",
    "# Bước 1: tách train (khoảng 60%) và tạm_thời (40%)\n",
    "train_data, temp_data = train_test_split(\n",
    "    data_list, test_size=0.4, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Bước 2: từ temp_data tách ra validation (50%) và test (50%)\n",
    "val_data, test_data = train_test_split(\n",
    "    temp_data, test_size=0.5, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(train_data))\n",
    "print(\"Val size:\", len(val_data))\n",
    "print(\"Test size:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tạo Dataset cho Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T08:06:29.464270Z",
     "start_time": "2025-02-27T08:06:24.574264Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, label2id, max_len=64):\n",
    "        \"\"\"\n",
    "        data: list of dict, mỗi dict có {\"text\": str, \"sentiment\": str}\n",
    "        tokenizer: tokenizer từ Hugging Face (AutoTokenizer, v.v.)\n",
    "        label2id: dict ánh xạ từ sentiment (str) -> id (int)\n",
    "        max_len: chiều dài tối đa khi tokenize\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label2id = label2id\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        text = sample[\"text\"]\n",
    "        sentiment = sample[\"sentiment\"]\n",
    "        label_id = self.label2id[sentiment]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # Mặc định, tokenizer trả về:\n",
    "        #   encoding[\"input_ids\"], encoding[\"attention_mask\"], (có thể có token_type_ids)\n",
    "        # Ta squeeze(0) để loại bỏ chiều batch (vì mỗi mẫu chỉ có 1)\n",
    "        input_ids = encoding[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = encoding[\"attention_mask\"].squeeze(0)\n",
    "\n",
    "        # Tạo dict kết quả\n",
    "        item = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": torch.tensor(label_id, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T08:06:46.725183Z",
     "start_time": "2025-02-27T08:06:30.415860Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_path = \"5CD-AI/Vietnamese-Sentiment-visobert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path, num_labels=3, id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "train_dataset = SentimentDataset(train_data, tokenizer, label2id, max_len=64)\n",
    "val_dataset = SentimentDataset(val_data, tokenizer, label2id, max_len=64)\n",
    "test_dataset = SentimentDataset(test_data, tokenizer, label2id, max_len=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T08:11:40.076916Z",
     "start_time": "2025-02-27T08:11:40.069590Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def evaluate_function(eval_pred):\n",
    "    logits, labels = eval_pred  # logits, labels đều là numpy.ndarray\n",
    "    # Dùng np.argmax thay vì torch.argmax\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Tính metric (VD: accuracy, f1...)\n",
    "    # Ví dụ dùng scikit-learn hoặc huggingface metric\n",
    "    # Ở đây minh hoạ load_metric(\"accuracy\") và load_metric(\"f1\")\n",
    "    # (Bạn có thể thay bằng metric tuỳ ý)\n",
    "\n",
    "    import evaluate\n",
    "\n",
    "    accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "    acc = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metric.compute(\n",
    "        predictions=predictions, references=labels, average=\"weighted\"\n",
    "    )\n",
    "\n",
    "    return {\"accuracy\": acc[\"accuracy\"], \"f1\": f1[\"f1\"]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T08:12:20.487695Z",
     "start_time": "2025-02-27T08:11:43.915723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/6 00:00 < 00:02, 1.16 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbde87e4086408894e15091163762dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>5.580416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>8.432305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>8.990547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\datkt\\Desktop\\Working\\notebooks\\coding\\learning\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:397: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "  warnings.warn(\n",
      "C:\\Users\\datkt\\Desktop\\Working\\notebooks\\coding\\learning\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:397: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "  warnings.warn(\n",
      "C:\\Users\\datkt\\Desktop\\Working\\notebooks\\coding\\learning\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:397: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "  warnings.warn(\n",
      "C:\\Users\\datkt\\Desktop\\Working\\notebooks\\coding\\learning\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:397: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6, training_loss=0.0007009292385191657, metrics={'train_runtime': 35.6154, 'train_samples_per_second': 0.337, 'train_steps_per_second': 0.168, 'total_flos': 394670126592.0, 'train_loss': 0.0007009292385191657, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output/visobert-finetuned\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    logging_dir=\"./output/logs\",\n",
    "    logging_steps=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,  # dùng để validate\n",
    "    processing_class=tokenizer,  # Trainer sẽ tự động batch & pad\n",
    "    compute_metrics=evaluate_function,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T08:13:16.573780Z",
     "start_time": "2025-02-27T08:13:13.673492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: {'eval_loss': 3.8895528316497803, 'eval_accuracy': 0.5, 'eval_f1': 0.5, 'eval_runtime': 2.8813, 'eval_samples_per_second': 0.694, 'eval_steps_per_second': 0.347, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "test_metrics = trainer.evaluate(test_dataset)\n",
    "print(\"Test metrics:\", test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T08:13:47.292793Z",
     "start_time": "2025-02-27T08:13:47.217221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Hàng giao nhanh, chất lượng vừa ý.\n",
      "Predicted sentiment: neutral\n"
     ]
    }
   ],
   "source": [
    "test_text = \"Hàng giao nhanh, chất lượng vừa ý.\"\n",
    "inputs = tokenizer(\n",
    "    test_text, return_tensors=\"pt\", truncation=True, padding=True\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    pred_id = logits.argmax(dim=-1).item()\n",
    "\n",
    "print(\"Text:\", test_text)\n",
    "print(\"Predicted sentiment:\", id2label[pred_id])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling\n",
    "\n",
    "**Topic modelling** là một nhánh trong Xử lý Ngôn ngữ Tự nhiên (NLP) nhằm **tìm ra các chủ đề tiềm ẩn (latent topics)** trong một tập văn bản lớn, đại diện cho 1 loại **unsupervised learning** trong NLP\n",
    "\n",
    "**Ý tưởng cốt lõi là**: các văn bản thường có thể được mô tả bằng một số lượng hạn chế các chủ đề chính, và mỗi văn bản phản ánh các chủ đề đó với các trọng số (mức độ) khác nhau. Mục tiêu của topic modelling là tự động “phân loại” những văn bản này vào các chủ đề hoặc xác định được các chủ đề chính trong một tập dữ liệu lớn mà không cần gán nhãn trước.\n",
    "\n",
    "--- \n",
    "\n",
    "\n",
    "**Khi nào nên sử dụng topic modelling?**\n",
    "\n",
    "- *Khám phá dữ liệu (Exploratory Analysis)*: Khi bạn có một lượng văn bản lớn mà chưa biết rõ nội dung chính hay các nhóm chủ đề tiềm ẩn, topic modelling giúp bạn hình dung bức tranh tổng quan.\n",
    "- *Phân nhóm tài liệu*: Khi bạn muốn phân nhóm các văn bản theo chủ đề để tiện cho quá trình quản lý, tìm kiếm, hoặc truy xuất thông tin.\n",
    "    - VOC labeling\n",
    "    - Social Listening   \n",
    "- *Trích xuất từ khóa / insight*: Khi bạn muốn tóm tắt hoặc tìm các “từ khóa” nổi bật trong từng nhóm chủ đề nhằm phục vụ cho việc phân tích hoặc báo cáo.\n",
    "- *Tiền xử lý cho các bài toán khác*: Thông tin về chủ đề có thể được sử dụng làm đặc trưng (features) cho các bài toán máy học khác, ví dụ: phân loại văn bản, khuyến nghị nội dung, hoặc phân tích cảm xúc.\n",
    "\n",
    "---\n",
    "\n",
    "**Các phương pháp phổ biến trong topic modelling**\n",
    "\n",
    "- ***Latent Dirichlet Allocation (LDA):*** \n",
    "\n",
    "    Đây là phương pháp được sử dụng rất rộng rãi. Ý tưởng chính: giả định mỗi tài liệu (document) là tổ hợp của các chủ đề, và mỗi chủ đề là một phân phối xác suất trên các từ vựng. Thông qua quá trình huấn luyện, LDA ước lượng xem mỗi tài liệu chứa những chủ đề nào và mỗi chủ đề chứa những từ nào với trọng số bao nhiêu.\n",
    "- ***Latent Semantic Analysis (LSA) / Latent Semantic Indexing (LSI):*** \n",
    "\n",
    "    Dựa trên kỹ thuật phân rã ma trận (thường là SVD). Mỗi tài liệu được biểu diễn dưới dạng vector “bag-of-words” (hoặc TF-IDF), sau đó giảm chiều để tìm “khoảng không gian ngữ nghĩa” ẩn. LSA/LSI cũng có thể được sử dụng để tìm các chủ đề tiềm ẩn, tuy nhiên thường không ràng buộc các chủ đề và từ theo kiểu phân phối xác suất như LDA.\n",
    "- ***Non-negative Matrix Factorization (NMF):*** \n",
    "\n",
    "    Tương tự ý tưởng phân rã ma trận nhưng thêm ràng buộc “không âm” (non-negative). Vì vậy, các chủ đề NMF thường có diễn giải tương đối rõ ràng hơn (mỗi chủ đề là sự kết hợp cộng tuyến tính của các từ, không cho phép giá trị âm).\n",
    "- ***Neural Topic Modelling (chủ đề dựa trên mạng nơ-ron):*** \n",
    "\n",
    "    Ví dụ: Neural Variational Document Model (NVDM) hay những mô hình deep learning khác. Chúng sử dụng mạng nơ-ron để học phân phối chủ đề ẩn trong tài liệu. Có tiềm năng thể hiện tốt với các dữ liệu lớn, phức tạp.\n",
    "- ***BERT-based Topic Modelling:*** \n",
    "\n",
    "    Áp dụng các mô hình ngôn ngữ dựa trên Transformer như BERT để tạo embedding cho câu/từ. Sau đó, tiến hành clustering hoặc áp dụng các thuật toán phân nhóm khác lên embedding này để suy ra chủ đề.\n",
    "\n",
    "---\n",
    "\n",
    "**Cách xác định số lượng chủ đề (number of topics)**\n",
    "\n",
    "Việc chọn số lượng chủ đề phù hợp rất quan trọng, vì số lượng chủ đề quá ít hoặc quá nhiều đều có thể làm giảm chất lượng phân tích. Một số phương pháp phổ biến để ước lượng “tối ưu”:\n",
    "\n",
    "- ***Dựa trên kinh nghiệm / domain knowledge***\n",
    "\n",
    "    - Nếu bạn đã biết trước lĩnh vực nội dung hoặc mang tính chuyên ngành, bạn có thể ước lượng số lượng chủ đề hợp lý dựa vào kinh nghiệm.\n",
    "- ***Dùng metric đánh giá (Perplexity, Coherence, Silhouette Score, v.v.)***\n",
    "\n",
    "    - **Coherence score** (C_v, UMass, v.v.) phổ biến trong đánh giá LDA. Ý tưởng: tính mức độ liên quan giữa các từ cùng chủ đề, hoặc giữa từ trong chủ đề với các tài liệu.\n",
    "    - **Perplexity** thường được sử dụng cho các mô hình xác suất (vd. LDA), mặc dù nó không phải lúc nào cũng tương quan tốt với chất lượng “giải thích” của chủ đề.\n",
    "    - **Elbow** method áp dụng cho một số kỹ thuật như NMF, spectral clustering, K-means (trong trường hợp clustering embedding).\n",
    "    - **Grid search** (hoặc iterative search) với các mô hình topic modelling\n",
    "\n",
    "- ***Huấn luyện nhiều mô hình với số lượng chủ đề khác nhau (k = 5, 10, 15, 20, …) và quan sát sự thay đổi của các chỉ số đánh giá (coherence, perplexity, …).***\n",
    "    - Chọn k có chỉ số đánh giá tốt nhất hoặc đạt điểm cân bằng giữa giải thích được và tính gọn nhẹ.\n",
    "    - Trong thực tế, kết hợp cả đánh giá định lượng và định tính (xem xét sự “giải thích được” của chủ đề) là cách tối ưu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kết hợp mô hình truyền thống và transformer\n",
    "\n",
    "**1. Vì sao phương pháp truyền thống (LDA, NMF…) vẫn còn giá trị?**\n",
    "\n",
    "- Nhẹ, dễ triển khai: LDA, NMF triển khai tương đối gọn (thư viện Gensim, sklearn, …), không đòi hỏi hạ tầng GPU hay cấu hình quá cao.\n",
    "- Tính giải thích (interpretability) rõ ràng:\n",
    "    - Mỗi chủ đề là một phân phối xác suất của từ; dễ quan sát “top words” và gán nhãn.\n",
    "    - Các tổ chức, doanh nghiệp trong lĩnh vực cần khả năng giải thích (compliance, pháp lý…) có thể ưu tiên LDA/NMF.\n",
    "- Phù hợp dữ liệu vừa và nhỏ: Khi dữ liệu không quá lớn, hoặc chủ đề không quá phức tạp, LDA/NMF vẫn đem lại kết quả chấp nhận được, nhanh và ổn định.\n",
    "- Đánh giá/ so sánh dễ dàng: Có sẵn các chỉ số như perplexity, coherence (C_v, UMass, …) và bộ công cụ phân tích.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Lợi ích và hạn chế của tiếp cận transformer-based**\n",
    "\n",
    "***Lợi ích***\n",
    "\n",
    "- **Hiểu ngữ cảnh tốt hơn**: Các mô hình (BERT, PhoBERT, GPT, …) bắt được mối quan hệ ngữ nghĩa sâu hơn so với bag-of-words truyền thống.\n",
    "- **Hiệu quả với ngôn ngữ phức tạp / nhiều ngôn ngữ**: Đặc biệt khi văn bản dài, từ vựng phong phú, hoặc nhiều biến thể.\n",
    "- **Chất lượng chủ đề thường tốt hơn** (cụm từ, ngữ nghĩa phức tạp) nếu được huấn luyện/ fine-tune phù hợp.\n",
    "\n",
    "***Hạn chế***\n",
    "\n",
    "- **Chi phí tính toán cao**: Cần GPU, tài nguyên lớn hơn so với LDA/NMF.\n",
    "- **Khó giải thích**: Transformer-based embedding đôi khi khó “truy ngược” được vì sao model nhóm văn bản đó vào một cụm; phải trích xuất top words thủ công thông qua các thống kê tần suất kết hợp (chứ không phải xác suất hiển thị rõ như LDA).\n",
    "- **Phụ thuộc mô hình nền**: Chọn sai mô hình embedding, hoặc model chưa fine-tune cho domain → kết quả chưa tối ưu.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Best Practice thực tế hiện nay**\n",
    "\n",
    "- **Chọn phương pháp theo “bài toán” và “tài nguyên”:**\n",
    "\n",
    "    - Nếu dữ liệu nhỏ hoặc vừa phải, yêu cầu giải thích cao, và tài nguyên hạn chế → LDA / NMF vẫn là lựa chọn hiệu quả.\n",
    "    - Nếu dữ liệu lớn, mang tính đa dạng và cần nắm bắt ngữ nghĩa sâu, bạn sẵn sàng đầu tư hạ tầng → hướng transformer-based (BERTopic, Top2Vec, v.v.).\n",
    "\n",
    "- **Kết hợp cả hai:**\n",
    "\n",
    "    - Dùng embedding transformer để rút gọn chiều, sau đó chạy LDA trên vector (thay vì chạy LDA trên bag-of-words). Tuy không phổ biến bằng “transformer + clustering”, nhưng cũng là một hướng.\n",
    "\n",
    "- **Bảo đảm pipeline “chuẩn”:**\n",
    "\n",
    "    - Tiền xử lý: Với tiếng Việt, tách từ (Underthesea, PyVi…); với tiếng Anh, spaCy/NLTK. Lọc stopwords phù hợp.\n",
    "    - Sinh embedding (nếu dùng transformer) hoặc TF-IDF (nếu LDA/NMF).\n",
    "    - Giảm chiều (UMAP/PCA) → Phân cụm (K-means, HDBSCAN…).\n",
    "    - Trích xuất top words để đặt tên chủ đề, đánh giá coherence.\n",
    "    - Kiểm tra thủ công trên các văn bản đại diện.\n",
    "\n",
    "- **Chú trọng đánh giá định tính (qualitative):**\n",
    "\n",
    "    Dù dùng LDA hay BERT, vẫn nên xem xét thủ công một số văn bản trong cụm; vì chỉ số (coherence, silhouette…) cũng có thể chưa phản ánh hết.\n",
    "\n",
    "- **Cân nhắc domain adaptation / fine-tuning (nếu dùng mô hình embedding):**\n",
    "\n",
    "    - Đối với những ngữ cảnh chuyên ngành (y tế, tài chính, …), pretrained “chung” của BERT có thể không tối ưu.\n",
    "    - Có thể fine-tune nhẹ (MLM, TSDAE, …) hoặc chọn mô hình domain-specific (BioBERT, FinBERT, PhoBERT news,…)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuẩn bị và tiền xử lý dữ liệu\n",
    "\n",
    "**1. Dọn dẹp, chuẩn hóa (cleaning, normalization):**\n",
    "\n",
    "- Loại bỏ ký tự đặc biệt, link, HTML tag, …\n",
    "- Xử lý chính tả, chuyển về chữ thường (nếu phù hợp).\n",
    "- Tùy theo ngôn ngữ (tiếng Anh, tiếng Việt, …) sử dụng tokenizer phù hợp. Ví dụ:\n",
    "    - Tiếng Anh: spaCy, NLTK, …\n",
    "    - Tiếng Việt: Underthesea, PyVi, RDRsegmenter… (để tách từ).\n",
    "\n",
    "**2. (Nếu cần) Tách câu hoặc chia nhỏ văn bản lớn:**\n",
    "\n",
    "- Một bài báo quá dài có thể chia thành từng đoạn hoặc từng câu để embedding hiệu quả. Sau đó, có thể nhóm các đoạn/câu đó theo một cơ chế trung bình để đại diện toàn văn bản (hoặc áp dụng tiếp cận topic modelling trực tiếp trên từng đoạn/câu, rồi gộp lại).\n",
    "\n",
    "**3. Loại bỏ stopwords/ từ ít thông tin:**\n",
    "\n",
    "- Tùy ngôn ngữ, cần một danh sách stopwords chất lượng.\n",
    "- Tuy nhiên, với tiếp cận embedding transformer, đôi khi những từ này không tác động tiêu cực nhiều như mô hình bag-of-words, nhưng vẫn nên cân nhắc lọc bớt “noise”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T08:04:28.570057Z",
     "start_time": "2025-02-28T08:04:26.966972Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T08:04:28.970189Z",
     "start_time": "2025-02-28T08:04:28.939561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25626</td>\n",
       "      <td>One Weight-Loss Approach Fits All? No, Not Eve...</td>\n",
       "      <td>Dr. Frank Sacks, a professor of nutrition at H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19551</td>\n",
       "      <td>South Carolina Stuns Baylor to Reach the Round...</td>\n",
       "      <td>South Carolina’s win over   Duke was not only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25221</td>\n",
       "      <td>U.S. Presidential Race, Apple, Gene Wilder: Yo...</td>\n",
       "      <td>(Want to get this briefing by email? Here’s th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18026</td>\n",
       "      <td>His Predecessor Gone, Gambia’s New President F...</td>\n",
       "      <td>BANJUL, Gambia  —   A week after he was inaugu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21063</td>\n",
       "      <td>‘Harry Potter and the Cursed Child’ Goes From ...</td>\n",
       "      <td>The biggest book of the summer isn’t a blockbu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0  25626  One Weight-Loss Approach Fits All? No, Not Eve...   \n",
       "1  19551  South Carolina Stuns Baylor to Reach the Round...   \n",
       "2  25221  U.S. Presidential Race, Apple, Gene Wilder: Yo...   \n",
       "3  18026  His Predecessor Gone, Gambia’s New President F...   \n",
       "4  21063  ‘Harry Potter and the Cursed Child’ Goes From ...   \n",
       "\n",
       "                                             content  \n",
       "0  Dr. Frank Sacks, a professor of nutrition at H...  \n",
       "1  South Carolina’s win over   Duke was not only ...  \n",
       "2  (Want to get this briefing by email? Here’s th...  \n",
       "3  BANJUL, Gambia  —   A week after he was inaugu...  \n",
       "4  The biggest book of the summer isn’t a blockbu...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"data\\105 - news-articles.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T08:05:21.544972Z",
     "start_time": "2025-02-28T08:05:20.820088Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\datkt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\datkt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Gộp title + content nếu muốn (ở đây ví dụ gộp chung để phân tích toàn văn bản)\n",
    "df[\"text\"] = df[\"title\"].astype(str) + \" \" + df[\"content\"].astype(str)\n",
    "\n",
    "# Tải stopwords nếu chưa có\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lmtz = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Chuyển về chữ thường\n",
    "    text = text.lower()\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Loại bỏ dấu câu, từ rỗng và ký tự không cần thiết + lemmatize\n",
    "    tokens = [\n",
    "        lmtz.lemmatize(t)\n",
    "        for t in tokens\n",
    "        if t not in stop_words and t not in string.punctuation\n",
    "    ]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Áp dụng cho toàn bộ dữ liệu\n",
    "df[\"tokens\"] = df[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sinh embedding từ mô hình Transformer\n",
    "\n",
    "**2.1. Chọn mô hình gốc (pretrained model)**\n",
    "- Tiếng Anh: BERT-base, RoBERTa-base, Sentence-BERT (SBERT), v.v.\n",
    "- Tiếng Việt: PhoBERT, xlm-roberta-base (đa ngôn ngữ), hoặc các mô hình vibert4news,...\n",
    "> Lưu ý:\n",
    ">- Với dữ liệu chuyên ngành, nếu có domain-specific model (VD: mô hình cho y khoa, pháp luật, tài chính), bạn nên sử dụng để embedding phản ánh ngữ nghĩa chính xác hơn.\n",
    ">- Có thể cân nhắc fine-tune nhẹ mô hình trên dữ liệu gốc (unsupervised domain adaptation) để cải thiện độ phù hợp.\n",
    "\n",
    "**2.2. Chiến lược lấy embedding**\n",
    "- **Sentence embedding:**\n",
    "\n",
    "    - Ví dụ dùng Sentence-BERT (SBERT) – mô hình được huấn luyện đặc biệt để sinh embedding câu, cho kết quả tốt hơn so với BERT “raw”.\n",
    "    - Nếu mô hình không được tối ưu cho sentence embedding, có thể dùng pooling (mean pooling, CLS token) từ layer cuối/ trung gian của BERT.\n",
    "\n",
    "- **Document embedding:**\n",
    "\n",
    "    - Nếu mỗi “bài” rất dài, có thể chia thành nhiều đoạn/câu, rồi lấy trung bình (average pooling), hoặc dùng mô hình hierarchical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T08:05:37.660385Z",
     "start_time": "2025-02-28T08:05:23.966316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "327b2a90f92e4707bd3befe2bf2cf952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Chọn 1 mô hình sentence-BERT cho tiếng Anh\n",
    "model_name = 'all-MiniLM-L6-v2'\n",
    "model_sbert = SentenceTransformer(model_name)\n",
    "\n",
    "# Chuyển mỗi văn bản (đã preprocessing) thành chuỗi để embedding\n",
    "docs = df['text'].tolist()\n",
    "\n",
    "# Sinh embeddings (mỗi doc -> vector 384 chiều cho 'all-MiniLM-L6-v2')\n",
    "embeddings = model_sbert.encode(docs, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T08:05:46.937404Z",
     "start_time": "2025-02-28T08:05:39.010994Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\datkt\\Desktop\\Working\\notebooks\\coding\\learning\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "C:\\Users\\datkt\\Desktop\\Working\\notebooks\\coding\\learning\\.venv\\Lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# (Tuỳ chọn) Giảm chiều để clustering tốt hơn: Dùng UMAP để giảm từ 384 chiều → 10, 15… (tuỳ ý).\n",
    "import umap\n",
    "\n",
    "reducer = umap.UMAP(n_neighbors=40, n_components=10, random_state=42)\n",
    "reduced_embeddings = reducer.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phân cụm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T08:07:39.112610Z",
     "start_time": "2025-02-28T08:07:37.831268Z"
    }
   },
   "outputs": [],
   "source": [
    "# K-means (cần biết trước số cụm):\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k = 5  # giả định muốn 5 cụm\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(reduced_embeddings)\n",
    "cluster_labels = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDBSCAN (tự động xác định số cụm dựa trên mật độ):\n",
    "\n",
    "import hdbscan\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=10, gen_min_span_tree=True)\n",
    "cluster_labels = clusterer.fit_predict(reduced_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T08:08:39.962076Z",
     "start_time": "2025-02-28T08:08:39.952160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                              title  cluster\n",
      "0  25626  One Weight-Loss Approach Fits All? No, Not Eve...        0\n",
      "1  19551  South Carolina Stuns Baylor to Reach the Round...        4\n",
      "2  25221  U.S. Presidential Race, Apple, Gene Wilder: Yo...        2\n",
      "3  18026  His Predecessor Gone, Gambia’s New President F...        1\n",
      "4  21063  ‘Harry Potter and the Cursed Child’ Goes From ...        3\n"
     ]
    }
   ],
   "source": [
    "# Gán mỗi document vào cụm / chủ đề\n",
    "df['cluster'] = cluster_labels\n",
    "print(df[['id', 'title', 'cluster']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trích xuất từ khoá đại diện cho từng cụm\n",
    "\n",
    "- Cách nhanh: Đếm tần suất từ (hoặc TF-IDF) trong mỗi cụm.\n",
    "- Hoặc: Sử dụng BERTopic – nó tự động thực hiện bước này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T08:10:20.831128Z",
     "start_time": "2025-02-28T08:10:20.813865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cụm 0: ['’', '“', '”', 'said', 'mr.', '—', 'would', 'dr.', 'one', 'company']\n",
      "Cụm 1: ['’', '“', '”', 'said', 'mr.', 'state', '—', 'year', 'united', 'one']\n",
      "Cụm 2: ['’', 'mr.', '“', '”', 'trump', 'said', '—', 'president', 'new', 'would']\n",
      "Cụm 3: ['’', '“', '”', 'mr.', 'said', '—', 'new', 'time', 'show', 'song']\n",
      "Cụm 4: ['’', '“', '”', 'said', 'new', 'mr.', 'ms.', '—', 'would', 'time']\n"
     ]
    }
   ],
   "source": [
    "# Trích xuất từ khoá đại diện cho từng cụm\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "cluster_texts = defaultdict(list)\n",
    "\n",
    "for cluster_id, text_tokens in zip(df['cluster'], df['tokens']):\n",
    "    cluster_texts[cluster_id].extend(text_tokens)\n",
    "\n",
    "for c in sorted(cluster_texts.keys()):\n",
    "    word_freq = Counter(cluster_texts[c])\n",
    "    top_words = [w for w, _ in word_freq.most_common(10)]\n",
    "    print(f\"Cụm {c}: {top_words}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nếu c == -1 (HDBSCAN): là outlier.\n",
    "- Từ list top_words, bạn có thể đặt nhãn (ví dụ “Embeddings & BERT” / “LDA topic modeling”, …)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification\n",
    "\n",
    "Text classification (phân loại văn bản) là một trong những nhiệm vụ quan trọng của xử lý ngôn ngữ tự nhiên (NLP), giúp gán nhãn cho văn bản dựa trên nội dung của nó. Ví dụ, phân loại email spam, phân loại tin tức theo chủ đề, phân loại đánh giá sản phẩm (tích cực/tiêu cực),…\n",
    "\n",
    "### 1. Các bước trong pipeline phân loại văn bản\n",
    "\n",
    "#### 1.1. Thu thập và chuẩn bị dữ liệu\n",
    "- **Thu thập dữ liệu**: Tập hợp dữ liệu văn bản từ các nguồn như website, cơ sở dữ liệu, API,...\n",
    "- **Gán nhãn**: Đối với bài toán giám sát, cần có dữ liệu đã được gán nhãn (ví dụ: spam vs. non-spam, tin tức thể thao, chính trị, giải trí, v.v.).\n",
    "- **Tiền xử lý**:\n",
    "  - Loại bỏ ký tự đặc biệt, HTML tags, số, dấu câu không cần thiết.\n",
    "  - Chuyển đổi về chữ thường (lowercasing).\n",
    "  - Tokenization: tách từ, câu bằng các công cụ như NLTK, spaCy (tiếng Anh) hoặc Underthesea (tiếng Việt).\n",
    "  - Loại bỏ stopwords: loại bỏ các từ không mang nhiều ý nghĩa (ví dụ: \"và\", \"nhưng\", \"của\" trong tiếng Việt).\n",
    "  - (Tuỳ chọn) Stemming/Lemmatization: rút gọn từ về gốc từ để giảm tính đa dạng của từ vựng.\n",
    "\n",
    "#### 1.2. Biểu diễn văn bản (Text Representation)\n",
    "- **Bag-of-Words (BoW)**: Biểu diễn văn bản dưới dạng vector tần số từ.\n",
    "- **TF-IDF**: Cân nhắc tần số xuất hiện của từ trong văn bản so với toàn bộ corpus để xác định tầm quan trọng.\n",
    "- **Word Embeddings**: Sử dụng các mô hình như Word2Vec, GloVe để chuyển từ thành vector có ngữ nghĩa.\n",
    "- **Sentence/Document Embeddings**: Sử dụng các mô hình Transformer (BERT, RoBERTa, …) hoặc Sentence-BERT để chuyển đổi toàn bộ văn bản thành vector đại diện.\n",
    "\n",
    "#### 1.3. Lựa chọn mô hình phân loại\n",
    "- **Các thuật toán truyền thống**:\n",
    "  - Naive Bayes\n",
    "  - Support Vector Machines (SVM)\n",
    "  - Logistic Regression\n",
    "  - Decision Trees / Random Forest\n",
    "- **Các mô hình deep learning**:\n",
    "  - Convolutional Neural Networks (CNN) cho văn bản\n",
    "  - Recurrent Neural Networks (RNN), LSTM, GRU\n",
    "  - Transformer-based models (BERT, RoBERTa, XLNet, …) với fine-tuning\n",
    "\n",
    "#### 1.4. Huấn luyện mô hình\n",
    "- **Chia dữ liệu**: Tách dữ liệu thành tập huấn luyện, tập kiểm tra và (tuỳ chọn) tập validation.\n",
    "- **Huấn luyện mô hình**: Sử dụng tập huấn luyện để học các đặc trưng và tìm ra các trọng số phù hợp.\n",
    "- **Tối ưu hóa**: Sử dụng các thuật toán tối ưu (như Adam, SGD) và các kỹ thuật regularization để tránh overfitting.\n",
    "\n",
    "#### 1.5. Đánh giá mô hình\n",
    "- **Các chỉ số đánh giá**:\n",
    "  - Accuracy: Độ chính xác tổng thể.\n",
    "  - Precision, Recall, F1-score: Đặc biệt hữu ích với các lớp không cân bằng.\n",
    "  - Confusion Matrix: Ma trận nhầm lẫn để phân tích lỗi.\n",
    "- **Cross-validation**: Sử dụng K-fold cross-validation để đảm bảo mô hình ổn định và tổng quát.\n",
    "\n",
    "#### 1.6. Triển khai và bảo trì\n",
    "- **Triển khai mô hình**: Tích hợp vào hệ thống hoặc API để xử lý văn bản theo thời gian thực.\n",
    "- **Bảo trì và cập nhật**: Theo dõi hiệu suất mô hình khi có dữ liệu mới và cập nhật mô hình định kỳ.\n",
    "\n",
    "### 2. Các phương pháp hiện đại và ứng dụng\n",
    "\n",
    "#### 2.1. Fine-tuning các mô hình Transformer\n",
    "- **BERT và các biến thể**:\n",
    "  - Fine-tuning BERT cho nhiệm vụ phân loại văn bản đã cho kết quả rất tốt, đặc biệt với dữ liệu có ngữ cảnh phức tạp.\n",
    "  - Các mô hình như RoBERTa, XLNet, ALBERT cũng thường được sử dụng để cải thiện hiệu suất.\n",
    "- **Ứng dụng**:\n",
    "  - Phân loại email spam\n",
    "  - Phân loại cảm xúc trong đánh giá sản phẩm\n",
    "  - Phân loại tin tức, bài báo theo chủ đề\n",
    "\n",
    "#### 2.2. Kết hợp các phương pháp truyền thống và deep learning\n",
    "- **Hybrid models**:\n",
    "  - Sử dụng các đặc trưng truyền thống (TF-IDF) kết hợp với embedding từ các mô hình Transformer.\n",
    "  - Sử dụng ensemble methods: Kết hợp kết quả từ các mô hình truyền thống (Naive Bayes, SVM) với các mô hình deep learning để cải thiện độ chính xác.\n",
    "\n",
    "### 3. Best practices trong Text Classification\n",
    "\n",
    "- **Tiền xử lý**:\n",
    "  - Làm sạch dữ liệu kỹ lưỡng là bước nền tảng.\n",
    "  - Tùy chỉnh bộ stopwords và các bước tiền xử lý theo ngôn ngữ và đặc thù của dữ liệu.\n",
    "- **Chọn đúng biểu diễn**:\n",
    "  - Đối với văn bản ngắn, các biểu diễn như TF-IDF có thể hiệu quả.\n",
    "  - Với văn bản phức tạp, sử dụng embeddings từ Transformer sẽ giúp nắm bắt ngữ cảnh tốt hơn.\n",
    "- **Xây dựng pipeline linh hoạt**:\n",
    "  - Sử dụng các thư viện như Scikit-learn, Keras, hoặc Hugging Face Transformers để xây dựng và huấn luyện mô hình.\n",
    "  - Tích hợp các bước tiền xử lý, biểu diễn và huấn luyện thành một pipeline để dễ bảo trì.\n",
    "- **Đánh giá kỹ càng**:\n",
    "  - Sử dụng nhiều chỉ số đánh giá, đặc biệt khi dữ liệu có sự mất cân bằng giữa các lớp.\n",
    "- **Fine-tuning và chuyển giao học**:\n",
    "  - Fine-tuning mô hình pretrained trên tập dữ liệu của bạn sẽ cho hiệu quả cao.\n",
    "  - Chuyển giao học (transfer learning) là chìa khóa để áp dụng thành công các mô hình Transformer trong NLP.\n",
    "\n",
    "### 4. Kết luận\n",
    "\n",
    "Text classification là một nhiệm vụ then chốt trong NLP với ứng dụng rộng rãi. Từ các phương pháp truyền thống như Naive Bayes, SVM đến các mô hình deep learning hiện đại như BERT, việc lựa chọn phương pháp phù hợp phụ thuộc vào đặc thù của dữ liệu, yêu cầu về hiệu suất và khả năng giải thích của mô hình. Một pipeline hoàn chỉnh cần kết hợp các bước từ thu thập, tiền xử lý, biểu diễn văn bản, huấn luyện mô hình đến đánh giá và triển khai, với khả năng điều chỉnh linh hoạt cho từng bài toán cụ thể.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
