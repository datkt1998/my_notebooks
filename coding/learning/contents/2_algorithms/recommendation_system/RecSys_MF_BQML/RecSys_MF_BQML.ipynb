{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Systems with BigQuery ML and Vertex AI Pipelines using Matrix Factorization\n",
    "\n",
    "Matrix factorizations are widely used for Recommendation Systems. They are a great and easy starting point if you want to build a quick and easy solution to deliver great recommendations to your customers.\n",
    "\n",
    "**Pipeline**\n",
    "\n",
    "<img src = \"_images/pipeline_overall.png\">\n",
    "\n",
    "Our pipeline is responsible for the whole recommendation process, including managing BigQuery slots and deploying the model to get online recommendations:\n",
    "1. Creating a slot commitment + reservation + assignment\n",
    "2. Building the BigQuery ML Matrix Factorization model\n",
    "3. Deleting the slot commitment + reservation + assignment\n",
    "4. Exporting the model\n",
    "5. Deploying the model to Cloud Run using TensorFlow serving\n",
    "\n",
    "**Capacity Management / Slots (Attention)**\n",
    "\n",
    "BigQuery ML Matrix Factorization uses `Alternating Least Squares` for ***explicit feedback*** and `Weighted Alternating Least Squares` for ***implicit feedback***. \n",
    "\n",
    "Do dữ liệu train thường lớn nên các model cần sử dụng many interations để over data, do đó thay vì sử dụng các sử dụng tính toán chi phí để compute bằng việc dùng bao nhiêu tính tiền bấy nhiêu thì train model sẽ sử dụng cách tính chi phí theo từng slot reservations.\n",
    "> we use flex slots, a way of short-term commitments. The commitment duration is only 60 seconds after that, we can cancel at any time. In our case, we only need the commitment for the duration of our model “training”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi tiết bài viết: [link](https://medium.com/google-cloud/recommendations-pipeline-with-matrix-factorization-using-bigquery-ml-and-vertex-ai-pipelines-67e72ddec7f5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
