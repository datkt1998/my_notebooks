{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7fdb1ee3-8bcf-4f80-9160-5f737357f693",
   "metadata": {},
   "source": [
    "# Custom Transforms Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c54f025a",
   "metadata": {},
   "source": [
    "## FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa98499-37e6-4eed-b0b1-790cb956efff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# remove columns with few unique values\n",
    "def cust_transform(X, min_values=3):\n",
    "    X_obj = (X.dtypes == 'object')\n",
    "    X_few_unique = X.loc[:,X_obj].nunique() < min_values\n",
    "    return X.loc[:,(X_obj & X_few_unique)]\n",
    "    \n",
    "# define the transformer\n",
    "trans = FunctionTransformer(cust_transform, kw_args={'min_values':5})\n",
    "\n",
    "# # apply the transform\n",
    "X_train = trans.fit_transform(X_train)\n",
    "X_test = trans.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f51c3-93d6-4278-9637-2c4c1e0428c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or use decorator\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "@FunctionTransformer\n",
    "def cust_transform(X, min_values=3):\n",
    "    X_obj = (X.dtypes == 'object')\n",
    "    X_few_unique = X.loc[:,X_obj].nunique() < min_values\n",
    "    return X.loc[:,(X_obj & X_few_unique)]\n",
    "\n",
    "# # apply the transform\n",
    "X_train = cust_transform.fit_transform(X_train)\n",
    "X_test = cust_transform.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624b2283-2662-4b5e-a654-2f559d228e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in pipeline\n",
    "col_trans = ColumnTransformer(\n",
    "    [\n",
    "        (\"cust_transform\", cust_transform, ),\n",
    "        (\"label encoding\", OrdinalEncoder(), [\"country\", \"store\", \"product\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe = Pipeline([(\"preprocessing\", col_trans), (\"regression\", LinearRegression())])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19d15a56",
   "metadata": {},
   "source": [
    "## Class transformation\n",
    "\n",
    "These are __4 configurations__ that always used when creating custom transformer:\n",
    "- Add `BaseEstimator` & `TransformerMix` into inherit `get_params` and `fit_transform` function. Personally, I always use `fit_transform` when I need to have a quick view on the output.\n",
    "- Define `self.variables` attributes so that you can easily select which columns to be applied on later\n",
    "- Define `fit` method. Depending on the transformation, if it doesnâ€™t require fitting, just create a dummy fit function.\n",
    "- Define `transform` method. This is used to transform original dataset to modified dataset based on your transformation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a47670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3433695c",
   "metadata": {},
   "source": [
    "Example 1: Custom transformer without requiring `fit` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24274f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Custom transformer without requiring fit method\n",
    "\n",
    "class DropFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_dropped = X.drop(self.variables, axis = 1)\n",
    "        self.columns = X_dropped.columns\n",
    "        return X_dropped"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09cbaeef",
   "metadata": {},
   "source": [
    "Example 2: Custom transformer requiring `fit` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd63fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Custom transformer requiring fit method\n",
    "\n",
    "class OneHotEncodercustom(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables\n",
    "        self.ohe = OneHotEncoder(drop='first', handle_unknown = 'ignore')\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        self.ohe.fit(X_)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        # get one-hot encoded feature in df format\n",
    "        X_transformed = pd.DataFrame(self.ohe.transform(X_).toarray(), columns= self.ohe.get_feature_names_out())\n",
    "        \n",
    "        # Remove columns that are one hot encoded in original df\n",
    "        X.drop(self.variables, axis= 1, inplace=True)\n",
    "        \n",
    "        # Add one hot encoded feature to original df\n",
    "        X[self.ohe.get_feature_names_out()] = X_transformed[self.ohe.get_feature_names_out()].values\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbb7222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom transformer\n",
    "\n",
    "class SimpleImputerCustom(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Improvise onsklearn.impute.SimpleImputer function so it \n",
    "    returns as dataframe instead of np.array.\"\"\"\n",
    "    def __init__(self, variables, strategy):\n",
    "        self.variables = variables\n",
    "        self.strategy = strategy\n",
    "        self.imp = SimpleImputer(missing_values=np.nan,   \n",
    "                    strategy=self.strategy)\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        self.imp.fit(X_)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        X_transformed = pd.DataFrame(self.imp.transform(X_), columns= self.variables)\n",
    "        X.drop(self.variables, axis= 1, inplace=True)\n",
    "        X[self.variables] = X_transformed[self.variables].values\n",
    "        return X\n",
    "\n",
    "\n",
    "class DomainNumFE(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Feature engineering technique for numerical features based on domain knowledge\"\"\"\n",
    "    def __init__(self, variables = None):\n",
    "        self.variables = variables\n",
    "\n",
    "    def fit(self, X, y =None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # source: https://www.kaggle.com/lavanyashukla01/how-i-made-top-0-3-on-a-kaggle-competition#Feature-Engineering\n",
    "        X_ = X.copy()\n",
    "        X_['HasWoodDeck'] = (X_['WoodDeckSF'] == 0) * 1\n",
    "        X_['HasOpenPorch'] = (X_['OpenPorchSF'] == 0) * 1\n",
    "        X_['HasEnclosedPorch'] = (X_['EnclosedPorch'] == 0) * 1     \n",
    "        return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02971ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom columns selection by AUC score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class AucSelection(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, remain_threshold = 0.501, nan_strategy = 'remain'):\n",
    "        assert (remain_threshold > 0.5) and (remain_threshold <= 1)\n",
    "        self.remain_threshold = remain_threshold\n",
    "        self.nan_strategy = nan_strategy\n",
    "        self.droped_feature_ = None\n",
    "        self.droped_index_ = None\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        self.auc = X.apply(lambda c: self.get_auc(y, c))\n",
    "        auc_nan = self.auc.fillna(self.remain_threshold) if \\\n",
    "            self.nan_strategy == 'remain' else self.auc.fillna(0.5) # drop\n",
    "        self.droped_index_ = (auc_nan < self.remain_threshold) \n",
    "        self.droped_feature_ = X.columns[self.droped_index_]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.droped_index_ is None:\n",
    "            raise ValueError(\"AucSelection is not be fitted\" )\n",
    "        X_ = X.loc[:,~self.droped_index_]\n",
    "        return X_\n",
    "    \n",
    "    def get_auc(y, var, flexible_sign=True):\n",
    "        \"\"\"\n",
    "        AUC the hien kha nang predictive cua model voi bien Y,\n",
    "        do vay khi AUC(y, var) ~ 0.5 (random guess) the hien var \n",
    "        khong co kha nang giai thich bien Y\n",
    "        \"\"\"\n",
    "        try: # numeric data\n",
    "            nan_idx = np.isnan(np.array(var)) # filter NaN\n",
    "            var_ = var[~nan_idx]\n",
    "            y_ = y[~nan_idx]\n",
    "            # if label not only 1s/0s\n",
    "            auc = roc_auc_score(y_score=var_, y_true=y_) if (var_.std() > 0) else 0.5\n",
    "            # for evaluation only\n",
    "            if (auc < 0.5) & (flexible_sign):\n",
    "                auc = 1.0 - auc\n",
    "            return auc\n",
    "        except: # categorical\n",
    "            return np.nan\n",
    "    \n",
    "auc_selector = AucSelection(remain_threshold = 0.502)\n",
    "X_train = auc_selector.fit_transform(X_train, y_train)\n",
    "X_test = auc_selector.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f2bdaed",
   "metadata": {},
   "source": [
    "## Custom make columns selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8caf051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
    "\n",
    "class custom_column_seletor(make_column_selector):\n",
    "\n",
    "    def __init__(self, pattern=None, dtype_include=None, dtype_exclude=None, add_vars = []):\n",
    "        super().__init__(pattern, dtype_include, dtype_exclude)\n",
    "        self.add_vars = add_vars\n",
    "\n",
    "    def __call__(self, df):\n",
    "        if not hasattr(df, \"iloc\"):\n",
    "            raise ValueError(\n",
    "                \"make_column_selector can only be applied to pandas dataframes\"\n",
    "            )\n",
    "        df_row = df.iloc[:1]\n",
    "        if self.dtype_include is not None or self.dtype_exclude is not None:\n",
    "            df_row = df_row.select_dtypes(\n",
    "                include=self.dtype_include, exclude=self.dtype_exclude\n",
    "            )\n",
    "        cols = df_row.columns\n",
    "        if self.pattern is not None:\n",
    "            cols = cols[cols.str.contains(self.pattern, regex=True)]\n",
    "\n",
    "        df_ = df[cols.tolist()].copy()\n",
    "        df_ = self.filter_columns(df_)\n",
    "        return list(set().union(df_.columns.tolist(), self.add_vars))\n",
    "    \n",
    "    def filter_columns(df):\n",
    "        \"\"\"\n",
    "        make custom process to get specific columns\n",
    "        \"\"\"\n",
    "        # example\n",
    "        nuni = df.nunique() < 30\n",
    "        return df.loc[:,nuni]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81d857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_trans = ColumnTransformer(\n",
    "    [\n",
    "        (\"cust_transform\", cust_transform, custom_column_seletor(dtype_include=float, add_vars=[\"store\", \"product\"]) ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e715e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_trans = make_column_transformer(\n",
    "        (\"cust_transform\", cust_transform, custom_column_seletor(dtype_include=float, add_vars=[\"store\", \"product\"]) ),\n",
    "        (\"cust_transform2\", cust_transform2, custom_column_seletor(dtype_exclude=np.number, add_vars=[ \"product\"]) ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
