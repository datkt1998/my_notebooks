{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7949db45-a4da-4bc0-9319-0cb9235b1573",
   "metadata": {
    "id": "F1OozWpUijnX"
   },
   "source": [
    "# Feature selection\n",
    "\n",
    "Để xây dựng mô hình chúng ta sẽ rất cần đến dữ liệu lớn. Nhưng dữ liệu quá lớn cũng không thực sự tốt. Những hệ thống của các tập đoàn công nghệ lớn có thể có số lượng trường dữ liệu lên tới hàng trăm ngàn. Đây là một con số khổng lồ và sẽ gây ra những hạn chế đó là:\n",
    "\n",
    "* Tăng chi phí tính toán.\n",
    "* Quá nhiều biến giải thích có thể dẫn tới _quá khớp_ (_overfiting_). Tức hiện tượng mô hình hoạt động tốt trên _tập huấn luyện_ nhưng kém trên _tập kiểm tra_.\n",
    "* Trong số các biến sẽ có những biến gây nhiễu và làm giảm chất lượng mô hình.\n",
    "* Rối loạn thông tin do không thể kiểm soát và hiểu hết các biến.\n",
    "\n",
    "Chính vì thế chúng ta cần phải có những phương pháp như giảm chiều dữ liệu hoặc lựa chọn biến quan trọng. Về phương pháp giảm chiều dữ liệu sẽ được trình bày ở một chương khác. Trong chương này này chúng ta sẽ làm quen với một số kĩ thuật lựa chọn biến thông dụng.\n",
    "\n",
    "Bên dưới là những thuật toán quan trọng được sử dụng để lựa chọn các biến."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6282354a-eb8f-4cde-bcb4-e6645f368788",
   "metadata": {
    "id": "mN_b5BbxiwX9"
   },
   "source": [
    "## Phương pháp thống kê\n",
    "\n",
    "Một phương pháp quan trọng trong các phương pháp thống kê nhằm giảm số lượng biến là lựa chọn dựa trên phương sai. Dựa trên phân tích các biến không biến động thì không có tác dụng gì trong việc phân loại hoặc dự báo bởi chúng ta dường như đã biết được giá trị của chúng cho tất cả các quan sát. Do đó ý tưởng chính của phương pháp này là thông qua độ lớn phương sai của toàn bộ các _biến numeric_ để loại bỏ những biến nếu nó nhỏ hơn một ngưỡi nhất định.\n",
    "\n",
    "Trong sklearn chúng ta có thể sử dụng _VarianceThreshold_ để lọc bỏ biến theo phương sai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321f99e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7PfY5cBi0om",
    "outputId": "46f47c8a-5699-49e2-abd8-bab4124b240d"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Khởi toạo dữ liệu example\n",
    "X, y = make_classification(n_samples=500, n_features=50, random_state=123)\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "print('y shape:', y.shape)\n",
    "\n",
    "# Lọc bỏ các biến có phương sai nhỏ hơn 0.8\n",
    "print('Total features with thres=0.8: {}'.format(VarianceThreshold(0.8).fit_transform(X).shape))\n",
    "\n",
    "# Lọc bỏ các biến có phương sai nhỏ hơn 1.0\n",
    "X_kvar = VarianceThreshold(0.9).fit_transform(X)\n",
    "print('Total features with thres=1.0: {}'.format(X_kvar.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "593a5f57-f013-422c-88e2-a446ac9726e5",
   "metadata": {
    "id": "7_vWaDdojCpW"
   },
   "source": [
    "Ngoài phương pháp phương sai, chúng ta có thể áp dụng [kiểm định thống kê đơn biến](https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection). Phương pháp này sẽ đánh giá sự độc lập tuyến tính giữa hai biến ngẫu nhiên dựa trên phân phối _chi-squared_ và _Fisher_ để lựa chọn ra $k$ biến tốt nhất. Để hình dung kĩ hơn về hai phương pháp thống kê nêu trên, tiếp theo chúng ta cùng thực hành lựa chọn biến và đánh giá hiệu quả mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355e89a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OO5G-WepjOcg",
    "outputId": "d88a3d74-1d59-4110-a32a-d40479b84380"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Lựa chọn biến dựa trên phương pháp Fisher\n",
    "X_kbest = SelectKBest(f_classif, k = 5).fit_transform(X, y)\n",
    "print('X shape after applying statistical selection: ',X_kbest.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "768fce41-65e4-4b0d-aae3-cf9fb4758182",
   "metadata": {
    "id": "r9DUMtqUjQpW"
   },
   "source": [
    "Chúng ta sẽ cùng đánh giá hiệu quả mô hình bằng cross-validation trước và sau lựa chọn biến với KFold = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe33d5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HwYXqLlWjRIQ",
    "outputId": "cbb8418c-8386-48fe-b610-91b05f585887"
   },
   "outputs": [],
   "source": [
    "# Hồi qui logistic\n",
    "logit = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "\n",
    "# Cross validation cho:\n",
    "# 1.dữ liệu gốc\n",
    "acc_org = cross_val_score(logit, X, y, scoring = 'accuracy', cv = 5).mean()\n",
    "# 2. Áp dụng phương sai\n",
    "acc_var = cross_val_score(logit, X_kvar, y, scoring = 'accuracy', cv = 5).mean()\n",
    "# 3. Áp dụng phương pháp thống kê\n",
    "acc_stat = cross_val_score(logit, X_kbest, y, scoring = 'accuracy', cv = 5).mean()\n",
    "\n",
    "print('Accuracy trên dữ liệu gốc:', acc_org)\n",
    "print('Accuracy áp dụng phương sai:', acc_var)\n",
    "print('Accuracy dụng pp thống kê:', acc_stat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fce42b38-13b4-475b-99f9-69794abf0e5a",
   "metadata": {
    "id": "XQaRtczHy3fT"
   },
   "source": [
    "Như vậy ta thấy sau khi áp dụng feature selection đã cải thiện được độ chính xác của mô hình dự báo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f7dde70-6036-41e6-8966-6d2a1d39856d",
   "metadata": {
    "id": "d9yQ02fvjWAa"
   },
   "source": [
    "## Sử dụng mô hình\n",
    "\n",
    "Đây là phương pháp rất thường xuyên được áp dụng trong các cuộc thi phân tích dữ liệu. Chúng ta sẽ dựa trên một số mô hình cơ sở để đánh giá mức độ quan trọng của các biến. Có hai lớp mô hình thường được sử dụng để đánh biến đó là _Random Forest_ và _Linear Regression_. Ưu điểm của các phương pháp này là kết quả đánh giá rất chuẩn xác, tuy nhiên nhược điểm của chúng là phải xây dựng mô hình hồi qui rồi mới xác định được biến quan trọng. Điều này dường như đi trái lại với thực tế phải lựa chọn biến trước khi huấn luyện mô hình. Để áp dụng phương pháp này chúng ta thực hiện như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f66a47",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8QDK3nRjdVC",
    "outputId": "05f1cded-cb35-4451-e034-9e9fea4e47de"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Hồi qui theo RandomForest\n",
    "rdFrt = RandomForestClassifier(n_estimators = 20, random_state = 1)\n",
    "# Hồi qui theo LinearSVC\n",
    "lnSVC = LinearSVC(C=0.01, penalty=\"l1\", dual=False)\n",
    "# Hồi qui theo Lasso\n",
    "lassoReg = Lasso(alpha = 1.0)\n",
    "# Tạo một pipeline thực hiện lựa chọn biến từ RandomForest model và hồi qui theo logit\n",
    "pipe1 = make_pipeline(StandardScaler(), SelectFromModel(estimator = rdFrt), logit)\n",
    "# Tạo một pipeline thực hiện lựa chọn biến từ Linear SVC model và hồi qui theo logit\n",
    "pipe2 = make_pipeline(StandardScaler(), SelectFromModel(estimator = lnSVC), logit)\n",
    "\n",
    "# Cross validate đối với \n",
    "# 1. Mô hình logit\n",
    "acc_log = cross_val_score(logit, X, y, scoring = 'accuracy', cv = 5).mean()\n",
    "# 2. Mô hình RandomForest\n",
    "acc_rdf = cross_val_score(rdFrt, X, y, scoring = 'accuracy', cv = 5).mean()\n",
    "# 3. Mô hình pipe1\n",
    "acc_pip1 = cross_val_score(pipe1, X, y, scoring = 'accuracy', cv = 5).mean()\n",
    "# 3. Mô hình pipe2\n",
    "acc_pip2 = cross_val_score(pipe2, X, y, scoring = 'accuracy', cv = 5).mean()\n",
    "\n",
    "print('Accuracy theo logit:', acc_log)\n",
    "print('Accuracy theo random forest:', acc_rdf)\n",
    "print('Accuracy theo pipeline 1:', acc_pip1)\n",
    "print('Accuracy theo pipeline 2:', acc_pip2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec30288a-0fc5-47a7-8f3c-185369e0b6e7",
   "metadata": {
    "id": "w8zLfGzEy2UP"
   },
   "source": [
    "Như vậy select dựa trên mô hình Random Forest và Linear SVC đã có hiệu quả trong việc cải thiện độ chính xác của mô hình. Bên cạnh việc thực hiện lựa chọn biến dựa trên model, chúng ta còn có thể lựa chọn biến theo grid search."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef41a226-07a9-4778-8873-69cdb29b2841",
   "metadata": {
    "id": "idYeCz6ajis9"
   },
   "source": [
    "## Sử dụng Search\n",
    "\n",
    "**Exhaustive Search**\n",
    "\n",
    "Ý tưởng chính của phương pháp này là tìm ra một tập con các đặc trưng tốt nhất trong số các đặc trưng đầu vào dựa trên một thước đo mô hình cụ thể (chẳng hạn như _accuracy_). Ví dụ, khi bạn có tổng cộng $n$ đặc trưng thì bạn cần huấn luyện mô hình trên tất cả các kết hợp từ $1, 2, 3, ..., n$ đặc trưng. Tổng số lượng các kết hợp có thể sẽ là:\n",
    "\n",
    "$$\\binom{n}{1} + \\binom{n}{2} + \\binom{n}{3} + \\dots + \\binom{n}{n} = 2^{n} - 1$$\n",
    "\n",
    "Đây là số lượng không hề nhỏ nếu bộ dữ liệu của bạn có số lượng đặc trưng lớn. Chính vì thế phương pháp này được coi là _Exhaustive_ và chỉ phù hợp với những bộ dữ liệu có số lượng đặc trưng nhỏ. Ưu điểm của phương pháp này mang lại đó là giúp tìm ra được tập con đặc trưng tốt nhất trực tiếp thông qua đánh giá _accuracy_."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e698fdd-ad34-4288-a3a0-da0ef933c240",
   "metadata": {
    "id": "ZZfRpw7Mjsp9"
   },
   "source": [
    "**Sequential Feature Selection**\n",
    "\n",
    "Nếu như chúng ta tìm kiếm trên toàn bộ các bộ kết hợp đặc trưng đầu vào của mô hình sẽ rất lâu. Do đó việc đầu tiên ta cần thực hiện là giới hạn không gian tìm kiếm. Tuỳ theo hướng tìm kiếm là tăng biến hoặc giảm biến mà phương pháp này bao gồm hai hai lựa chọn là: forward hoặc backward tương ứng. Theo lựa chọn forward thì ban đầu ta xuất phát từ lựa chọn $1$ đặc trưng đầu vào mà mô hình có kết quả tốt nhất. Ở các bước tiếp theo ta sẽ tìm ra một đặc trưng phù hợp nhất để thêm vào mô hình sao cho thước đo đánh giá mô hình là lớn nhất. Quá trình này tiếp tục cho đến khi số lượng các đặc trưng được thêm vào đạt mức tối đa `k_features` hoặc tới khi hàm loss fuction mô hình không giảm nữa. Theo chiều ngược lại, bắt đầu từ toàn bộ các đặc trưng và loại dần đặc trưng thì sẽ là backward. \n",
    "\n",
    "So với phương pháp _Exhaustive Search_ thì _Sequential Feature Selection_ ít tốn kém hơn về chi phí nhưng không đảm bảo chắc chắn rằng tập hợp đặc trưng tìm được là tối ưu. Hướng di chuyển tìm kiếm theo forward và backward cũng hoàn toàn là lựa chọn may rủi.\n",
    "\n",
    "Bên dưới ta sẽ tiến hành áp dụng phương pháp _Sequential Feature Selection_ để tìm kiếm đặc trưng theo backward với số biến cần lựa chọn là `k_features=3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e848206",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HqZcFnnij1o-",
    "outputId": "13c7c2f1-7eae-4aa6-843d-0505963acccf"
   },
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4117e6c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuzSaah3j1vu",
    "outputId": "b987ca78-f8f0-40c3-beb3-c165241c8d65"
   },
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "selector = SequentialFeatureSelector(logit, scoring = 'accuracy', \n",
    "                                     verbose = 2, \n",
    "                                     k_features = 3,\n",
    "                                     forward = False,\n",
    "                                     n_jobs = -1)\n",
    "\n",
    "selector.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e501e6e-903e-4488-84cb-f05f89eb8749",
   "metadata": {
    "id": "MyTNLolmjzBm"
   },
   "source": [
    "Ta có thể thấy mô hình xuất phát từ 50 biến ban đầu và sau mỗi một quá trình sẽ loại dần các biến cho đến khi số lượng biến tối thiểu đạt được là 3. Sau mỗi quá trình mức độ accuracy sẽ tăng dần."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
