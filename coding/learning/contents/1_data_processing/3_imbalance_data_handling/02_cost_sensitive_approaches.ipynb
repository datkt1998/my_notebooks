{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c49a3c57-9444-4095-83d4-fb68085adb07",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cost sensitive approaches\n",
    "**Methods will modifies the learning function**\n",
    "\n",
    "**1. Cost of misclassifying obs**\n",
    "- __Cost of misclassifying__ of specific class is the prediction errors of this class\n",
    "- Thông thường các thuật toán sẽ không phân biệt error rate của từng class mà sẽ là chung của tất cả các class, với asumption là all misclassification errors có chi phí bằng nhau ở các class. Khi áp dụng cost of misclassification, tức quan tâm tới sự khác biệt về `error-rate` của từng class. Ví dụ: Chi phí của phân loại khách hàng __BAD__ thành __GOOD__ cao hơn cost phân loại sai khách hành __GOOD__ thành __BAD__\n",
    "- **Cost sensitive learning (CSL)** là 1 dạng learning mà sẽ đo lường __Cost of misclassifying__, với mục tiêu là minimize the total cost (cost in each class is differently)\n",
    "- So sánh **Cost sensitive** với **Cost insensitive learning**\n",
    "\n",
    "|Cost insensitive|Cost sensitive|\n",
    "|-----|-----|\n",
    "|Minimize error-rate|Minimize cost|\n",
    "|Same cost to all misclassification|Different misclassification cost|\n",
    "\n",
    "**2. Cost Matrix**\n",
    "\n",
    "<img src=\"_images/02cs_costsen.png\">\n",
    "\n",
    "**3. Obtaining the Cost**\n",
    "\n",
    "There are 2 ways of estimating the cost:\n",
    "\n",
    "- `Domain Expert` provides the cost (depend on knowledge/business)\n",
    "- `Balance Ratio`: set **class_weight** or **sample_weight** parameter to indicate that the loss function should be modified to accommodate the class imbalance and the cost attributed to each misclassification, find cost as hyper-parameter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61a5ee90-68fe-453e-9471-47ddf7bbf740",
   "metadata": {},
   "source": [
    "## BasicCost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d526f0e9-bcb5-4c67-b7c6-cbdd7aa3b160",
   "metadata": {},
   "source": [
    "- **class_weight**: can take 'balanced' as argument, in which case it will use the balance ratio as weight. Alternatively, it can take a dictionary with {class: penalty}, pairs. In this case, it penalizes mistakes in samples of class[i] with class_weight[i]. For instances, class_weight = {0:1, and 1:10}, misclassification of observations of class 1 are penalized 10 times more than misclassification of observations of class 0.\n",
    "- **sample_weight** is a vector of the same length as y, containing the weight or penalty for each individual observation. In principle, it is more flexible, because it allows us to set weights to the observations and not to the class as a whole. So in this case, for example we could set up higher penalties for fraudulent applications that are more costly (money-wise)than to those fraudulent applications that are of little money."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "405e275d-0f06-4d34-89e8-30e22c76da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# weights introduced here\n",
    "logit = LogisticRegression(\n",
    "        penalty='l2',\n",
    "        solver='newton-cg',\n",
    "        random_state=0,\n",
    "        max_iter=10,\n",
    "        n_jobs=4,\n",
    "        class_weight={0:1, 1:10} # weights / cost\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9870b437-4c02-4599-99f9-be55f7c7c660",
   "metadata": {},
   "source": [
    "## MetaCost\n",
    "\n",
    "**1. Conditional Risk - Expected Cost**\n",
    "EC của quan sát x theo class i được định nghĩa là giá trị average có weight của tất cả các cost được assign của x theo all classes thành class i.\n",
    "$$R(i|x)=\\sum_{j=1}^{M}P(j|x)\\cdot C(i,j)$$\n",
    "in which:\n",
    "- $R(i|x)$ is the expected cose of classifying an observation x into class i\n",
    "- $P(j|x)$ is the probability of x of being of class j\n",
    "- $C(i,j)$ is the cost of assigning an observation x of class j to class i\n",
    "\n",
    "__Conclusion__: For observation x, x will classify belong to class 1 if and only if `R(1|x) <= R(0|x)` or $\\frac{C(1,0)}{C(1,0) + C(0,1)}$ <= P(1|x)\n",
    "\n",
    "Bởi vì almost các thuật toán sklearn sử dụng __insensitive cost__, nên nếu muốn chuyển đổi sang __sensitive cost__ (__MetaCost__), sử dụng `predict_prob` để lấy xác suất __P(1|x)__, kết hợp với cost đã assign giúp xác định observation nào sẽ được phân loại theo class 1 theo __Conclusion__ ở trên.\n",
    "\n",
    "**2. MetaCost**\n",
    "\n",
    "__MetaCost__ change the original label to the new, then get new dataset to use for any algorithms, i.e. use `bagging multi-classifiers` to get probabilities of each class, combine these with `Cost`, then re-labels the target `Y` to the  new class that has a minimises the `conditional risk (EC)`, and finally we have a new dataset (new label) to train the ML that we want.\n",
    "__MetaCost__ is a procedure to make cost insenstitve algorithm, cost sensitive, which applied to any algorithm whether it returns probabilities or classes\n",
    "\n",
    "- __Parameter__ for `Metacost`:\n",
    "    - `S` : training set\n",
    "    - `L` : Classsification learning algorithm\n",
    "    - `C` : cost matrix\n",
    "    - `m` : the number of resamples to generate\n",
    "    - `n` : the number of examples in each resample\n",
    "    - `p` : is True if L produces class pprobabilities\n",
    "    - `q` : is True if all resamples are to be used for each example\n",
    "   \n",
    "<img src=\"_images/02cs_meta_cost.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fe6ae4f-fd19-4cd8-9ff4-85010e4d360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "class MetaCost:\n",
    "    \"\"\"A procedure for making error-based classifiers cost-sensitive\n",
    "\n",
    "    Adapted from https://github.com/Treers/MetaCost/blob/master/MetaCost.py\n",
    "\n",
    "    .. note:: The form of the cost matrix C must be as follows:\n",
    "    +---------------+----------+----------+----------+\n",
    "    |  actual class |          |          |          |\n",
    "    +               |          |          |          |\n",
    "    |   +           | y(x)=j_1 | y(x)=j_2 | y(x)=j_3 |\n",
    "    |       +       |          |          |          |\n",
    "    |           +   |          |          |          |\n",
    "    |predicted class|          |          |          |\n",
    "    +---------------+----------+----------+----------+\n",
    "    |   h(x)=j_1    |    0     |    a     |     b    |\n",
    "    |   h(x)=j_2    |    c     |    0     |     d    |\n",
    "    |   h(x)=j_3    |    e     |    f     |     0    |\n",
    "    +---------------+----------+----------+----------+\n",
    "    | C = np.array([[0, a, b],[c, 0 , d],[e, f, 0]]) |\n",
    "    +------------------------------------------------+\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, estimator, cost_matrix, n_estimators=50, n_samples=None, p=True, q=True):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        estimator :\n",
    "            An sklearn classifier\n",
    "        cost_matrix :\n",
    "            The cost matrix\n",
    "        n_estimators :\n",
    "            The number of estimators in the ensemble\n",
    "        n_samples :\n",
    "            The number of samples to train each estimator\n",
    "        p :\n",
    "            Is True if the estimator produces class probabilities. False otherwise\n",
    "        q :\n",
    "            True if all samples are to be used for each example\n",
    "        \"\"\"\n",
    "\n",
    "        self.estimator = estimator\n",
    "        self.cost_matrix = cost_matrix\n",
    "        self.n_estimators = n_estimators\n",
    "        self. n_samples = n_samples\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X :\n",
    "            Training set\n",
    "        y :\n",
    "            Target\n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise ValueError('S must be a DataFrame object')\n",
    "\n",
    "        X = X.copy()\n",
    "\n",
    "        # reset index, helps with resampling\n",
    "        X.reset_index(inplace=True, drop=True)\n",
    "        y.index = X.index\n",
    "\n",
    "        variables = list(X.columns)\n",
    "\n",
    "        # concatenate\n",
    "        S = pd.concat([X,y], axis=1)\n",
    "        S.columns = variables + ['target']\n",
    "\n",
    "        num_class = y.nunique()\n",
    "\n",
    "        if not self.n_samples:\n",
    "            self.n_samples = len(X)\n",
    "\n",
    "        S_ = {} # list of subdatasets\n",
    "        M = []  # list of models\n",
    "\n",
    "        print('resampling data and training ensemble')\n",
    "        for i in range(self.n_estimators):\n",
    "\n",
    "            # Let S_[i] be a resample of S with self.n examples\n",
    "            S_[i] = S.sample(n=self.n_samples, replace=True)\n",
    "\n",
    "            X = S_[i][variables].values\n",
    "            y = S_[i]['target'].values\n",
    "\n",
    "            # Let M[i] = model produced by applying L to S_[i]\n",
    "            model = clone(self.estimator)\n",
    "            M.append(model.fit(X, y))\n",
    "\n",
    "        print('Finished training ensemble')\n",
    "\n",
    "        label = []\n",
    "        S_array = S[variables].values\n",
    "        # for each observation\n",
    "        print('evaluating optimal class per observation')\n",
    "        for i in range(len(S)):\n",
    "            if self.q:\n",
    "                # consider the predictions of all models\n",
    "                M_ = M\n",
    "            else:\n",
    "                # consider the predictions of models which were not train on\n",
    "                # this particular observation\n",
    "                k_th = [k for k, v in S_.items() if i not in v.index]\n",
    "                M_ = list(np.array(M)[k_th])\n",
    "\n",
    "            if self.p:\n",
    "                P_j = [model.predict_proba(S_array[[i]]) for model in M_]\n",
    "            else:\n",
    "                P_j = []\n",
    "                vector = [0] * num_class\n",
    "                for model in M_:\n",
    "                    vector[model.predict(S_array[[i]])] = 1\n",
    "                    P_j.append(vector)\n",
    "\n",
    "            # Calculate P(j|x)\n",
    "            # the average probability of each class, when combining all models\n",
    "            P = np.array(np.mean(P_j, 0)).T\n",
    "\n",
    "            # Relabel:\n",
    "            label.append(np.argmin(self.cost_matrix.dot(P)))\n",
    "        print('Finished re-assigning labels')\n",
    "\n",
    "        # Model produced by applying L to S with relabeled y\n",
    "        print('Training model on new data')\n",
    "        X_train = S[variables].values\n",
    "        y_train = np.array(label)\n",
    "        self.estimator.fit(X_train, y_train)\n",
    "        print('Finished training model on data with new labels')\n",
    "        self.y_ = pd.Series(label)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        try:\n",
    "            probs = self.estimator.predict_proba(X)\n",
    "        except:\n",
    "            probs = None\n",
    "            print('this estimator does not support predict_proba')\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4a73446-cb75-4fcc-b6d3-db9e0b4a2b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='target'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "# only a few observations to speed the computaton\n",
    "data = pd.read_csv('Datasets/kdd2004.csv').sample(10000)\n",
    "\n",
    "# imbalanced target\n",
    "data.target.value_counts().plot(kind = 'pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70cdee28-96c4-4cd8-9a9f-ceac022c24e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# separate dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),  # drop the target\n",
    "    data['target'],  # just the target\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "# set up the estimator we would like to ensemble\n",
    "logit = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    solver='newton-cg',\n",
    "    random_state=0,\n",
    "    max_iter=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0991012-45d9-4e62-8194-cb8e6fee9d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling data and training ensemble\n",
      "Finished training ensemble\n",
      "evaluating optimal class per observation\n",
      "Finished re-assigning labels\n",
      "Training model on new data\n",
      "Finished training model on data with new labels\n",
      "Train set, MetaCost roc-auc: 0.9490451674621461\n",
      "Train set, MetaCost roc-auc: 0.8632507381246028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2973,    0],\n",
       "       [  11,   16]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no cost (similar normal with no metacost)\n",
    "\n",
    "metacost_nocost = MetaCost(estimator=logit,\n",
    "                     cost_matrix=np.array([[0, 1], [1, 0]]),\n",
    "                     n_estimators=50,\n",
    "                     n_samples=None,\n",
    "                     p=True,\n",
    "                     q=True)\n",
    "metacost_nocost.fit(X_train, y_train)\n",
    "# metacost_.predict_proba(X_train)\n",
    "\n",
    "\n",
    "print('Train set, MetaCost roc-auc: {}'.format(roc_auc_score(y_train, metacost_nocost.predict_proba(X_train)[:, 1])))\n",
    "print('Train set, MetaCost roc-auc: {}'.format(roc_auc_score(y_test, metacost_nocost.predict_proba(X_test)[:, 1])))\n",
    "confusion_matrix(y_test, metacost_nocost.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31961b78-5996-4346-a18f-a44e46ebba75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling data and training ensemble\n",
      "Finished training ensemble\n",
      "evaluating optimal class per observation\n",
      "Finished re-assigning labels\n",
      "Training model on new data\n",
      "Finished training model on data with new labels\n",
      "Train set, MetaCost roc-auc: 0.9924060854180382\n",
      "Train set, MetaCost roc-auc: 0.9241942918364042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2797,  176],\n",
       "       [   7,   20]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metacost\n",
    "\"\"\"\n",
    "TN | FN\n",
    "FP | TP\n",
    "\n",
    "cost\n",
    "0 | 100\n",
    "1 | 0\n",
    "\"\"\"\n",
    "metacost_ = MetaCost(estimator=logit,\n",
    "                     cost_matrix=np.array([[0, 100], [1, 0]]),\n",
    "                     n_estimators=50,\n",
    "                     n_samples=None,\n",
    "                     p=True,\n",
    "                     q=True)\n",
    "metacost_.fit(X_train, y_train)\n",
    "# metacost_.predict_proba(X_train)\n",
    "\n",
    "\n",
    "print('Train set, MetaCost roc-auc: {}'.format(roc_auc_score(y_train, metacost_.predict_proba(X_train)[:, 1])))\n",
    "print('Train set, MetaCost roc-auc: {}'.format(roc_auc_score(y_test, metacost_.predict_proba(X_test)[:, 1])))\n",
    "confusion_matrix(y_test, metacost_.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc0844e3-2f34-4314-a353-3c49e3da8c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set, MetaCost roc-auc: 0.9941046226958525\n",
      "Train set, MetaCost roc-auc: 0.9232101256991939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khongdat/miniforge3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2841,  132],\n",
       "       [   8,   19]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare with basicCost by parameter class_weight\n",
    "logit_cost = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    solver='newton-cg',\n",
    "    random_state=0,\n",
    "    max_iter=10,\n",
    "    n_jobs=4,\n",
    "    class_weight = {0:1, 1:100},\n",
    ")\n",
    "\n",
    "logit_cost.fit(X_train, y_train)\n",
    "\n",
    "print('Train set, MetaCost roc-auc: {}'.format(roc_auc_score(y_train, logit_cost.predict_proba(X_train)[:, 1])))\n",
    "print('Train set, MetaCost roc-auc: {}'.format(roc_auc_score(y_test, logit_cost.predict_proba(X_test)[:, 1])))\n",
    "confusion_matrix(y_test, logit_cost.predict(X_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb980c4b-08e3-4c59-ac36-edbe5e1a6187",
   "metadata": {},
   "source": [
    "lowest FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f9819ca-c1b2-4927-aef5-663f3fd965c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set, MetaCost roc-auc: 0.9914314516129032\n",
      "Train set, MetaCost roc-auc: 0.9283801123693488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2971,    2],\n",
       "       [  14,   13]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare with logistic normal\n",
    "logit.fit(X_train, y_train)\n",
    "print('Train set, MetaCost roc-auc: {}'.format(roc_auc_score(y_train, logit.predict_proba(X_train)[:, 1])))\n",
    "print('Train set, MetaCost roc-auc: {}'.format(roc_auc_score(y_test, logit.predict_proba(X_test)[:, 1])))\n",
    "confusion_matrix(y_test, logit.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
