{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "import uvicorn\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from fastapi import Request, FastAPI, Response\n",
    "from fastapi.responses import JSONResponse\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(\"../sentiment\")\n",
    "\n",
    "app = FastAPI(title=\"Sentiment Analysis\")\n",
    "\n",
    "AIP_HEALTH_ROUTE = os.environ.get(\"AIP_HEALTH_ROUTE\", \"/health\")\n",
    "AIP_PREDICT_ROUTE = os.environ.get(\"AIP_PREDICT_ROUTE\", \"/predict\")\n",
    "\n",
    "\n",
    "class Prediction(BaseModel):\n",
    "    sentiment: str\n",
    "    confidence: Optional[float]\n",
    "\n",
    "\n",
    "class Predictions(BaseModel):\n",
    "    predictions: List[Prediction]\n",
    "\n",
    "\n",
    "# instad of creating a class we could have also loaded this information\n",
    "# from the model configuration. Better if you introduce new labels over time\n",
    "class Sentiment(Enum):\n",
    "    NEGATIVE = 0\n",
    "    POSITIVE = 1\n",
    "\n",
    "\n",
    "@app.get(AIP_HEALTH_ROUTE, status_code=200)\n",
    "async def health():\n",
    "    return {\"health\": \"ok\"}\n",
    "\n",
    "\n",
    "@app.post(\n",
    "    AIP_PREDICT_ROUTE,\n",
    "    response_model=Predictions,\n",
    "    response_model_exclude_unset=True,\n",
    ")\n",
    "async def predict(request: Request):\n",
    "    body = await request.json()\n",
    "    print(body)\n",
    "\n",
    "    instances = body[\"instances\"]\n",
    "    print(instances)\n",
    "    print(type(instances))\n",
    "    instances = [x[\"text\"] for x in instances]\n",
    "    print(instances)\n",
    "\n",
    "    tf_batch = tokenizer(\n",
    "        instances,\n",
    "        max_length=128,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"tf\",\n",
    "    )\n",
    "\n",
    "    print(tf_batch)\n",
    "\n",
    "    tf_outputs = model(tf_batch)\n",
    "\n",
    "    print(tf_outputs)\n",
    "\n",
    "    tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
    "    print(tf_predictions)\n",
    "\n",
    "    indices = np.argmax(tf_predictions, axis=-1)\n",
    "    confidences = np.max(tf_predictions, axis=-1)\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    for index, confidence in zip(indices, confidences):\n",
    "        sentiment = Sentiment(index).name\n",
    "        print(index)\n",
    "        print(confidence)\n",
    "        outputs.append(Prediction(sentiment=sentiment, confidence=confidence))\n",
    "\n",
    "    return Predictions(predictions=outputs)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, host=\"0.0.0.0\", port=8080)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
