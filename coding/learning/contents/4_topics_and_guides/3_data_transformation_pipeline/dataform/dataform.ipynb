{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataform Overview\n",
    "\n",
    "**Dataform** is a serverless service for data analysts to develop and deploy tables, incremental tables, or views to BigQuery. Dataform offers a web environment for SQL workflow development, connection with GitHub, GitLab, Azure DevOps Services, and Bitbucket, continuous integration, continuous deployment, and workflow execution.\n",
    "\n",
    "**Dataform** lets you manage data transformation in the Extraction, Loading, and Transformation (ELT) process for data integration. After raw data is extracted from source systems and loaded into BigQuery, Dataform helps you to transform it into a well-defined, tested, and documented suite of data tables.\n",
    "\n",
    "**Main features**:\n",
    "- Develop and execute SQL workflows for data transformation.\n",
    "- Collaborate with team members on SQL workflow development through Git.\n",
    "- Manage a large number of tables and their dependencies.\n",
    "- Declare source data and manage table dependencies.\n",
    "- View a visualization of the dependency tree of your SQL workflow.\n",
    "- Manage data with SQL code in a central repository.\n",
    "- Reuse code with JavaScript.\n",
    "- Test data correctness with quality tests on source and output tables.\n",
    "- Version control SQL code.\n",
    "- Document data tables inside SQL code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repository Project**\n",
    "\n",
    "**1. Types of files:** (should be put in folder with same name)\n",
    "\n",
    "- **Config files** (`JSON` or `SQLX` files): let you configure your SQL workflows. They contain general configuration, execution schedules, or schema for creating new tables and views.\n",
    "- **Definitions**: are `SQLX` and `JavaScript` files that define new tables, views, and additional SQL operations to run in BigQuery.\n",
    "- **Includes**: are JavaScript files where you can define variables and functions to use in your project.\n",
    "\n",
    "**2. Workflow development and version control**\n",
    "\n",
    "In Dataform, the **workflow development** is the same local development, then you can pull changes from the repository, commit all or selected changes, and push them to Git branches of the repository.\n",
    "\n",
    "In Workflow development, you can:\n",
    "\n",
    "- Develop the following SQL workflow actions\n",
    "  - Source data declarations\n",
    "  - Tables and views\n",
    "  - Incremental tables\n",
    "  - Table partitions and clusters\n",
    "  - Dependencies between actions\n",
    "  - Documentation of tables\n",
    "  - Custom SQL operations\n",
    "  - BigQuery labels\n",
    "  - BigQuery policy tags\n",
    "  - Dataform tags\n",
    "  - Data quality tests, called assertions\n",
    "- Use JavaScript to reuse your Dataform SQL workflow code.\n",
    "  - Across a file with code encapsulation\n",
    "  - Across a repository with includes\n",
    "  - Across repositories with packages\n",
    "\n",
    "**3. Workflow compilation**\n",
    "\n",
    "**4. Workflow execution**\n",
    "\n",
    "- You can schedule Dataform executions in BigQuery in the following ways:\n",
    "  - Create workflow configurations to schedule executions of compilation results created in release configurations\n",
    "  - Schedule executions with Cloud Composer\n",
    "  - Schedule executions with Workflows and Cloud Scheduler\n",
    "\n",
    "- To debug errors, you can monitor executions in the following ways:\n",
    "  - View detailed Dataform execution logs\n",
    "  - View audit logs for Dataform\n",
    "  - View Cloud Logging logs for Dataform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terms\n",
    "\n",
    "1. **Release configuration**: let you configure how Dataform should compile the code of your repository. If your repository is connected to a remote git repository, you can create release configurations from different branches. Dataform will pull code from your remote git repository before compiling it\n",
    "2. **Workflow configurations**: let you schedule workflow executions\n",
    "3. **Development Workspace**: Is the same local development branch (git) in google cloud web workspace\n",
    "4. **Dataform core package**: Is the same python version when develop python programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Administer & Control Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Repository\n",
    "\n",
    "https://cloud.google.com/dataform/docs/create-repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to GIT repository\n",
    "\n",
    "https://cloud.google.com/dataform/docs/connect-repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config Dataform Settings \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `workflow_settings.yaml`\n",
    "Repository Workflow setting `workflow_settings.yaml` stores Dataform workflow settings in the `YAML` format.\n",
    "\n",
    "```yaml\n",
    "defaultProject: my-gcp-project-id             # BigQuery Google Cloud project ID\n",
    "defaultDataset: dataform                      # BigQuery dataset in which Dataform creates assets\n",
    "defaultLocation: asia-southeast1              # default BigQuery dataset region\n",
    "defaultAssertionDataset: dataform_assertions  # BigQuery dataset in which Dataform creates views with assertion results\n",
    "vars:\n",
    "  executionSetting: dev\n",
    "  environmentName: development\n",
    "```\n",
    "\n",
    "See all [configs reference for workflow settings](https://dataform-co.github.io/dataform/docs/configs-reference#workflowsettings)\n",
    "\n",
    "**Access the properties in Dataform code**\n",
    "from `workflow_settings.yaml` options to the code accessible `dataform.projectConfig` options apply:\n",
    "- `defaultProject` => `defaultDatabase`.\n",
    "- `defaultDataset` => `defaultSchema`.\n",
    "- `defaultAssertionDataset` => `assertionSchema`.\n",
    "- `projectSuffix` => `databaseSuffix`.\n",
    "- `datasetSuffix` => `schemaSuffix`.\n",
    "- `namePrefix` => `tablePrefix`.\n",
    "\n",
    "use clause:\n",
    "```SQL\n",
    "${when(dataform.projectConfig.vars.\"YOUR_VARIABLE\" === \"SET_VALUE\", \"CONDITION\", \"ELSE\")}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "  config { type: \"view\" }\n",
    "  SELECT ${when(\n",
    "    !dataform.projectConfig.tablePrefix,\n",
    "    \"table prefix is set!\",\n",
    "    \"table prefix is not set!\"\n",
    "  )}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "  select\n",
    "    *\n",
    "  from ${ref(\"data\")}\n",
    "  ${when(\n",
    "    dataform.projectConfig.vars.executionSetting === \"staging\",\n",
    "    \"where mod(farm_fingerprint(id) / 10) = 0\",\n",
    "  )}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage Core Packages\n",
    "\n",
    "- If **Only Dataform core package + No addition packages**: put `Dataform core package` in the `workflow_settings.yaml`\n",
    "\n",
    "```yaml\n",
    "dataformCoreVersion: \"3.0.0\"        # As a best practice, always use the latest available version of the Dataform core framework                \n",
    "defaultProject: my-gcp-project-id   # BigQuery Google Cloud project ID\n",
    "defaultDataset: dataform            # BigQuery dataset in which Dataform creates assets\n",
    "```\n",
    "- If  **Dataform core package + Addition packages**: put `Dataform core package` + `addition packages` in the `package.json`\n",
    "\n",
    " ```json\n",
    " {\n",
    "   \"name\": \"repository-name\",\n",
    "   \"dependencies\": {\n",
    "     \"@dataform/core\": \"3.0.0\",\n",
    "     \"dataform-scd\": \"https://github.com/dataform-co/dataform-scd/archive/0.3.tar.gz\"\n",
    "   }\n",
    " }\n",
    " ```\n",
    "   > remove `dataformCoreVersion` in `workflow_settings.yaml`\n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control Access\n",
    "\n",
    "https://cloud.google.com/dataform/docs/required-access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datafrom Core (SQLX)\n",
    "\n",
    "Dataform core for the following purposes:\n",
    "- Defining tables, views, materialized views, or incremental tables.\n",
    "- Defining data transformation logic.\n",
    "- Declaring source data and managing table dependencies.\n",
    "- Documenting table and column descriptions inside code.\n",
    "- Reusing functions and variables across different queries.\n",
    "- Writing data assertions to ensure data consistency.\n",
    "\n",
    ">You can compile and run Dataform core locally through the Dataform CLI outside of Google Cloud.\n",
    "\n",
    "A SQLX file consists of a **config block** and a **body**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config block\n",
    "\n",
    "In the config block, you can perform the following actions:\n",
    "- **Specify query metadata**: configure how Dataform materializes queries into BigQuery, for example the output table type, the target database, or labels using the config metadata.\n",
    "- **Document data**: document your tables and their fields directly\n",
    "- **Define data quality tests** (called `assertions`): check for uniqueness, null values, or a custom condition that run after table creation (also define assertions outside the config block, in a separate SQLX file.)\n",
    "> All config properties, and the config block itself, are optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config {\n",
    "  type: \"table\",\n",
    "    description: \"This table joins orders information from OnlineStore & payment information from PaymentApp\",\n",
    "  columns: {\n",
    "    order_date: \"The date when a customer placed their order\",\n",
    "    id: \"Order ID as defined by OnlineStore\",\n",
    "    order_status: \"The status of an order e.g. sent, delivered\",\n",
    "    customer_id: \"Unique customer ID\",\n",
    "    payment_status: \"The status of a payment e.g. pending, paid\",\n",
    "    payment_method: \"How the customer chose to pay\",\n",
    "    item_count: \"The number of items the customer ordered\",\n",
    "    amount: \"The amount the customer paid\"\n",
    "  },\n",
    "    assertions: {\n",
    "    uniqueKey: [\"id\"]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLX body\n",
    "\n",
    "following actions:\n",
    "- **Define a table and its dependencies**: use SQL `SELECT` statements and the `ref` function\n",
    "\n",
    "`ref` function use to **build a dependency tree of all the tables** to be created or updated, lets you **reference tables defined in project instead of hard coding** the schema and table name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config { type: \"table\" }\n",
    "\n",
    "SELECT\n",
    "  order_date AS date,\n",
    "  order_id AS order_id,\n",
    "  order_status AS order_status,\n",
    "  SUM(item_count) AS item_count,\n",
    "  SUM(amount) AS revenue\n",
    "\n",
    "FROM ${ref(\"store_clean\")}\n",
    "\n",
    "GROUP BY 1, 2, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After compilation, the SQL code is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE\n",
    "OR REPLACE TABLE Dataform.orders AS\n",
    "SELECT\n",
    "    order_date AS date,\n",
    "    order_id AS order_id,\n",
    "    order_status AS order_status,\n",
    "    SUM(item_count) AS item_count,\n",
    "    SUM(amount) AS revenue\n",
    "FROM\n",
    "    Dataform_stg.store_clean\n",
    "GROUP BY\n",
    "    1,\n",
    "    2,\n",
    "    3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Define additional SQL operations to run in BigQuery**: configure Dataform to execute one or more SQL statements before or after creating a table or view, you can [specify pre-query and post-query operations](https://cloud.google.com/dataform/docs/custom-sql).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM ...\n",
    "\n",
    "post_operations {\n",
    "  GRANT `roles/bigquery.dataViewer` ON TABLE ${self()} TO \"group:someusers@dataform.co\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Generate SQL code with JavaScript Block**: define reusable functions to generate repetitive parts of SQL code\n",
    "\n",
    "Note: Reuse code defined in a **JavaScript block only inside the SLQX file where the block is defined**. For global, to reuse code across your entire repository, you can create **includes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "js {\n",
    "  const columnName = \"foo\";\n",
    "}\n",
    "\n",
    "SELECT 1 AS ${columnName} FROM \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept of workspace\n",
    "\n",
    "**Compiled graph**\n",
    "\n",
    "Filter the graph by the following properties:\n",
    "- Name\n",
    "- Tag\n",
    "- Type\n",
    "    - Assertion\n",
    "    - Declaration\n",
    "    - Incremental Table\n",
    "    - Materialized view\n",
    "    - Operations\n",
    "    - Table\n",
    "    - Unknown\n",
    "    - View\n",
    "You can select multiple filters at once. Dataform will apply them with the `OR` condition.\n",
    "\n",
    "**Repository Structure**\n",
    "\n",
    "- `definitions/`: a directory for asset definitions, in Dataform core or JavaScript.\n",
    "- `includes/`: an empty directory for scripts and variables that you can reuse across the repository.\n",
    "- `workflow_settings.yaml`(`dataform.json` for early version 3.0.0): the default Dataform configuration file containing the Google Cloud project ID and BigQuery schema to publish assets in. You can override the default settings to customize them to your needs, but it's not a requirement to begin using Dataform.\n",
    "- `package.json`: the default Dataform dependencies configuration file with the latest version of @dataform/core. You can use this file to import packages.\n",
    "- `definitions/sample.sqlx`: a sample SQLX file to help you get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataform Tables\n",
    "\n",
    "https://cloud.google.com/dataform/docs/tables\n",
    "\n",
    "**1. type of table**\n",
    "- `table`: a regular table.\n",
    "- `incremental`: an incremental table  must include a `where` clause (updated table by insert new records by date)\n",
    "- `view`: a table view\n",
    "    - `materialized`: store underlying data under view (combine `table` and `view` --> increase performance and cost, but need to refresh continuously)\n",
    "\n",
    "> Other value of `type`: `operations`, `declaration`, `assertion`,...\n",
    "\n",
    "**2. [Partitions and clusters](https://cloud.google.com/dataform/docs/partitions-clusters)**\n",
    "\n",
    "**3. [Table/Field description](https://cloud.google.com/dataform/docs/document-tables)**\n",
    "\n",
    "**4. [Assertions](https://cloud.google.com/dataform/docs/assertions)**\n",
    "- Test and validate output table. Dataform runs assertions every time it updates your SQL workflow and alerts you if any assertions fail.\n",
    "\n",
    "**5. [Config additional table settings](https://cloud.google.com/dataform/docs/table-settings)**\n",
    "- Override default table settings, such as database or schema, and disable table creation, or execute a SQL statement before or after table creation\n",
    "\n",
    "**6. [Table labels](https://cloud.google.com/dataform/docs/labels)**\n",
    "\n",
    "**7. [Setting column-level access control](https://cloud.google.com/bigquery/docs/column-level-security-intro)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create table\n",
    "\n",
    "**1. `ref`** function: reference and automatically depend on the following objects defined in your Dataform SQL workflow instead of hard coding the schema and table names\n",
    "\n",
    "- ${ref(\"database\", \"schema\", \"name\")} : project_id.schema.name\n",
    "- ${ref(\"schema\", \"name\")} : default_project_id.schema.name\n",
    "- ${ref(\"name\")}: default_project_id.default_schema.name\n",
    "\n",
    "**2. `resolve`** : similar `ref` but not set the table as a dependency to this action \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workspace compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution & Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schedule Execution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
