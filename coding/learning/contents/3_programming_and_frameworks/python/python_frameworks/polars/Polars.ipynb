{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "**1. So sánh Pandas, Polars, PySpark, và Dask**\n",
    "\n",
    "| **Tiêu chí**              | **Pandas**                                         | **Polars**                                         | **PySpark**                                      | **Dask**                                       |\n",
    "|---------------------------|---------------------------------------------------|---------------------------------------------------|-------------------------------------------------|-----------------------------------------------|\n",
    "| **Hiệu năng**             | Trung bình (single-threaded).                     | Rất cao (Rust, multi-threaded).                  | Cao (phân tán trên nhiều cluster).             | Cao (đa luồng hoặc phân tán).                 |\n",
    "| **Kích thước dữ liệu**    | Giới hạn bởi bộ nhớ RAM.                          | Lớn (out-of-core và Apache Arrow).               | Rất lớn (phân tán trên nhiều node).            | Lớn (out-of-core, phân tán).                  |\n",
    "| **Lazy Evaluation**       | Không.                                            | Có (tối ưu hóa pipeline).                        | Có (nhưng chậm hơn Polars).                    | Có.                                           |\n",
    "| **Dễ sử dụng**            | Rất dễ (API quen thuộc với Python).               | Dễ (API tương tự Pandas).                        | Trung bình (cần hiểu rõ Spark API).            | Trung bình (API tương tự Pandas).            |\n",
    "| **Khả năng mở rộng**      | Hạn chế (thích hợp cho dữ liệu nhỏ).              | Tốt (Arrow, Parquet, ORC).                       | Rất cao (được thiết kế cho hệ thống lớn).      | Cao (hỗ trợ phân tán và dữ liệu lớn).         |\n",
    "| **Thời gian khởi chạy**   | Nhanh.                                            | Nhanh.                                           | Chậm (cần thiết lập SparkContext).             | Trung bình.                                   |\n",
    "| **Quản lý tài nguyên**    | Không hỗ trợ quản lý phân tán.                    | Không hỗ trợ quản lý phân tán.                   | Có (hỗ trợ cluster phân tán).                  | Có (quản lý song song, cluster nhỏ).          |\n",
    "| **Ngôn ngữ cốt lõi**      | Python.                                           | Rust.                                            | Scala/Java (API Python là giao diện).          | Python.                                       |\n",
    "| **Định dạng hỗ trợ**      | CSV, Excel, SQL, JSON.                            | CSV, Parquet, JSON, IPC, ORC.                    | CSV, Parquet, ORC, Avro, JSON.                 | CSV, Parquet, JSON, Zarr.                    |\n",
    "| **Xử lý song song**       | Không (single-threaded).                          | Có (tích hợp đa luồng).                          | Có (phân tán trên cluster).                    | Có (đa luồng hoặc phân tán).                  |\n",
    "| **Ưu điểm chính**         | Dễ dùng, phổ biến, nhiều tài liệu hỗ trợ.          | Rất nhanh, hỗ trợ lazy evaluation, tối ưu hóa.   | Tốt cho dữ liệu cực lớn và xử lý phân tán.      | Tốt cho dữ liệu lớn nhưng quen thuộc với Pandas. |\n",
    "| **Nhược điểm chính**      | Hiệu năng thấp với dữ liệu lớn.                   | Còn mới, tài liệu ít hơn Pandas.                 | Cần tài nguyên cluster, phức tạp hơn.          | Hiệu năng kém hơn Polars với dữ liệu nhỏ.     |\n",
    "| **Khi nào sử dụng?**      | Xử lý dữ liệu nhỏ và vừa, phân tích nhanh.         | Dữ liệu lớn, cần hiệu năng cao, xử lý nhanh.     | Dữ liệu cực lớn, xử lý phân tán trên cluster.   | Khi cần xử lý dữ liệu lớn và sử dụng API quen thuộc Pandas. |\n",
    "\n",
    "- **Pandas**: Lý tưởng cho xử lý dữ liệu nhỏ và vừa, dễ học, nhiều tài liệu hỗ trợ.\n",
    "- **Polars**: Phù hợp khi cần hiệu năng cao hoặc xử lý dữ liệu lớn nhanh chóng.\n",
    "- **PySpark**: Dành cho dữ liệu cực lớn, đòi hỏi xử lý phân tán trên cluster.\n",
    "- **Dask**: Là lựa chọn tốt nếu bạn cần xử lý dữ liệu lớn với cách tiếp cận quen thuộc từ Pandas.\n",
    "\n",
    "**2. Differences in concepts between Polars and pandas**\n",
    "\n",
    "**Polars không có multi-index/index**\n",
    "- pandas gắn nhãn cho mỗi hàng bằng “index”, trong khi Polars không dùng index mà đánh chỉ số các hàng bằng vị trí số nguyên.\n",
    "- Polars thiết kế để kết quả dễ dự đoán và câu lệnh dễ đọc, tránh sự phức tạp do “index” gây ra.\n",
    "\n",
    "**Polars sử dụng Apache Arrow thay vì NumPy arrays**\n",
    "- Polars lưu trữ dữ liệu theo chuẩn Apache Arrow, tối ưu hóa việc phân tích dữ liệu, tăng tốc độ tải, giảm bộ nhớ, và tính toán nhanh hơn. pandas sử dụng NumPy arrays.\n",
    "- Polars utilizes the Arrow Columnar Format for its data orientation\n",
    "\n",
    "**Polars hỗ trợ hoạt động song song tốt hơn pandas**\n",
    "- Polars khai thác khả năng xử lý đồng thời mạnh mẽ của Rust, cho phép nhiều hoạt động chạy song song. pandas chủ yếu hoạt động đơn luồng, cần thư viện bổ sung (như Dask) để chạy song song.\n",
    "\n",
    "**Polars có thể đánh giá lười biếng và tối ưu hóa câu truy vấn**\n",
    "- pandas chỉ hỗ trợ đánh giá tức thời (eager evaluation). Polars hỗ trợ cả đánh giá tức thời và đánh giá lười biếng (lazy evaluation).\n",
    "- Khi dùng lazy evaluation, Polars tối ưu hóa tự động các câu truy vấn, cải thiện tốc độ và giảm tiêu thụ bộ nhớ.\n",
    "\n",
    "**Sử dụng index như một kỹ thuật tối ưu hóa**\n",
    "- Polars có thể sử dụng cấu trúc dữ liệu “index” tương tự như cơ sở dữ liệu để tối ưu hóa, nhưng không dùng nó để quản lý dữ liệu như pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**3. Differences in Key syntax between Polars and pandas**\n",
    "\n",
    "Use the same syntax like pandas might be run, but it likely runs slower than it should. Then, it should be used by rewrite code syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.DataFrame({\"foo\": [1, 2, 3], \"bar\": [None, \"bak\", \"baz\"]})\n",
    "csv_file = \"docs/assets/data/path.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- selecting data in parallel optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns\n",
    "df.select(\"a\")\n",
    "\n",
    "# filter\n",
    "df.filter(pl.col(\"a\") < 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lazy model to optimize query by identify that only the relevant. By calling the `.collect` method at the end con **eagerly evaluate** the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lazy mode: scan_csv\n",
    "df = pl.scan_csv(csv_file)\n",
    "\n",
    "# eager mode: read_csv\n",
    "df = pl.read_csv(csv_file)\n",
    "grouped_df = df.group_by(\"id1\").agg(pl.col(\"v1\").sum()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Column assignment in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column assignment\n",
    "\n",
    "# in Pandas\n",
    "df.assign(\n",
    "    tenXValue=lambda df_: df_.value * 10,\n",
    "    hundredXValue=lambda df_: df_.value * 100,\n",
    ")\n",
    "\n",
    "# in Polars\n",
    "df.with_columns(\n",
    "    tenXValue=pl.col(\"value\") * 10,\n",
    "    hundredXValue=pl.col(\"value\") * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column assignment based on predicate\n",
    "\n",
    "# in Pandas\n",
    "df.assign(a=lambda df_: df_.a.where(df_.c != 2, df_.b))\n",
    "\n",
    "# in Polars: Polars compute every branch of an when -> then -> otherwise in parallel\n",
    "df.with_columns(\n",
    "    pl.when(pl.col(\"c\") == 2)  # when\n",
    "    .then(pl.col(\"b\"))  # then\n",
    "    .otherwise(pl.col(\"a\"))  # otherwise\n",
    "    .alias(\"a\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- filter in Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter((pl.col(\"m2_living\") > 2500) & (pl.col(\"price\") < 300000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dataframe transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"c\": [1, 1, 1, 2, 2, 2, 2],\n",
    "        \"type\": [\"m\", \"n\", \"o\", \"m\", \"m\", \"n\", \"n\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# in pandas\n",
    "df[\"size\"] = df.groupby(\"c\")[\"type\"].transform(len)\n",
    "\n",
    "# in polars\n",
    "df.with_columns(pl.col(\"type\").count().over(\"c\").alias(\"size\"))\n",
    "\n",
    "# multi\n",
    "df.with_columns(\n",
    "    pl.col(\"c\").count().over(\"c\").alias(\"size\"),\n",
    "    pl.col(\"c\").sum().over(\"type\").alias(\"sum\"),\n",
    "    pl.col(\"type\").reverse().over(\"c\").alias(\"reverse_type\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data type and structures\n",
    "\n",
    "### Data-types\n",
    "\n",
    "| **Category**     | **Datatype**            |\n",
    "|-------------------|-------------------------|\n",
    "| **Numeric**       | `Int8`, `Int16`, `Int32`, `Int64` (both negative and positive) |\n",
    "|                   | `UInt8`, `UInt16`, `UInt32`, `UInt64` (non-negative) |\n",
    "|                   | `Float32`, `Float64`     (need fast calculation by approximation)    |\n",
    "|                   | `Decimal` (need precision calculation)               | \n",
    "| **Nested**        | `List`                    | \n",
    "|                   | `Array`                   | \n",
    "|                   | `Struct`  (like `Dict`)                | \n",
    "| **Temporal**      | `Date`                    | \n",
    "|                   | `Time`                    | \n",
    "|                   | `Datetime`                | \n",
    "|                   | `Duration`                | \n",
    "| **Miscellaneous** | `Boolean`                 | \n",
    "|                   | `String` (UTF-8 encoded)  | \n",
    "|                   | `Binary`                  | \n",
    "|                   | `Categorical`  (inferred strings at runtime)          | \n",
    "|                   | `Enum` (Set predetermined strings)                   | \n",
    "|                   | `Object`                  | \n",
    "|                   | `Null`                    | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5,)\n",
      "Series: 'ints' [i64]\n",
      "[\n",
      "\t1\n",
      "\t2\n",
      "\t3\n",
      "\t4\n",
      "\t5\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "s1 = pl.Series(\"ints\", [1, 2, 3, 4, 5])\n",
    "s2 = pl.Series(\"uints\", [1, 2, 3, 4, 5], dtype=pl.UInt64)\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Int64, UInt64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(s1.dtype, s2.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 4)\n",
      "┌────────────────┬────────────┬────────┬────────┐\n",
      "│ name           ┆ birthdate  ┆ weight ┆ height │\n",
      "│ ---            ┆ ---        ┆ ---    ┆ ---    │\n",
      "│ str            ┆ date       ┆ f64    ┆ f64    │\n",
      "╞════════════════╪════════════╪════════╪════════╡\n",
      "│ Alice Archer   ┆ 1997-01-10 ┆ 57.9   ┆ 1.56   │\n",
      "│ Ben Brown      ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
      "│ Chloe Cooper   ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   │\n",
      "│ Daniel Donovan ┆ 1981-04-30 ┆ 83.1   ┆ 1.75   │\n",
      "└────────────────┴────────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"name\": [\n",
    "            \"Alice Archer\",\n",
    "            \"Ben Brown\",\n",
    "            \"Chloe Cooper\",\n",
    "            \"Daniel Donovan\",\n",
    "        ],\n",
    "        \"birthdate\": [\n",
    "            date(1997, 1, 10),\n",
    "            date(1985, 2, 15),\n",
    "            date(1983, 3, 22),\n",
    "            date(1981, 4, 30),\n",
    "        ],\n",
    "        \"weight\": [57.9, 72.5, 53.6, 83.1],  # (kg)\n",
    "        \"height\": [1.56, 1.77, 1.65, 1.75],  # (m)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>birthdate</th><th>weight</th><th>height</th></tr><tr><td>str</td><td>date</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Alice Archer&quot;</td><td>1997-01-10</td><td>57.9</td><td>1.56</td></tr><tr><td>&quot;Ben Brown&quot;</td><td>1985-02-15</td><td>72.5</td><td>1.77</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 4)\n",
       "┌──────────────┬────────────┬────────┬────────┐\n",
       "│ name         ┆ birthdate  ┆ weight ┆ height │\n",
       "│ ---          ┆ ---        ┆ ---    ┆ ---    │\n",
       "│ str          ┆ date       ┆ f64    ┆ f64    │\n",
       "╞══════════════╪════════════╪════════╪════════╡\n",
       "│ Alice Archer ┆ 1997-01-10 ┆ 57.9   ┆ 1.56   │\n",
       "│ Ben Brown    ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
       "└──────────────┴────────────┴────────┴────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>birthdate</th><th>weight</th><th>height</th></tr><tr><td>str</td><td>date</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Chloe Cooper&quot;</td><td>1983-03-22</td><td>53.6</td><td>1.65</td></tr><tr><td>&quot;Daniel Donovan&quot;</td><td>1981-04-30</td><td>83.1</td><td>1.75</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 4)\n",
       "┌────────────────┬────────────┬────────┬────────┐\n",
       "│ name           ┆ birthdate  ┆ weight ┆ height │\n",
       "│ ---            ┆ ---        ┆ ---    ┆ ---    │\n",
       "│ str            ┆ date       ┆ f64    ┆ f64    │\n",
       "╞════════════════╪════════════╪════════╪════════╡\n",
       "│ Chloe Cooper   ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   │\n",
       "│ Daniel Donovan ┆ 1981-04-30 ┆ 83.1   ┆ 1.75   │\n",
       "└────────────────┴────────────┴────────┴────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>birthdate</th><th>weight</th><th>height</th></tr><tr><td>str</td><td>date</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Chloe Cooper&quot;</td><td>1983-03-22</td><td>53.6</td><td>1.65</td></tr><tr><td>&quot;Ben Brown&quot;</td><td>1985-02-15</td><td>72.5</td><td>1.77</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 4)\n",
       "┌──────────────┬────────────┬────────┬────────┐\n",
       "│ name         ┆ birthdate  ┆ weight ┆ height │\n",
       "│ ---          ┆ ---        ┆ ---    ┆ ---    │\n",
       "│ str          ┆ date       ┆ f64    ┆ f64    │\n",
       "╞══════════════╪════════════╪════════╪════════╡\n",
       "│ Chloe Cooper ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   │\n",
       "│ Ben Brown    ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
       "└──────────────┴────────────┴────────┴────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 4\n",
      "Columns: 4\n",
      "$ name       <str> 'Alice Archer', 'Ben Brown', 'Chloe Cooper', 'Daniel Donovan'\n",
      "$ birthdate <date> 1997-01-10, 1985-02-15, 1983-03-22, 1981-04-30\n",
      "$ weight     <f64> 57.9, 72.5, 53.6, 83.1\n",
      "$ height     <f64> 1.56, 1.77, 1.65, 1.75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.glimpse(return_as_string=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (9, 5)\n",
      "┌────────────┬────────────────┬─────────────────────┬───────────┬──────────┐\n",
      "│ statistic  ┆ name           ┆ birthdate           ┆ weight    ┆ height   │\n",
      "│ ---        ┆ ---            ┆ ---                 ┆ ---       ┆ ---      │\n",
      "│ str        ┆ str            ┆ str                 ┆ f64       ┆ f64      │\n",
      "╞════════════╪════════════════╪═════════════════════╪═══════════╪══════════╡\n",
      "│ count      ┆ 4              ┆ 4                   ┆ 4.0       ┆ 4.0      │\n",
      "│ null_count ┆ 0              ┆ 0                   ┆ 0.0       ┆ 0.0      │\n",
      "│ mean       ┆ null           ┆ 1986-09-04 00:00:00 ┆ 66.775    ┆ 1.6825   │\n",
      "│ std        ┆ null           ┆ null                ┆ 13.560082 ┆ 0.097082 │\n",
      "│ min        ┆ Alice Archer   ┆ 1981-04-30          ┆ 53.6      ┆ 1.56     │\n",
      "│ 25%        ┆ null           ┆ 1983-03-22          ┆ 57.9      ┆ 1.65     │\n",
      "│ 50%        ┆ null           ┆ 1985-02-15          ┆ 72.5      ┆ 1.75     │\n",
      "│ 75%        ┆ null           ┆ 1985-02-15          ┆ 72.5      ┆ 1.75     │\n",
      "│ max        ┆ Daniel Donovan ┆ 1997-01-10          ┆ 83.1      ┆ 1.77     │\n",
      "└────────────┴────────────────┴─────────────────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "┌────────┬─────┐\n",
      "│ name   ┆ age │\n",
      "│ ---    ┆ --- │\n",
      "│ str    ┆ u8  │\n",
      "╞════════╪═════╡\n",
      "│ Alice  ┆ 27  │\n",
      "│ Ben    ┆ 39  │\n",
      "│ Chloe  ┆ 41  │\n",
      "│ Daniel ┆ 43  │\n",
      "└────────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "# set schema\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice\", \"Ben\", \"Chloe\", \"Daniel\"],\n",
    "        \"age\": [27, 39, 41, 43],\n",
    "    },\n",
    "    schema={\"name\": None, \"age\": pl.UInt8},\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "┌────────┬─────┐\n",
      "│ name   ┆ age │\n",
      "│ ---    ┆ --- │\n",
      "│ str    ┆ u16 │\n",
      "╞════════╪═════╡\n",
      "│ Alice  ┆ 27  │\n",
      "│ Ben    ┆ 39  │\n",
      "│ Chloe  ┆ 41  │\n",
      "│ Daniel ┆ 43  │\n",
      "└────────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "# override datatype in some of columns (not all columns)\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice\", \"Ben\", \"Chloe\", \"Daniel\"],\n",
    "        \"age\": [27, 39, 41, 43],\n",
    "    },\n",
    "    schema_overrides={\"age\": pl.UInt16},\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in eager mode (executed immediately)\n",
    "df = pl.read_csv(\"docs/assets/data/path.csv\")\n",
    "\n",
    "# lazy mode (prefer)\n",
    "df = pl.scan_csv(\"docs/assets/data/path.csv\")\n",
    "\n",
    "# write csv\n",
    "df.write_csv(\"docs/assets/data/path.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Excel files** : https://docs.pola.rs/user-guide/io/excel/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Multiple files strategy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If data in multiple file is the same schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in eager mode\n",
    "df = pl.read_csv(\"docs/assets/data/my_many_files_*.csv\")\n",
    "\n",
    "# lazy mode (prefer)\n",
    "df = pl.scan_csv(\"docs/assets/data/my_many_files_*.csv\")\n",
    "df.show_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If data in multiple file is not in 1 table, but do same task (parallel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "queries = []\n",
    "for file in glob.glob(\"docs/assets/data/my_many_files_*.csv\"):\n",
    "    q = pl.scan_csv(file).group_by(\"bar\").agg(pl.len(), pl.sum(\"foo\"))\n",
    "    queries.append(q)\n",
    "\n",
    "dataframes = pl.collect_all(queries)\n",
    "print(dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet (prefer than CSV)\n",
    "\n",
    "Polars is optimize to load and write `parquet` file format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in eager mode (executed immediately)\n",
    "df = pl.read_parquet(\"docs/assets/data/path.parquet\")\n",
    "\n",
    "# lazy mode (prefer)\n",
    "df = pl.scan_parquet(\"docs/assets/data/path.parquet\")\n",
    "\n",
    "# write csv\n",
    "df.write_parquet(\"docs/assets/data/path.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we scan a Parquet file stored in the cloud, we can also apply predicate and projection pushdowns. This can significantly reduce the amount of data that needs to be downloaded. For scanning a Parquet file in the cloud, see Cloud storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hive partitioned data\n",
    "\n",
    "https://docs.pola.rs/user-guide/io/hive/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For READ hive partitioned data:**\n",
    "```\n",
    "┌───────────────────────────────────────────────────────┐\n",
    "│ File path                                             │\n",
    "╞═══════════════════════════════════════════════════════╡\n",
    "│ docs/assets/data/hive/year=2023/month=11/data.parquet │\n",
    "│ docs/assets/data/hive/year=2023/month=12/data.parquet │\n",
    "│ docs/assets/data/hive/year=2024/month=01/data.parquet │\n",
    "│ docs/assets/data/hive/year=2024/month=02/data.parquet │\n",
    "└───────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.scan_parquet(\"docs/assets/data/hive/\").collect()\n",
    "\n",
    "with pl.Config(tbl_rows=99):\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For READ Handling mixed files:**\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│ File path                                                   │\n",
    "╞═════════════════════════════════════════════════════════════╡\n",
    "│ docs/assets/data/hive_mixed/description.txt                 │\n",
    "│ docs/assets/data/hive_mixed/year=2023/month=11/data.parquet │\n",
    "│ docs/assets/data/hive_mixed/year=2023/month=12/data.parquet │\n",
    "│ docs/assets/data/hive_mixed/year=2024/month=01/data.parquet │\n",
    "│ docs/assets/data/hive_mixed/year=2024/month=02/data.parquet │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.scan_parquet(\n",
    "    \"docs/assets/data/hive_mixed/**/*.parquet\", hive_partitioning=True\n",
    ").collect()\n",
    "\n",
    "with pl.Config(tbl_rows=99):\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For READ specific hive files:**\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│ File path                                                   │\n",
    "╞═════════════════════════════════════════════════════════════╡\n",
    "│ docs/assets/data/hive_mixed/description.txt                 │\n",
    "│ docs/assets/data/hive_mixed/year=2023/month=11/data.parquet │\n",
    "│ docs/assets/data/hive_mixed/year=2023/month=12/data.parquet │\n",
    "│ docs/assets/data/hive_mixed/year=2024/month=01/data.parquet │\n",
    "│ docs/assets/data/hive_mixed/year=2024/month=02/data.parquet │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.scan_parquet(\n",
    "    [\n",
    "        \"docs/assets/data/hive/year=2024/month=01/data.parquet\",\n",
    "        \"docs/assets/data/hive/year=2024/month=02/data.parquet\",\n",
    "    ],\n",
    "    hive_partitioning=True,\n",
    ").collect()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For WRITE to hive files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌─────┬─────┬─────┐\n",
      "│ a   ┆ b   ┆ c   │\n",
      "│ --- ┆ --- ┆ --- │\n",
      "│ i64 ┆ i64 ┆ i32 │\n",
      "╞═════╪═════╪═════╡\n",
      "│ 1   ┆ 1   ┆ 1   │\n",
      "│ 1   ┆ 1   ┆ 1   │\n",
      "│ 2   ┆ 1   ┆ 1   │\n",
      "│ 2   ┆ 2   ┆ 1   │\n",
      "│ 3   ┆ 2   ┆ 1   │\n",
      "└─────┴─────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame({\"a\": [1, 1, 2, 2, 3], \"b\": [1, 1, 1, 2, 2], \"c\": 1})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partitioned by the columns a and b\n",
    "df.write_parquet(\"docs/assets/data/hive_write/\", partition_by=[\"a\", \"b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output following paths:\n",
    "```\n",
    "┌──────────────────────────────────────────────────────┐\n",
    "│ File path                                            │\n",
    "╞══════════════════════════════════════════════════════╡\n",
    "│ docs/assets/data/hive_write/a=1/b=1/00000000.parquet │\n",
    "│ docs/assets/data/hive_write/a=2/b=1/00000000.parquet │\n",
    "│ docs/assets/data/hive_write/a=2/b=2/00000000.parquet │\n",
    "│ docs/assets/data/hive_write/a=3/b=2/00000000.parquet │\n",
    "└──────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in eager mode (executed immediately)\n",
    "df = pl.read_json(\"docs/assets/data/path.json\")\n",
    "\n",
    "# read Newline Delimited JSON\n",
    "df = pl.read_ndjson(\"docs/assets/data/path.json\")\n",
    "\n",
    "# lazy mode (prefer - only Newline Delimited JSON)\n",
    "df = pl.scan_ndjson(\"docs/assets/data/path.csv\")\n",
    "\n",
    "# write csv\n",
    "df.write_json(\"docs/assets/data/path.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database\n",
    "\n",
    "detail: https://docs.pola.rs/user-guide/io/database/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engine\n",
    "\n",
    "Polars xử lý data theo cơ chế **column-wise Apache Arrow format** nên một số engine có thể bị chậm do phải load data row-wise vào Python trước khi copying data lại vào the column-wise Apache Arrow format\n",
    "- row-wise engine: **SQLAlchemy** or **DBAPI2** connection\n",
    "- column-wise engine: [ConnectorX](https://github.com/sfu-db/connector-x) or [ADBC](https://arrow.apache.org/docs/format/ADBC.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read\n",
    "\n",
    "`read_database_uri` faster than `read_database` for **SQLAlchemy** or **DBAPI2** connection if you are using a SQLAlchemy or DBAPI2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "via **URI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# via URI\n",
    "uri = \"postgresql://username:password@server:port/database\"\n",
    "query = \"SELECT * FROM foo\"\n",
    "\n",
    "pl.read_database_uri(query=query, uri=uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "via **connection engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# via connection engine\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "conn = create_engine(\"sqlite:///test.db\")\n",
    "# conn = sqlite3.connect(\"test.db\")\n",
    "\n",
    "query = \"SELECT * FROM foo\"\n",
    "\n",
    "pl.read_database(query=query, connection=conn.connect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write\n",
    "support engine:\n",
    "- SQLAlchemy\n",
    "- Arrow Database Connectivity (ADBC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"postgresql://username:password@server:port/database\"\n",
    "df = pl.DataFrame({\"foo\": [1, 2, 3]})\n",
    "\n",
    "df.write_database(table_name=\"records\", connection=uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"postgresql://username:password@server:port/database\"\n",
    "df = pl.DataFrame({\"foo\": [1, 2, 3]})\n",
    "\n",
    "df.write_database(table_name=\"records\", connection=uri, engine=\"adbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud Storage\n",
    "\n",
    "- **Service**: `AWS S3`, `Azure Blob Storage`, `Google Cloud Storage`\n",
    "\n",
    "- **File-format**: `Parquet`, `CSV`, `IPC`, `NDJSON`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Authen cloud](https://docs.pola.rs/user-guide/io/cloud-storage/#cloud-authentication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "source = \"s3://bucket/*.parquet\"\n",
    "\n",
    "storage_options = {\n",
    "    \"aws_access_key_id\": \"<secret>\",\n",
    "    \"aws_secret_access_key\": \"<secret>\",\n",
    "    \"aws_region\": \"us-east-1\",\n",
    "}\n",
    "df = pl.scan_parquet(source, storage_options=storage_options).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read\n",
    "\n",
    "Using `pl.scan_*` functions to read from cloud storage can benefit from [predicate and projection pushdowns](https://docs.pola.rs/user-guide/lazy/optimizations/), where the query optimizer will apply them before the file is downloaded. This can significantly reduce the amount of data that needs to be downloaded. The query evaluation is triggered by calling `collect`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"s3://bucket/*.parquet\"\n",
    "\n",
    "# Read file\n",
    "df = pl.read_parquet(source)\n",
    "\n",
    "# Scanning (query optimization)\n",
    "df = (\n",
    "    pl.scan_parquet(source)\n",
    "    .filter(pl.col(\"id\") < 100)\n",
    "    .select(\"id\", \"value\")\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write\n",
    "using: \n",
    "- `s3fs` for **S3**, \n",
    "- `adlfs` for **Azure Blob Storage**\n",
    "- `gcsfs` for **Google Cloud Storage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import s3fs\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"foo\": [\"a\", \"b\", \"c\", \"d\", \"d\"],\n",
    "        \"bar\": [1, 2, 3, 4, 5],\n",
    "    }\n",
    ")\n",
    "\n",
    "fs = s3fs.S3FileSystem()\n",
    "destination = \"s3://bucket/my_file.parquet\"\n",
    "\n",
    "# write parquet\n",
    "with fs.open(destination, mode=\"wb\") as f:\n",
    "    df.write_parquet(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Perform a query.\n",
    "QUERY = (\n",
    "    \"SELECT name FROM `bigquery-public-data.usa_names.usa_1910_2013` \"\n",
    "    'WHERE state = \"TX\" '\n",
    "    \"LIMIT 100\"\n",
    ")\n",
    "query_job = client.query(QUERY)  # API request\n",
    "rows = query_job.result()  # Waits for query to finish\n",
    "\n",
    "df = pl.from_arrow(rows.to_arrow())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import io\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Write DataFrame to stream as parquet file; does not hit disk\n",
    "with io.BytesIO() as stream:\n",
    "    df.write_parquet(stream)\n",
    "    stream.seek(0)\n",
    "    job = client.load_table_from_file(\n",
    "        stream,\n",
    "        destination=\"tablename\",\n",
    "        project=\"projectname\",\n",
    "        job_config=bigquery.LoadJobConfig(\n",
    "            source_format=bigquery.SourceFormat.PARQUET,\n",
    "        ),\n",
    "    )\n",
    "job.result()  # Waits for the job to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face\n",
    "https://docs.pola.rs/user-guide/io/hugging-face/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 4)\n",
      "┌────────────────┬────────────┬────────┬────────┐\n",
      "│ name           ┆ birthdate  ┆ weight ┆ height │\n",
      "│ ---            ┆ ---        ┆ ---    ┆ ---    │\n",
      "│ str            ┆ date       ┆ f64    ┆ f64    │\n",
      "╞════════════════╪════════════╪════════╪════════╡\n",
      "│ Alice Archer   ┆ 1997-01-10 ┆ 57.9   ┆ 1.56   │\n",
      "│ Ben Brown      ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
      "│ Chloe Cooper   ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   │\n",
      "│ Daniel Donovan ┆ 1981-04-30 ┆ 83.1   ┆ 1.75   │\n",
      "└────────────────┴────────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from datetime import date\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"name\": [\n",
    "            \"Alice Archer\",\n",
    "            \"Ben Brown\",\n",
    "            \"Chloe Cooper\",\n",
    "            \"Daniel Donovan\",\n",
    "        ],\n",
    "        \"birthdate\": [\n",
    "            date(1997, 1, 10),\n",
    "            date(1985, 2, 15),\n",
    "            date(1983, 3, 22),\n",
    "            date(1981, 4, 30),\n",
    "        ],\n",
    "        \"weight\": [57.9, 72.5, 53.6, 83.1],  # (kg)\n",
    "        \"height\": [1.56, 1.77, 1.65, 1.75],  # (m)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(col(\"weight\")) / (col(\"height\").pow([dyn int: 2]))]\n"
     ]
    }
   ],
   "source": [
    "bmi_expr = pl.col(\"weight\") / (pl.col(\"height\") ** 2)\n",
    "print(bmi_expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `bmi_expr` just is an expressions with lazy, no computations have taken place yet. That's what we need contexts for by `select`, `with_columns`, `filter`, `group_by`, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select and create\n",
    "\n",
    "**`select`**\n",
    "\n",
    "Select column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "┌────────┬────────────────┐\n",
      "│ weight ┆ name           │\n",
      "│ ---    ┆ ---            │\n",
      "│ f64    ┆ str            │\n",
      "╞════════╪════════════════╡\n",
      "│ 57.9   ┆ Alice Archer   │\n",
      "│ 72.5   ┆ Ben Brown      │\n",
      "│ 53.6   ┆ Chloe Cooper   │\n",
      "│ 83.1   ┆ Daniel Donovan │\n",
      "└────────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "subdf = df.select(pl.col(\"weight\"), pl.col(\"name\"))\n",
    "print(subdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf2 = df.select([\"weight\", \"name\"])\n",
    "subdf2.equals(subdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>weight</th></tr><tr><td>f64</td></tr></thead><tbody><tr><td>57.9</td></tr><tr><td>72.5</td></tr><tr><td>53.6</td></tr><tr><td>83.1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 1)\n",
       "┌────────┐\n",
       "│ weight │\n",
       "│ ---    │\n",
       "│ f64    │\n",
       "╞════════╡\n",
       "│ 57.9   │\n",
       "│ 72.5   │\n",
       "│ 53.6   │\n",
       "│ 83.1   │\n",
       "└────────┘"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "produce new columns / series that are ***aggregations***, ***combinations*** of other `columns`, or `literals` and same lenght with df or must be a scalar:\n",
    "  - Scalars will be broadcast to match the length of the remaining series\n",
    "  - Literals, like the number used above, are also broadcast\n",
    "  - Broadcasting can also occur within expressions\n",
    "\n",
    "> `select` only includes the columns selected by its input expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 4)\n",
      "┌───────────┬───────────┬───────────────┬───────────┐\n",
      "│ bmi       ┆ avg_bmi   ┆ ideal_max_bmi ┆ deviation │\n",
      "│ ---       ┆ ---       ┆ ---           ┆ ---       │\n",
      "│ f64       ┆ f64       ┆ i32           ┆ f64       │\n",
      "╞═══════════╪═══════════╪═══════════════╪═══════════╡\n",
      "│ 23.791913 ┆ 23.438973 ┆ 25            ┆ 0.115645  │\n",
      "│ 23.141498 ┆ 23.438973 ┆ 25            ┆ -0.097471 │\n",
      "│ 19.687787 ┆ 23.438973 ┆ 25            ┆ -1.22912  │\n",
      "│ 27.134694 ┆ 23.438973 ┆ 25            ┆ 1.210946  │\n",
      "└───────────┴───────────┴───────────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\n",
    "    bmi=bmi_expr,\n",
    "    avg_bmi=bmi_expr.mean(),\n",
    "    ideal_max_bmi=25,\n",
    "    deviation=(bmi_expr - bmi_expr.mean()) / bmi_expr.std(),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### by datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "┌────────┬────────┐\n",
      "│ weight ┆ height │\n",
      "│ ---    ┆ ---    │\n",
      "│ f64    ┆ f64    │\n",
      "╞════════╪════════╡\n",
      "│ 57.9   ┆ 1.56   │\n",
      "│ 72.5   ┆ 1.77   │\n",
      "│ 53.6   ┆ 1.65   │\n",
      "│ 83.1   ┆ 1.75   │\n",
      "└────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "float_df = df.select(pl.col(pl.Float64))\n",
    "print(float_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### by pattern matching in columns name\n",
    "\n",
    "- `^` : start\n",
    "- `$` : end \n",
    "- `*` : multi-characters\n",
    "- `.` : single-character\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "┌────────┬────────┐\n",
      "│ weight ┆ height │\n",
      "│ ---    ┆ ---    │\n",
      "│ f64    ┆ f64    │\n",
      "╞════════╪════════╡\n",
      "│ 57.9   ┆ 1.56   │\n",
      "│ 72.5   ┆ 1.77   │\n",
      "│ 53.6   ┆ 1.65   │\n",
      "│ 83.1   ┆ 1.75   │\n",
      "└────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\"^*ght$\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 4)\n",
      "┌────────────────┬────────────┬────────┬────────┐\n",
      "│ name           ┆ birthdate  ┆ weight ┆ height │\n",
      "│ ---            ┆ ---        ┆ ---    ┆ ---    │\n",
      "│ str            ┆ date       ┆ f64    ┆ f64    │\n",
      "╞════════════════╪════════════╪════════╪════════╡\n",
      "│ Alice Archer   ┆ 1997-01-10 ┆ 57.9   ┆ 1.56   │\n",
      "│ Ben Brown      ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
      "│ Chloe Cooper   ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   │\n",
      "│ Daniel Donovan ┆ 1981-04-30 ┆ 83.1   ┆ 1.75   │\n",
      "└────────────────┴────────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(pl.all())\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### exclude columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "┌────────────────┬────────────┐\n",
      "│ name           ┆ birthdate  │\n",
      "│ ---            ┆ ---        │\n",
      "│ str            ┆ date       │\n",
      "╞════════════════╪════════════╡\n",
      "│ Alice Archer   ┆ 1997-01-10 │\n",
      "│ Ben Brown      ┆ 1985-02-15 │\n",
      "│ Chloe Cooper   ┆ 1983-03-22 │\n",
      "│ Daniel Donovan ┆ 1981-04-30 │\n",
      "└────────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(pl.all().exclude(\"^*ght$\"))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`with_columns`**\n",
    "\n",
    "very similar to the context `select`, but `with_columns` creates a new dataframe that contains the columns from the original dataframe and the new columns according to its input expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 8)\n",
      "┌───────────────┬────────────┬────────┬────────┬───────────┬───────────┬───────────────┬───────────┐\n",
      "│ name          ┆ birthdate  ┆ weight ┆ height ┆ bmi       ┆ avg_bmi   ┆ ideal_max_bmi ┆ deviation │\n",
      "│ ---           ┆ ---        ┆ ---    ┆ ---    ┆ ---       ┆ ---       ┆ ---           ┆ ---       │\n",
      "│ str           ┆ date       ┆ f64    ┆ f64    ┆ f64       ┆ f64       ┆ i32           ┆ f64       │\n",
      "╞═══════════════╪════════════╪════════╪════════╪═══════════╪═══════════╪═══════════════╪═══════════╡\n",
      "│ Alice Archer  ┆ 1997-01-10 ┆ 57.9   ┆ 1.56   ┆ 23.791913 ┆ 23.438973 ┆ 25            ┆ 0.115645  │\n",
      "│ Ben Brown     ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   ┆ 23.141498 ┆ 23.438973 ┆ 25            ┆ -0.097471 │\n",
      "│ Chloe Cooper  ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   ┆ 19.687787 ┆ 23.438973 ┆ 25            ┆ -1.22912  │\n",
      "│ Daniel        ┆ 1981-04-30 ┆ 83.1   ┆ 1.75   ┆ 27.134694 ┆ 23.438973 ┆ 25            ┆ 1.210946  │\n",
      "│ Donovan       ┆            ┆        ┆        ┆           ┆           ┆               ┆           │\n",
      "└───────────────┴────────────┴────────┴────────┴───────────┴───────────┴───────────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.with_columns(\n",
    "    bmi=bmi_expr,\n",
    "    avg_bmi=bmi_expr.mean(),\n",
    "    ideal_max_bmi=25,\n",
    "    deviation=(bmi_expr - bmi_expr.mean()) / bmi_expr.std(),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create column by group by expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌───────┬───────┬────────────┐\n",
      "│ group ┆ value ┆ group_mean │\n",
      "│ ---   ┆ ---   ┆ ---        │\n",
      "│ str   ┆ i64   ┆ f64        │\n",
      "╞═══════╪═══════╪════════════╡\n",
      "│ A     ┆ 10    ┆ 15.0       │\n",
      "│ A     ┆ 20    ┆ 15.0       │\n",
      "│ B     ┆ 15    ┆ 25.0       │\n",
      "│ B     ┆ 25    ┆ 25.0       │\n",
      "│ B     ┆ 35    ┆ 25.0       │\n",
      "└───────┴───────┴────────────┘\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"group\": [\"A\", \"A\", \"B\", \"B\", \"B\"],\n",
    "        \"value\": [10, 20, 15, 25, 35],\n",
    "    }\n",
    ")\n",
    "\n",
    "result = df.with_columns(\n",
    "    pl.col(\"value\").mean().over(\"group\").alias(\"group_mean\")\n",
    ")\n",
    "\n",
    "# Group by \"group\" and calculate group-wise mean\n",
    "group_mean = df.group_by(\"group\").agg(\n",
    "    pl.col(\"value\").mean().alias(\"group_mean\")\n",
    ")\n",
    "\n",
    "# Join the group mean back to the original DataFrame\n",
    "result2 = df.join(group_mean, on=\"group\")\n",
    "\n",
    "print(result2)\n",
    "print(result.equals(result2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`alias`**\n",
    "\n",
    "set name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n",
      "┌───────────┬───────────┬───────────┐\n",
      "│ bmi       ┆ avg_bmi   ┆ deviation │\n",
      "│ ---       ┆ ---       ┆ ---       │\n",
      "│ f64       ┆ f64       ┆ f64       │\n",
      "╞═══════════╪═══════════╪═══════════╡\n",
      "│ 23.791913 ┆ 23.438973 ┆ 0.115645  │\n",
      "│ 23.141498 ┆ 23.438973 ┆ -0.097471 │\n",
      "│ 19.687787 ┆ 23.438973 ┆ -1.22912  │\n",
      "│ 27.134694 ┆ 23.438973 ┆ 1.210946  │\n",
      "└───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\n",
    "    bmi_expr.alias(\"bmi\"),\n",
    "    bmi_expr.mean().alias(\"avg_bmi\"),\n",
    "    ((bmi_expr - bmi_expr.mean()) / bmi_expr.std()).alias(\"deviation\"),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### prefixing and suffixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n",
      "┌────────────────────┬────────────────────┬────────────────┐\n",
      "│ 10_multiple_weight ┆ 10_multiple_height ┆ birthdate_year │\n",
      "│ ---                ┆ ---                ┆ ---            │\n",
      "│ f64                ┆ f64                ┆ i32            │\n",
      "╞════════════════════╪════════════════════╪════════════════╡\n",
      "│ 579.0              ┆ 15.6               ┆ 1997           │\n",
      "│ 725.0              ┆ 17.7               ┆ 1985           │\n",
      "│ 536.0              ┆ 16.5               ┆ 1983           │\n",
      "│ 831.0              ┆ 17.5               ┆ 1981           │\n",
      "└────────────────────┴────────────────────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\n",
    "    (pl.col(\"^*ight$\") * 10).name.prefix(\"10_multiple_\"),\n",
    "    (pl.col(\"birthdate\").dt.year()).name.suffix(\"_year\"),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 4)\n",
      "┌────────────────┬────────────┬────────┬────────┐\n",
      "│ NAME           ┆ BIRTHDATE  ┆ WEIGHT ┆ HEIGHT │\n",
      "│ ---            ┆ ---        ┆ ---    ┆ ---    │\n",
      "│ str            ┆ date       ┆ f64    ┆ f64    │\n",
      "╞════════════════╪════════════╪════════╪════════╡\n",
      "│ Alice Archer   ┆ 1997-01-10 ┆ 57.9   ┆ 1.56   │\n",
      "│ Ben Brown      ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
      "│ Chloe Cooper   ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   │\n",
      "│ Daniel Donovan ┆ 1981-04-30 ┆ 83.1   ┆ 1.75   │\n",
      "└────────────────┴────────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# There is also `.name.to_uppercase`, so this usage of `.map` is moot.\n",
    "result = df.select(pl.all().name.map(str.upper))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter\n",
    "\n",
    "**`filter`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 4)\n",
      "┌───────────┬────────────┬────────┬────────┐\n",
      "│ name      ┆ birthdate  ┆ weight ┆ height │\n",
      "│ ---       ┆ ---        ┆ ---    ┆ ---    │\n",
      "│ str       ┆ date       ┆ f64    ┆ f64    │\n",
      "╞═══════════╪════════════╪════════╪════════╡\n",
      "│ Ben Brown ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
      "└───────────┴────────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.filter(\n",
    "    pl.col(\"birthdate\").is_between(date(1982, 12, 31), date(1996, 1, 1)),\n",
    "    pl.col(\"height\") > 1.7,\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌──────┬───────┬──────────┬────────┐\n",
      "│ nrs  ┆ names ┆ random   ┆ groups │\n",
      "│ ---  ┆ ---   ┆ ---      ┆ ---    │\n",
      "│ i64  ┆ str   ┆ f64      ┆ str    │\n",
      "╞══════╪═══════╪══════════╪════════╡\n",
      "│ 1    ┆ foo   ┆ 0.37454  ┆ A      │\n",
      "│ 2    ┆ ham   ┆ 0.950714 ┆ A      │\n",
      "│ 3    ┆ spam  ┆ 0.731994 ┆ B      │\n",
      "│ null ┆ egg   ┆ 0.598658 ┆ A      │\n",
      "│ 5    ┆ spam  ┆ 0.156019 ┆ B      │\n",
      "└──────┴───────┴──────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)  # For reproducibility.\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"nrs\": [1, 2, 3, None, 5],\n",
    "        \"names\": [\"foo\", \"ham\", \"spam\", \"egg\", \"spam\"],\n",
    "        \"random\": np.random.rand(5),\n",
    "        \"groups\": [\"A\", \"A\", \"B\", \"A\", \"B\"],\n",
    "    }\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 6)\n",
      "┌─────────┬──────────┬─────────────┬──────────────┬──────────┬──────────┐\n",
      "│ nrs > 1 ┆ nrs >= 3 ┆ random < .2 ┆ random <= .5 ┆ nrs != 1 ┆ nrs == 1 │\n",
      "│ ---     ┆ ---      ┆ ---         ┆ ---          ┆ ---      ┆ ---      │\n",
      "│ bool    ┆ bool     ┆ bool        ┆ bool         ┆ bool     ┆ bool     │\n",
      "╞═════════╪══════════╪═════════════╪══════════════╪══════════╪══════════╡\n",
      "│ false   ┆ false    ┆ false       ┆ true         ┆ false    ┆ true     │\n",
      "│ true    ┆ false    ┆ false       ┆ false        ┆ true     ┆ false    │\n",
      "│ true    ┆ true     ┆ false       ┆ false        ┆ true     ┆ false    │\n",
      "│ null    ┆ null     ┆ false       ┆ false        ┆ null     ┆ null     │\n",
      "│ true    ┆ true     ┆ true        ┆ true         ┆ true     ┆ false    │\n",
      "└─────────┴──────────┴─────────────┴──────────────┴──────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\n",
    "    (pl.col(\"nrs\") > 1).alias(\"nrs > 1\"),  # .gt\n",
    "    (pl.col(\"nrs\") >= 3).alias(\"nrs >= 3\"),  # ge\n",
    "    (pl.col(\"random\") < 0.2).alias(\"random < .2\"),  # .lt\n",
    "    (pl.col(\"random\") <= 0.5).alias(\"random <= .5\"),  # .le\n",
    "    (pl.col(\"nrs\") != 1).alias(\"nrs != 1\"),  # .ne\n",
    "    (pl.col(\"nrs\") == 1).alias(\"nrs == 1\"),  # .eq\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the operators `&`, `|`, and `~`, for the Boolean operations “and”, “or”, and “not”, respectively, or the functions of the same name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌─────────────────────────────┬─────────────────────────┬─────────────┐\n",
      "│ number not null and group A ┆ random < 0.5 or group B ┆ group not B │\n",
      "│ ---                         ┆ ---                     ┆ ---         │\n",
      "│ bool                        ┆ bool                    ┆ bool        │\n",
      "╞═════════════════════════════╪═════════════════════════╪═════════════╡\n",
      "│ true                        ┆ true                    ┆ true        │\n",
      "│ true                        ┆ false                   ┆ true        │\n",
      "│ false                       ┆ true                    ┆ false       │\n",
      "│ false                       ┆ false                   ┆ true        │\n",
      "│ false                       ┆ true                    ┆ false       │\n",
      "└─────────────────────────────┴─────────────────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Boolean operators & | ~\n",
    "result = df.select(\n",
    "    ((~pl.col(\"nrs\").is_null()) & (pl.col(\"groups\") == \"A\")).alias(\n",
    "        \"number not null and group A\"\n",
    "    ),\n",
    "    ((pl.col(\"random\") < 0.5) | (pl.col(\"groups\") == \"B\")).alias(\n",
    "        \"random < 0.5 or group B\"\n",
    "    ),\n",
    "    (pl.col(\"groups\") != \"B\").alias(\"group not B\"),\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Corresponding named functions `and_`, `or_`, and `not_`.\n",
    "result2 = df.select(\n",
    "    (pl.col(\"nrs\").is_null().not_().and_(pl.col(\"groups\") == \"A\")).alias(\n",
    "        \"number not null and group A\"\n",
    "    ),\n",
    "    ((pl.col(\"random\") < 0.5).or_(pl.col(\"groups\") == \"B\")).alias(\n",
    "        \"random < 0.5 or group B\"\n",
    "    ),\n",
    ")\n",
    "print(result.equals(result2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `n_unique`: exact number but may be slow for large dataset\n",
    "- `approx_n_unique`: approximation by uses the algorithm [HyperLogLog++](https://en.wikipedia.org/wiki/HyperLogLog) to estimate the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 2)\n",
      "┌──────────┬─────────────────┐\n",
      "│ n_unique ┆ approx_n_unique │\n",
      "│ ---      ┆ ---             │\n",
      "│ u32      ┆ u32             │\n",
      "╞══════════╪═════════════════╡\n",
      "│ 63218    ┆ 63784           │\n",
      "└──────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "long_df = pl.DataFrame({\"numbers\": np.random.randint(0, 100_000, 100_000)})\n",
    "\n",
    "result = long_df.select(\n",
    "    pl.col(\"numbers\").n_unique().alias(\"n_unique\"),\n",
    "    pl.col(\"numbers\").approx_n_unique().alias(\"approx_n_unique\"),\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `value_counts`: unique values and their counts as `structs` datatype\n",
    "- `unique`: return only unique value\n",
    "- `unique_counts`: return only unique value count (need `unique(maintain_order=True)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n",
      "┌──────────────┬────────┬───────────────┐\n",
      "│ value_counts ┆ unique ┆ unique_counts │\n",
      "│ ---          ┆ ---    ┆ ---           │\n",
      "│ struct[2]    ┆ str    ┆ u32           │\n",
      "╞══════════════╪════════╪═══════════════╡\n",
      "│ {\"spam\",2}   ┆ foo    ┆ 1             │\n",
      "│ {\"foo\",1}    ┆ ham    ┆ 1             │\n",
      "│ {\"ham\",1}    ┆ spam   ┆ 2             │\n",
      "│ {\"egg\",1}    ┆ egg    ┆ 1             │\n",
      "└──────────────┴────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select()\n",
    "\n",
    "result = df.select(\n",
    "    pl.col(\"names\").value_counts(sort=True).alias(\"value_counts\"),\n",
    "    pl.col(\"names\").unique(maintain_order=True).alias(\"unique\"),\n",
    "    pl.col(\"names\").unique_counts().alias(\"unique_counts\"),\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional (when - then - else)\n",
    "- `when`: accept predicate expression (True/False seri)\n",
    "- `then`: corresponding values of the expression inside if when = `True`\n",
    "- `otherwise`: corresponding values of the expression inside if when = `False`, or `null` if not provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌──────┬─────────┐\n",
      "│ nrs  ┆ Collatz │\n",
      "│ ---  ┆ ---     │\n",
      "│ i64  ┆ i64     │\n",
      "╞══════╪═════════╡\n",
      "│ 1    ┆ 2       │\n",
      "│ 2    ┆ 8       │\n",
      "│ 3    ┆ 27      │\n",
      "│ null ┆ 9999    │\n",
      "│ 5    ┆ 125     │\n",
      "└──────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\n",
    "    pl.col(\"nrs\"),\n",
    "    pl.when(pl.col(\"nrs\") == 1)\n",
    "    .then(pl.col(\"nrs\") + 1)\n",
    "    .otherwise(\n",
    "        pl.when(pl.col(\"nrs\").is_null())\n",
    "        .then(9999)\n",
    "        .otherwise(pl.col(\"nrs\") ** 3)\n",
    "    )\n",
    "    .alias(\"Collatz\"),\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expression expansion\n",
    "\n",
    "a shorthand notation for when you want to apply the same transformation to multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌────────┬───────────────────┬────────┬──────────┬─────────┬───────────┬──────────┐\n",
      "│ ticker ┆ company_name      ┆ price  ┆ day_high ┆ day_low ┆ year_high ┆ year_low │\n",
      "│ ---    ┆ ---               ┆ ---    ┆ ---      ┆ ---     ┆ ---       ┆ ---      │\n",
      "│ str    ┆ str               ┆ f64    ┆ f64      ┆ f64     ┆ f64       ┆ f64      │\n",
      "╞════════╪═══════════════════╪════════╪══════════╪═════════╪═══════════╪══════════╡\n",
      "│ AAPL   ┆ Apple             ┆ 229.9  ┆ 231.31   ┆ 228.6   ┆ 237.23    ┆ 164.08   │\n",
      "│ NVDA   ┆ NVIDIA            ┆ 138.93 ┆ 139.6    ┆ 136.3   ┆ 140.76    ┆ 39.23    │\n",
      "│ MSFT   ┆ Microsoft         ┆ 420.56 ┆ 424.04   ┆ 417.52  ┆ 468.35    ┆ 324.39   │\n",
      "│ GOOG   ┆ Alphabet (Google) ┆ 166.41 ┆ 167.62   ┆ 164.78  ┆ 193.31    ┆ 121.46   │\n",
      "│ AMZN   ┆ Amazon            ┆ 188.4  ┆ 189.83   ┆ 188.44  ┆ 201.2     ┆ 118.35   │\n",
      "└────────┴───────────────────┴────────┴──────────┴─────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {  # As of 14th October 2024, ~3pm UTC\n",
    "        \"ticker\": [\"AAPL\", \"NVDA\", \"MSFT\", \"GOOG\", \"AMZN\"],\n",
    "        \"company_name\": [\n",
    "            \"Apple\",\n",
    "            \"NVIDIA\",\n",
    "            \"Microsoft\",\n",
    "            \"Alphabet (Google)\",\n",
    "            \"Amazon\",\n",
    "        ],\n",
    "        \"price\": [229.9, 138.93, 420.56, 166.41, 188.4],\n",
    "        \"day_high\": [231.31, 139.6, 424.04, 167.62, 189.83],\n",
    "        \"day_low\": [228.6, 136.3, 417.52, 164.78, 188.44],\n",
    "        \"year_high\": [237.23, 140.76, 468.35, 193.31, 201.2],\n",
    "        \"year_low\": [164.08, 39.23, 324.39, 121.46, 118.35],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example: compute the mean value of the columns “price” and “year_high” and will rename them as “avg_year_high” and “avg_year_high”, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>avg_price</th><th>avg_year_high</th></tr><tr><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>228.84</td><td>248.17</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 2)\n",
       "┌───────────┬───────────────┐\n",
       "│ avg_price ┆ avg_year_high │\n",
       "│ ---       ┆ ---           │\n",
       "│ f64       ┆ f64           │\n",
       "╞═══════════╪═══════════════╡\n",
       "│ 228.84    ┆ 248.17        │\n",
       "└───────────┴───────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# instead of\n",
    "[\n",
    "    pl.col(\"price\").mean().alias(\"avg_price\"),\n",
    "    pl.col(\"year_high\").mean().alias(\"avg_year_high\"),\n",
    "]\n",
    "\n",
    "# using\n",
    "expr = pl.col(\"price\", \"year_high\").mean().name.prefix(\"avg_\")\n",
    "df.select(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 5)\n",
      "┌───────────┬──────────────┬─────────────┬───────────────┬──────────────┐\n",
      "│ price*1.1 ┆ day_high*1.1 ┆ day_low*1.1 ┆ year_high*1.1 ┆ year_low*1.1 │\n",
      "│ ---       ┆ ---          ┆ ---         ┆ ---           ┆ ---          │\n",
      "│ f64       ┆ f64          ┆ f64         ┆ f64           ┆ f64          │\n",
      "╞═══════════╪══════════════╪═════════════╪═══════════════╪══════════════╡\n",
      "│ 252.89    ┆ 254.441      ┆ 251.46      ┆ 260.953       ┆ 180.488      │\n",
      "│ 152.823   ┆ 153.56       ┆ 149.93      ┆ 154.836       ┆ 43.153       │\n",
      "│ 462.616   ┆ 466.444      ┆ 459.272     ┆ 515.185       ┆ 356.829      │\n",
      "│ 183.051   ┆ 184.382      ┆ 181.258     ┆ 212.641       ┆ 133.606      │\n",
      "│ 207.24    ┆ 208.813      ┆ 207.284     ┆ 221.32        ┆ 130.185      │\n",
      "└───────────┴──────────────┴─────────────┴───────────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# multiply all columns with data type Float64 by 1.1\n",
    "expr = (pl.col(pl.Float64) * 1.1).name.suffix(\"*1.1\")\n",
    "result = df.select(expr)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How to select columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### by columns name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌────────┬───────────────────┬───────┬──────────┬─────────┬───────────┬──────────┐\n",
      "│ ticker ┆ company_name      ┆ price ┆ day_high ┆ day_low ┆ year_high ┆ year_low │\n",
      "│ ---    ┆ ---               ┆ ---   ┆ ---      ┆ ---     ┆ ---       ┆ ---      │\n",
      "│ str    ┆ str               ┆ f64   ┆ f64      ┆ f64     ┆ f64       ┆ f64      │\n",
      "╞════════╪═══════════════════╪═══════╪══════════╪═════════╪═══════════╪══════════╡\n",
      "│ AAPL   ┆ Apple             ┆ 191.6 ┆ 192.8    ┆ 190.5   ┆ 197.7     ┆ 136.7    │\n",
      "│ NVDA   ┆ NVIDIA            ┆ 115.8 ┆ 116.3    ┆ 113.6   ┆ 117.3     ┆ 32.7     │\n",
      "│ MSFT   ┆ Microsoft         ┆ 350.5 ┆ 353.4    ┆ 347.9   ┆ 390.3     ┆ 270.3    │\n",
      "│ GOOG   ┆ Alphabet (Google) ┆ 138.7 ┆ 139.7    ┆ 137.3   ┆ 161.1     ┆ 101.2    │\n",
      "│ AMZN   ┆ Amazon            ┆ 157.0 ┆ 158.2    ┆ 157.0   ┆ 167.7     ┆ 98.6     │\n",
      "└────────┴───────────────────┴───────┴──────────┴─────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "eur_usd_rate = 1.2\n",
    "\n",
    "result = df.with_columns(\n",
    "    (\n",
    "        pl.col(\n",
    "            \"price\",\n",
    "            \"day_high\",\n",
    "            \"day_low\",\n",
    "            \"year_high\",\n",
    "            \"year_low\",\n",
    "        )\n",
    "        / eur_usd_rate\n",
    "    ).round(1)\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### by datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌────────┬───────────────────┬────────┬──────────┬─────────┬───────────┬──────────┐\n",
      "│ ticker ┆ company_name      ┆ price  ┆ day_high ┆ day_low ┆ year_high ┆ year_low │\n",
      "│ ---    ┆ ---               ┆ ---    ┆ ---      ┆ ---     ┆ ---       ┆ ---      │\n",
      "│ str    ┆ str               ┆ f64    ┆ f64      ┆ f64     ┆ f64       ┆ f64      │\n",
      "╞════════╪═══════════════════╪════════╪══════════╪═════════╪═══════════╪══════════╡\n",
      "│ AAPL   ┆ Apple             ┆ 191.58 ┆ 192.76   ┆ 190.5   ┆ 197.69    ┆ 136.73   │\n",
      "│ NVDA   ┆ NVIDIA            ┆ 115.78 ┆ 116.33   ┆ 113.58  ┆ 117.3     ┆ 32.69    │\n",
      "│ MSFT   ┆ Microsoft         ┆ 350.47 ┆ 353.37   ┆ 347.93  ┆ 390.29    ┆ 270.33   │\n",
      "│ GOOG   ┆ Alphabet (Google) ┆ 138.68 ┆ 139.68   ┆ 137.32  ┆ 161.09    ┆ 101.22   │\n",
      "│ AMZN   ┆ Amazon            ┆ 157.0  ┆ 158.19   ┆ 157.03  ┆ 167.67    ┆ 98.63    │\n",
      "└────────┴───────────────────┴────────┴──────────┴─────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "result2 = df.with_columns(\n",
    "    (\n",
    "        pl.col(\n",
    "            pl.Float32,\n",
    "            pl.Float64,\n",
    "        )\n",
    "        / eur_usd_rate\n",
    "    ).round(2)\n",
    ")\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### by pattern matching in columns name\n",
    "\n",
    "- `^` : start\n",
    "- `$` : end \n",
    "- `*` : multi-characters\n",
    "- `.` : single-character\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 5)\n",
      "┌────────┬──────────┬───────────┬─────────┬──────────┐\n",
      "│ ticker ┆ day_high ┆ year_high ┆ day_low ┆ year_low │\n",
      "│ ---    ┆ ---      ┆ ---       ┆ ---     ┆ ---      │\n",
      "│ str    ┆ f64      ┆ f64       ┆ f64     ┆ f64      │\n",
      "╞════════╪══════════╪═══════════╪═════════╪══════════╡\n",
      "│ AAPL   ┆ 231.31   ┆ 237.23    ┆ 228.6   ┆ 164.08   │\n",
      "│ NVDA   ┆ 139.6    ┆ 140.76    ┆ 136.3   ┆ 39.23    │\n",
      "│ MSFT   ┆ 424.04   ┆ 468.35    ┆ 417.52  ┆ 324.39   │\n",
      "│ GOOG   ┆ 167.62   ┆ 193.31    ┆ 164.78  ┆ 121.46   │\n",
      "│ AMZN   ┆ 189.83   ┆ 201.2     ┆ 188.44  ┆ 118.35   │\n",
      "└────────┴──────────┴───────────┴─────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(pl.col(\"ticker\", \"^.*_high$\", \"^.*_low$\"))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate expressions\n",
    "\n",
    "Instead of `Way 1`, should do by `Way 2` to:\n",
    "- do a better job at optimising the query\n",
    "- parallelise the execution of the actual computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 9)\n",
      "┌────────┬──────────────┬────────┬──────────┬───┬───────────┬──────────┬─────────────┬─────────────┐\n",
      "│ ticker ┆ company_name ┆ price  ┆ day_high ┆ … ┆ year_high ┆ year_low ┆ day_amplitu ┆ year_amplit │\n",
      "│ ---    ┆ ---          ┆ ---    ┆ ---      ┆   ┆ ---       ┆ ---      ┆ de          ┆ ude         │\n",
      "│ str    ┆ str          ┆ f64    ┆ f64      ┆   ┆ f64       ┆ f64      ┆ ---         ┆ ---         │\n",
      "│        ┆              ┆        ┆          ┆   ┆           ┆          ┆ f64         ┆ f64         │\n",
      "╞════════╪══════════════╪════════╪══════════╪═══╪═══════════╪══════════╪═════════════╪═════════════╡\n",
      "│ AAPL   ┆ Apple        ┆ 229.9  ┆ 231.31   ┆ … ┆ 237.23    ┆ 164.08   ┆ 2.71        ┆ 73.15       │\n",
      "│ NVDA   ┆ NVIDIA       ┆ 138.93 ┆ 139.6    ┆ … ┆ 140.76    ┆ 39.23    ┆ 3.3         ┆ 101.53      │\n",
      "│ MSFT   ┆ Microsoft    ┆ 420.56 ┆ 424.04   ┆ … ┆ 468.35    ┆ 324.39   ┆ 6.52        ┆ 143.96      │\n",
      "│ GOOG   ┆ Alphabet     ┆ 166.41 ┆ 167.62   ┆ … ┆ 193.31    ┆ 121.46   ┆ 2.84        ┆ 71.85       │\n",
      "│        ┆ (Google)     ┆        ┆          ┆   ┆           ┆          ┆             ┆             │\n",
      "│ AMZN   ┆ Amazon       ┆ 188.4  ┆ 189.83   ┆ … ┆ 201.2     ┆ 118.35   ┆ 1.39        ┆ 82.85       │\n",
      "└────────┴──────────────┴────────┴──────────┴───┴───────────┴──────────┴─────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Way 1:\n",
    "result = df\n",
    "for tp in [\"day\", \"year\"]:\n",
    "    result = result.with_columns(\n",
    "        (pl.col(f\"{tp}_high\") - pl.col(f\"{tp}_low\")).alias(f\"{tp}_amplitude\")\n",
    "    )\n",
    "\n",
    "\n",
    "# Way 2 (should do):\n",
    "def amplitude_expressions(time_periods):\n",
    "    for tp in time_periods:\n",
    "        yield (pl.col(f\"{tp}_high\") - pl.col(f\"{tp}_low\")).alias(\n",
    "            f\"{tp}_amplitude\"\n",
    "        )\n",
    "\n",
    "\n",
    "result = df.with_columns(amplitude_expressions([\"day\", \"year\"]))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatype Operations\n",
    "\n",
    "Full link: https://docs.pola.rs/api/python/stable/reference/datatypes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌────────┬───────────────────┬────────┬──────────┬─────────┬───────────┬──────────┐\n",
      "│ ticker ┆ company_name      ┆ price  ┆ day_high ┆ day_low ┆ year_high ┆ year_low │\n",
      "│ ---    ┆ ---               ┆ ---    ┆ ---      ┆ ---     ┆ ---       ┆ ---      │\n",
      "│ str    ┆ str               ┆ f64    ┆ i64      ┆ i64     ┆ i64       ┆ i64      │\n",
      "╞════════╪═══════════════════╪════════╪══════════╪═════════╪═══════════╪══════════╡\n",
      "│ AAPL   ┆ Apple             ┆ 229.9  ┆ 231      ┆ 228     ┆ 237       ┆ 164      │\n",
      "│ NVDA   ┆ NVIDIA            ┆ 138.93 ┆ 139      ┆ 136     ┆ 140       ┆ 39       │\n",
      "│ MSFT   ┆ Microsoft         ┆ 420.56 ┆ 424      ┆ 417     ┆ 468       ┆ 324      │\n",
      "│ GOOG   ┆ Alphabet (Google) ┆ 166.41 ┆ 167      ┆ 164     ┆ 193       ┆ 121      │\n",
      "│ AMZN   ┆ Amazon            ┆ 188.4  ┆ 189      ┆ 188     ┆ 201       ┆ 118      │\n",
      "└────────┴───────────────────┴────────┴──────────┴─────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {  # As of 14th October 2024, ~3pm UTC\n",
    "        \"ticker\": [\"AAPL\", \"NVDA\", \"MSFT\", \"GOOG\", \"AMZN\"],\n",
    "        \"company_name\": [\n",
    "            \"Apple\",\n",
    "            \"NVIDIA\",\n",
    "            \"Microsoft\",\n",
    "            \"Alphabet (Google)\",\n",
    "            \"Amazon\",\n",
    "        ],\n",
    "        \"price\": [229.9, 138.93, 420.56, 166.41, 188.4],\n",
    "        \"day_high\": [231, 139, 424, 167, 189],\n",
    "        \"day_low\": [228, 136, 417, 164, 188],\n",
    "        \"year_high\": [237, 140, 468, 193, 201],\n",
    "        \"year_low\": [164, 39, 324, 121, 118],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Casting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `cast`\n",
    " - `strict` that determines how Polars behaves when it encounters a value that cannot be converted from the source data type to the target data type\n",
    "   - `strict=True`: raise if error\n",
    "   - `strict=False`: `null` if error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌──────────────────────────┬─────────────────────────────┐\n",
      "│ price_integers_as_floats ┆ day_high_floats_as_integers │\n",
      "│ ---                      ┆ ---                         │\n",
      "│ f32                      ┆ i32                         │\n",
      "╞══════════════════════════╪═════════════════════════════╡\n",
      "│ 229.899994               ┆ 231                         │\n",
      "│ 138.929993               ┆ 139                         │\n",
      "│ 420.559998               ┆ 424                         │\n",
      "│ 166.410004               ┆ 167                         │\n",
      "│ 188.399994               ┆ 189                         │\n",
      "└──────────────────────────┴─────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\n",
    "    pl.col(\"price\").cast(pl.Float32).name.suffix(\"_integers_as_floats\"),\n",
    "    pl.col(\"day_high\").cast(pl.Int32).name.suffix(\"_floats_as_integers\"),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### downcasting numerical\n",
    "\n",
    "Reduce the memory footprint of a column by changing the precision associated with its numeric data type:\n",
    "- `Int64` --> `Int16` \n",
    "- `Float64` --> `Float32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before downcasting: 263 bytes\n",
      "After downcasting: 229 bytes\n",
      "shape: (5, 8)\n",
      "┌────────┬────────────────┬────────────┬──────────┬─────────┬───────────┬──────────┬───────────────┐\n",
      "│ ticker ┆ company_name   ┆ price      ┆ day_high ┆ day_low ┆ year_high ┆ year_low ┆ year_low_conv │\n",
      "│ ---    ┆ ---            ┆ ---        ┆ ---      ┆ ---     ┆ ---       ┆ ---      ┆ ert_with_stri │\n",
      "│ str    ┆ str            ┆ f32        ┆ i32      ┆ i64     ┆ i64       ┆ i64      ┆ ct            │\n",
      "│        ┆                ┆            ┆          ┆         ┆           ┆          ┆ ---           │\n",
      "│        ┆                ┆            ┆          ┆         ┆           ┆          ┆ i8            │\n",
      "╞════════╪════════════════╪════════════╪══════════╪═════════╪═══════════╪══════════╪═══════════════╡\n",
      "│ AAPL   ┆ Apple          ┆ 229.899994 ┆ 231      ┆ 228     ┆ 237       ┆ 164      ┆ null          │\n",
      "│ NVDA   ┆ NVIDIA         ┆ 138.929993 ┆ 139      ┆ 136     ┆ 140       ┆ 39       ┆ 39            │\n",
      "│ MSFT   ┆ Microsoft      ┆ 420.559998 ┆ 424      ┆ 417     ┆ 468       ┆ 324      ┆ null          │\n",
      "│ GOOG   ┆ Alphabet       ┆ 166.410004 ┆ 167      ┆ 164     ┆ 193       ┆ 121      ┆ 121           │\n",
      "│        ┆ (Google)       ┆            ┆          ┆         ┆           ┆          ┆               │\n",
      "│ AMZN   ┆ Amazon         ┆ 188.399994 ┆ 189      ┆ 188     ┆ 201       ┆ 118      ┆ 118           │\n",
      "└────────┴────────────────┴────────────┴──────────┴─────────┴───────────┴──────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before downcasting: {df.estimated_size()} bytes\")\n",
    "result = df.with_columns(\n",
    "    pl.col(\"price\").cast(pl.Float32),\n",
    "    pl.col(\"day_high\").cast(pl.Int32),\n",
    "    pl.col(\"year_low\")\n",
    "    .cast(pl.Int8, strict=False)\n",
    "    .alias(\"year_low_convert_with_strict\"),\n",
    ")\n",
    "print(f\"After downcasting: {result.estimated_size()} bytes\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### strings to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 3)\n",
      "┌─────────────────────┬───────────────────┬────────┐\n",
      "│ integers_as_strings ┆ floats_as_strings ┆ floats │\n",
      "│ ---                 ┆ ---               ┆ ---    │\n",
      "│ i32                 ┆ f64               ┆ str    │\n",
      "╞═════════════════════╪═══════════════════╪════════╡\n",
      "│ 1                   ┆ 4.0               ┆ 4.0    │\n",
      "│ 2                   ┆ 5.8               ┆ 5.8    │\n",
      "│ 3                   ┆ -6.3              ┆ -6.3   │\n",
      "└─────────────────────┴───────────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"integers_as_strings\": [\"1\", \"2\", \"3\"],\n",
    "        \"floats_as_strings\": [\"4.0\", \"5.8\", \"-6.3\"],\n",
    "        \"floats\": [4.0, 5.8, -6.3],\n",
    "    }\n",
    ")\n",
    "\n",
    "result = df.select(\n",
    "    pl.col(\"integers_as_strings\").cast(pl.Int32),\n",
    "    pl.col(\"floats_as_strings\").cast(pl.Float64),\n",
    "    pl.col(\"floats\").cast(pl.String),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"integers\": [-1, 0, 2, 3, 4],\n",
    "        \"floats\": [0.0, 1.0, 2.0, 3.0, 4.0],\n",
    "        \"bools\": [True, False, True, False, True],\n",
    "    }\n",
    ")\n",
    "\n",
    "result = df.select(\n",
    "    pl.col(\"integers\").cast(pl.Boolean),\n",
    "    pl.col(\"floats\").cast(pl.Boolean),\n",
    "    pl.col(\"bools\").cast(pl.Int8),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number\n",
    "\n",
    "https://docs.pola.rs/api/python/stable/reference/expressions/computation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌─────────┬─────────┬─────────┬──────────────┬──────────────┬──────────┬─────────┐\n",
      "│ raw_nrs ┆ nrs + 5 ┆ nrs - 5 ┆ nrs * random ┆ nrs / random ┆ nrs ** 2 ┆ nrs % 3 │\n",
      "│ ---     ┆ ---     ┆ ---     ┆ ---          ┆ ---          ┆ ---      ┆ ---     │\n",
      "│ i64     ┆ i64     ┆ i64     ┆ f64          ┆ f64          ┆ i64      ┆ i64     │\n",
      "╞═════════╪═════════╪═════════╪══════════════╪══════════════╪══════════╪═════════╡\n",
      "│ 1       ┆ 6       ┆ -4      ┆ 0.37454      ┆ 2.669941     ┆ 1        ┆ 1       │\n",
      "│ 2       ┆ 7       ┆ -3      ┆ 1.901429     ┆ 2.103681     ┆ 4        ┆ 2       │\n",
      "│ 3       ┆ 8       ┆ -2      ┆ 2.195982     ┆ 4.098395     ┆ 9        ┆ 0       │\n",
      "│ null    ┆ null    ┆ null    ┆ null         ┆ null         ┆ null     ┆ null    │\n",
      "│ 5       ┆ 10      ┆ 0       ┆ 0.780093     ┆ 32.047453    ┆ 25       ┆ 2       │\n",
      "└─────────┴─────────┴─────────┴──────────────┴──────────────┴──────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\n",
    "    pl.col(\"nrs\").alias(\"raw_nrs\"),\n",
    "    (pl.col(\"nrs\") + 5).alias(\"nrs + 5\"),\n",
    "    (pl.col(\"nrs\") - 5).alias(\"nrs - 5\"),\n",
    "    (pl.col(\"nrs\") * pl.col(\"random\")).alias(\"nrs * random\"),\n",
    "    (pl.col(\"nrs\") / pl.col(\"random\")).alias(\"nrs / random\"),\n",
    "    (pl.col(\"nrs\") ** 2).alias(\"nrs ** 2\"),\n",
    "    (pl.col(\"nrs\") % 3).alias(\"nrs % 3\"),\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use **named functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Python only:\n",
    "result_named_operators = df.select(\n",
    "    pl.col(\"nrs\").alias(\"raw_nrs\"),\n",
    "    (pl.col(\"nrs\").add(5)).alias(\"nrs + 5\"),\n",
    "    (pl.col(\"nrs\").sub(5)).alias(\"nrs - 5\"),\n",
    "    (pl.col(\"nrs\").mul(pl.col(\"random\"))).alias(\"nrs * random\"),\n",
    "    (pl.col(\"nrs\").truediv(pl.col(\"random\"))).alias(\"nrs / random\"),\n",
    "    (pl.col(\"nrs\").pow(2)).alias(\"nrs ** 2\"),\n",
    "    (pl.col(\"nrs\").mod(3)).alias(\"nrs % 3\"),\n",
    ")\n",
    "\n",
    "print(result.equals(result_named_operators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datetime\n",
    "\n",
    "https://docs.pola.rs/api/python/stable/reference/expressions/temporal.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date</th><th>end_date</th><th>string</th><th>date_to_str</th><th>str_to_date</th><th>str_to_datetime</th><th>year_of_date</th><th>after_10_bdays</th><th>days_delta</th></tr><tr><td>date</td><td>date</td><td>str</td><td>str</td><td>date</td><td>datetime[μs]</td><td>i32</td><td>date</td><td>i64</td></tr></thead><tbody><tr><td>2022-02-01</td><td>2022-03-04</td><td>&quot;2022-01-01&quot;</td><td>&quot;2022-02-01&quot;</td><td>2022-01-01</td><td>2022-01-01 00:00:00</td><td>2022</td><td>2022-02-15</td><td>31</td></tr><tr><td>2022-01-05</td><td>2022-04-02</td><td>&quot;2022-01-02&quot;</td><td>&quot;2022-01-05&quot;</td><td>2022-01-02</td><td>2022-01-02 00:00:00</td><td>2022</td><td>2022-01-19</td><td>87</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 9)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ date      ┆ end_date  ┆ string    ┆ date_to_s ┆ … ┆ str_to_da ┆ year_of_d ┆ after_10_ ┆ days_del │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ tr        ┆   ┆ tetime    ┆ ate       ┆ bdays     ┆ ta       │\n",
       "│ date      ┆ date      ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆ datetime[ ┆ i32       ┆ date      ┆ i64      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ μs]       ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 2022-02-0 ┆ 2022-03-0 ┆ 2022-01-0 ┆ 2022-02-0 ┆ … ┆ 2022-01-0 ┆ 2022      ┆ 2022-02-1 ┆ 31       │\n",
       "│ 1         ┆ 4         ┆ 1         ┆ 1         ┆   ┆ 1         ┆           ┆ 5         ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 00:00:00  ┆           ┆           ┆          │\n",
       "│ 2022-01-0 ┆ 2022-04-0 ┆ 2022-01-0 ┆ 2022-01-0 ┆ … ┆ 2022-01-0 ┆ 2022      ┆ 2022-01-1 ┆ 87       │\n",
       "│ 5         ┆ 2         ┆ 2         ┆ 5         ┆   ┆ 2         ┆           ┆ 9         ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 00:00:00  ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date, datetime, time\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"date\": [date(2022, 2, 1), date(2022, 1, 5)],\n",
    "        \"end_date\": [date(2022, 3, 4), date(2022, 4, 2)],\n",
    "        \"string\": [\"2022-01-01\", \"2022-01-02\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "result = df.with_columns(\n",
    "    date_to_str=pl.col(\"date\").dt.to_string(\"%Y-%m-%d\"),\n",
    "    str_to_date=pl.col(\"string\").str.to_date(\"%Y-%m-%d\"),\n",
    "    str_to_datetime=pl.col(\"string\").str.to_datetime(\"%Y-%m-%d\"),\n",
    "    year_of_date=pl.col(\"date\").dt.year(),\n",
    "    after_10_bdays=pl.col(\"date\").dt.add_business_days(10),\n",
    "    days_delta=(pl.col(\"end_date\") - pl.col(\"date\")).dt.total_days(),\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String\n",
    "\n",
    "https://docs.pola.rs/api/python/stable/reference/expressions/string.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"language\": [\"English\", \"Dutch\", \"Portuguese\", \"Finish\"],\n",
    "        \"fruit\": [\"pear\", \"peer\", \"pêra\", \"päärynä\"],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**len and size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 4)\n",
      "┌────────────┬─────────┬────────────┬──────────────┐\n",
      "│ language   ┆ fruit   ┆ byte_count ┆ letter_count │\n",
      "│ ---        ┆ ---     ┆ ---        ┆ ---          │\n",
      "│ str        ┆ str     ┆ u32        ┆ u32          │\n",
      "╞════════════╪═════════╪════════════╪══════════════╡\n",
      "│ English    ┆ pear    ┆ 4          ┆ 4            │\n",
      "│ Dutch      ┆ peer    ┆ 4          ┆ 4            │\n",
      "│ Portuguese ┆ pêra    ┆ 5          ┆ 4            │\n",
      "│ Finish     ┆ päärynä ┆ 10         ┆ 7            │\n",
      "└────────────┴─────────┴────────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# len and size\n",
    "result = df.with_columns(\n",
    "    pl.col(\"fruit\").str.len_bytes().alias(\"byte_count\"),\n",
    "    pl.col(\"fruit\").str.len_chars().alias(\"letter_count\"),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parsing strings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 5)\n",
      "┌─────────┬───────────────┬───────┬───────┬─────────────┐\n",
      "│ fruit   ┆ starts_with_p ┆ p..r  ┆ e+    ┆ ends_with_r │\n",
      "│ ---     ┆ ---           ┆ ---   ┆ ---   ┆ ---         │\n",
      "│ str     ┆ bool          ┆ bool  ┆ bool  ┆ bool        │\n",
      "╞═════════╪═══════════════╪═══════╪═══════╪═════════════╡\n",
      "│ pear    ┆ true          ┆ true  ┆ true  ┆ true        │\n",
      "│ peer    ┆ true          ┆ true  ┆ true  ┆ true        │\n",
      "│ pêra    ┆ true          ┆ false ┆ false ┆ false       │\n",
      "│ päärynä ┆ true          ┆ true  ┆ false ┆ false       │\n",
      "└─────────┴───────────────┴───────┴───────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\n",
    "    pl.col(\"fruit\"),\n",
    "    pl.col(\"fruit\").str.starts_with(\"p\").alias(\"starts_with_p\"),\n",
    "    pl.col(\"fruit\").str.contains(\"p..r\").alias(\"p..r\"),\n",
    "    pl.col(\"fruit\").str.contains(\"e+\").alias(\"e+\"),\n",
    "    pl.col(\"fruit\").str.ends_with(\"r\").alias(\"ends_with_r\"),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 1)\n",
      "┌─────────┐\n",
      "│ urls    │\n",
      "│ ---     │\n",
      "│ str     │\n",
      "╞═════════╡\n",
      "│ messi   │\n",
      "│ null    │\n",
      "│ ronaldo │\n",
      "└─────────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"urls\": [\n",
    "            \"http://vote.com/ballon_dor?candidate=messi&ref=polars\",\n",
    "            \"http://vote.com/ballon_dor?candidat=jorginho&ref=polars\",\n",
    "            \"http://vote.com/ballon_dor?candidate=ronaldo&ref=polars\",\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "result = df.select(\n",
    "    pl.col(\"urls\").str.extract(r\"candidate=(\\w+)\", group_index=1),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "┌────────┬──────────────────┐\n",
      "│ text   ┆ text_replace_all │\n",
      "│ ---    ┆ ---              │\n",
      "│ str    ┆ str              │\n",
      "╞════════╪══════════════════╡\n",
      "│ -23abc ┆ ---abc           │\n",
      "│ abc-56 ┆ abc---           │\n",
      "└────────┴──────────────────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame({\"text\": [\"123abc\", \"abc456\"]})\n",
    "result = df.with_columns(\n",
    "    pl.col(\"text\").str.replace(r\"\\d\", \"-\"),\n",
    "    pl.col(\"text\").str.replace_all(r\"\\d\", \"-\").alias(\"text_replace_all\"),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>originals</th><th>addresses</th><th>lower</th><th>upper</th><th>strip</th><th>end</th><th>start</th><th>prefix</th><th>suffix</th><th>3_characters_begin</th><th>3_characters_end</th><th>from_2_with_len_4</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;128 PERF st&quot;</td><td>&quot;128 Perf St&quot;</td><td>&quot;128 perf st&quot;</td><td>&quot;128 PERF ST&quot;</td><td>&quot;PERF st&quot;</td><td>&quot;128 PERF st&quot;</td><td>&quot;PERF st&quot;</td><td>&quot;PERF st&quot;</td><td>&quot;128 PERF st&quot;</td><td>&quot;128&quot;</td><td>&quot; st&quot;</td><td>&quot;8 PE&quot;</td></tr><tr><td>&quot;Rust blVD, 158&quot;</td><td>&quot;Rust Blvd, 158&quot;</td><td>&quot;rust blvd, 158&quot;</td><td>&quot;RUST BLVD, 158&quot;</td><td>&quot;Rust blVD&quot;</td><td>&quot;Rust blVD&quot;</td><td>&quot;Rust blVD, 158&quot;</td><td>&quot;Rust blVD, 158&quot;</td><td>&quot;Rust blVD&quot;</td><td>&quot;Rus&quot;</td><td>&quot;158&quot;</td><td>&quot;st b&quot;</td></tr><tr><td>&quot;PoLaRs Av, 12&quot;</td><td>&quot;Polars Av, 12&quot;</td><td>&quot;polars av, 12&quot;</td><td>&quot;POLARS AV, 12&quot;</td><td>&quot;PoLaRs Av&quot;</td><td>&quot;PoLaRs Av&quot;</td><td>&quot;PoLaRs Av, 12&quot;</td><td>&quot;PoLaRs Av, 12&quot;</td><td>&quot;PoLaRs Av, 12&quot;</td><td>&quot;PoL&quot;</td><td>&quot; 12&quot;</td><td>&quot;LaRs&quot;</td></tr><tr><td>&quot;1042 Query sq&quot;</td><td>&quot;1042 Query Sq&quot;</td><td>&quot;1042 query sq&quot;</td><td>&quot;1042 QUERY SQ&quot;</td><td>&quot;Query sq&quot;</td><td>&quot;1042 Query sq&quot;</td><td>&quot;Query sq&quot;</td><td>&quot;1042 Query sq&quot;</td><td>&quot;1042 Query sq&quot;</td><td>&quot;104&quot;</td><td>&quot; sq&quot;</td><td>&quot;42 Q&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 12)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ originals ┆ addresses ┆ lower     ┆ upper     ┆ … ┆ suffix    ┆ 3_charact ┆ 3_charact ┆ from_2_w │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ers_begin ┆ ers_end   ┆ ith_len_ │\n",
       "│ str       ┆ str       ┆ str       ┆ str       ┆   ┆ str       ┆ ---       ┆ ---       ┆ 4        │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ str       ┆ str       ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ str      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 128 PERF  ┆ 128 Perf  ┆ 128 perf  ┆ 128 PERF  ┆ … ┆ 128 PERF  ┆ 128       ┆  st       ┆ 8 PE     │\n",
       "│ st        ┆ St        ┆ st        ┆ ST        ┆   ┆ st        ┆           ┆           ┆          │\n",
       "│ Rust      ┆ Rust      ┆ rust      ┆ RUST      ┆ … ┆ Rust blVD ┆ Rus       ┆ 158       ┆ st b     │\n",
       "│ blVD, 158 ┆ Blvd, 158 ┆ blvd, 158 ┆ BLVD, 158 ┆   ┆           ┆           ┆           ┆          │\n",
       "│ PoLaRs    ┆ Polars    ┆ polars    ┆ POLARS    ┆ … ┆ PoLaRs    ┆ PoL       ┆  12       ┆ LaRs     │\n",
       "│ Av, 12    ┆ Av, 12    ┆ av, 12    ┆ AV, 12    ┆   ┆ Av, 12    ┆           ┆           ┆          │\n",
       "│ 1042      ┆ 1042      ┆ 1042      ┆ 1042      ┆ … ┆ 1042      ┆ 104       ┆  sq       ┆ 42 Q     │\n",
       "│ Query sq  ┆ Query Sq  ┆ query sq  ┆ QUERY SQ  ┆   ┆ Query sq  ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses = pl.DataFrame(\n",
    "    {\n",
    "        \"addresses\": [\n",
    "            \"128 PERF st\",\n",
    "            \"Rust blVD, 158\",\n",
    "            \"PoLaRs Av, 12\",\n",
    "            \"1042 Query sq\",\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "addr = pl.col(\"addresses\")\n",
    "chars = \", 0123456789\"\n",
    "addresses = addresses.select(\n",
    "    addr.alias(\"originals\"),\n",
    "    addr.str.to_titlecase(),\n",
    "    addr.str.to_lowercase().alias(\"lower\"),\n",
    "    addr.str.to_uppercase().alias(\"upper\"),\n",
    "    addr.str.strip_chars(chars).alias(\"strip\"),\n",
    "    addr.str.strip_chars_end(chars).alias(\"end\"),\n",
    "    addr.str.strip_chars_start(chars).alias(\"start\"),\n",
    "    addr.str.strip_prefix(\"128 \").alias(\"prefix\"),\n",
    "    addr.str.strip_suffix(\", 158\").alias(\"suffix\"),\n",
    "    addr.str.head(3).alias(\"3_characters_begin\"),\n",
    "    addr.str.tail(3).alias(\"3_characters_end\"),\n",
    "    addr.str.slice(2, length=4).alias(\"from_2_with_len_4\"),\n",
    ")\n",
    "addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lists and array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### List\n",
    "\n",
    "https://docs.pola.rs/api/python/stable/reference/expressions/list.html\n",
    "\n",
    "List is suitable for columns those have values with **1-D** or **difference in lengths** (unknown lenght)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n",
      "┌─────────────────────────────────┬───────────────┬───────────────────────┐\n",
      "│ names                           ┆ children_ages ┆ medical_appointments  │\n",
      "│ ---                             ┆ ---           ┆ ---                   │\n",
      "│ list[str]                       ┆ list[i64]     ┆ list[datetime[μs]]    │\n",
      "╞═════════════════════════════════╪═══════════════╪═══════════════════════╡\n",
      "│ [\"Anne\", \"Averill\", \"Adams\"]    ┆ [5, 7]        ┆ []                    │\n",
      "│ [\"Brandon\", \"Brooke\", … \"Brans… ┆ []            ┆ []                    │\n",
      "│ [\"Camila\", \"Campbell\"]          ┆ []            ┆ []                    │\n",
      "│ [\"Dennis\", \"Doyle\"]             ┆ [8, 11, 18]   ┆ [2022-05-22 16:30:00] │\n",
      "└─────────────────────────────────┴───────────────┴───────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import polars as pl\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"names\": [\n",
    "            [\"Anne\", \"Averill\", \"Adams\"],\n",
    "            [\"Brandon\", \"Brooke\", \"Borden\", \"Branson\"],\n",
    "            [\"Camila\", \"Campbell\"],\n",
    "            [\"Dennis\", \"Doyle\"],\n",
    "        ],\n",
    "        \"children_ages\": [\n",
    "            [5, 7],\n",
    "            [],\n",
    "            [],\n",
    "            [8, 11, 18],\n",
    "        ],\n",
    "        \"medical_appointments\": [\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "            [datetime(2022, 5, 22, 16, 30)],\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌───────────┬──────────────────────┐\n",
      "│ station   ┆ temperatures         │\n",
      "│ ---       ┆ ---                  │\n",
      "│ str       ┆ list[str]            │\n",
      "╞═══════════╪══════════════════════╡\n",
      "│ Station 1 ┆ [\"20\", \"5\", … \"20\"]  │\n",
      "│ Station 2 ┆ [\"18\", \"8\", … \"40\"]  │\n",
      "│ Station 3 ┆ [\"19\", \"24\", … \"22\"] │\n",
      "│ Station 4 ┆ [\"E2\", \"E0\", … \"6\"]  │\n",
      "│ Station 5 ┆ [\"14\", \"8\", … \"E1\"]  │\n",
      "└───────────┴──────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "weather = pl.DataFrame(\n",
    "    {\n",
    "        \"station\": [f\"Station {idx}\" for idx in range(1, 6)],\n",
    "        \"temperatures\": [\n",
    "            \"20 5 5 E1 7 13 19 9 6 20\",\n",
    "            \"18 8 16 11 23 E2 8 E2 E2 E2 90 70 40\",\n",
    "            \"19 24 E9 16 6 12 10 22\",\n",
    "            \"E2 E0 15 7 8 10 E1 24 17 13 6\",\n",
    "            \"14 8 E0 16 22 24 E1\",\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "weather = weather.with_columns(pl.col(\"temperatures\").str.split(\" \"))\n",
    "print(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (49, 2)\n",
      "┌───────────┬──────────────┐\n",
      "│ station   ┆ temperatures │\n",
      "│ ---       ┆ ---          │\n",
      "│ str       ┆ str          │\n",
      "╞═══════════╪══════════════╡\n",
      "│ Station 1 ┆ 20           │\n",
      "│ Station 1 ┆ 5            │\n",
      "│ Station 1 ┆ 5            │\n",
      "│ Station 1 ┆ E1           │\n",
      "│ Station 1 ┆ 7            │\n",
      "│ …         ┆ …            │\n",
      "│ Station 5 ┆ E0           │\n",
      "│ Station 5 ┆ 16           │\n",
      "│ Station 5 ┆ 22           │\n",
      "│ Station 5 ┆ 24           │\n",
      "│ Station 5 ┆ E1           │\n",
      "└───────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# explode each element in its own rows\n",
    "result = weather.explode(\"temperatures\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 5)\n",
      "┌───────────┬──────────────────────┬────────────────────┬────────────────────┬──────────────────┐\n",
      "│ station   ┆ temperatures         ┆ head               ┆ tail               ┆ two_next_to_last │\n",
      "│ ---       ┆ ---                  ┆ ---                ┆ ---                ┆ ---              │\n",
      "│ str       ┆ list[str]            ┆ list[str]          ┆ list[str]          ┆ list[str]        │\n",
      "╞═══════════╪══════════════════════╪════════════════════╪════════════════════╪══════════════════╡\n",
      "│ Station 1 ┆ [\"20\", \"5\", … \"20\"]  ┆ [\"20\", \"5\", \"5\"]   ┆ [\"9\", \"6\", \"20\"]   ┆ [\"9\", \"6\"]       │\n",
      "│ Station 2 ┆ [\"18\", \"8\", … \"40\"]  ┆ [\"18\", \"8\", \"16\"]  ┆ [\"90\", \"70\", \"40\"] ┆ [\"90\", \"70\"]     │\n",
      "│ Station 3 ┆ [\"19\", \"24\", … \"22\"] ┆ [\"19\", \"24\", \"E9\"] ┆ [\"12\", \"10\", \"22\"] ┆ [\"12\", \"10\"]     │\n",
      "│ Station 4 ┆ [\"E2\", \"E0\", … \"6\"]  ┆ [\"E2\", \"E0\", \"15\"] ┆ [\"17\", \"13\", \"6\"]  ┆ [\"17\", \"13\"]     │\n",
      "│ Station 5 ┆ [\"14\", \"8\", … \"E1\"]  ┆ [\"14\", \"8\", \"E0\"]  ┆ [\"22\", \"24\", \"E1\"] ┆ [\"22\", \"24\"]     │\n",
      "└───────────┴──────────────────────┴────────────────────┴────────────────────┴──────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# slicing\n",
    "result = weather.with_columns(\n",
    "    pl.col(\"temperatures\").list.head(3).alias(\"head\"),\n",
    "    pl.col(\"temperatures\").list.tail(3).alias(\"tail\"),\n",
    "    pl.col(\"temperatures\").list.slice(-3, 2).alias(\"two_next_to_last\"),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**access in namespace `list`**: https://docs.pola.rs/api/python/stable/reference/expressions/list.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌───────────┬──────────────────────┬────────┐\n",
      "│ station   ┆ temperatures         ┆ errors │\n",
      "│ ---       ┆ ---                  ┆ ---    │\n",
      "│ str       ┆ list[str]            ┆ u32    │\n",
      "╞═══════════╪══════════════════════╪════════╡\n",
      "│ Station 1 ┆ [\"20\", \"5\", … \"20\"]  ┆ 1      │\n",
      "│ Station 2 ┆ [\"18\", \"8\", … \"40\"]  ┆ 4      │\n",
      "│ Station 3 ┆ [\"19\", \"24\", … \"22\"] ┆ 1      │\n",
      "│ Station 4 ┆ [\"E2\", \"E0\", … \"6\"]  ┆ 3      │\n",
      "│ Station 5 ┆ [\"14\", \"8\", … \"E1\"]  ┆ 2      │\n",
      "└───────────┴──────────────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# Function with list\n",
    "\n",
    "result = weather.with_columns(\n",
    "    pl.col(\"temperatures\")\n",
    "    .list.eval(\n",
    "        pl.element().cast(pl.Int64, strict=False).is_null()\n",
    "    )  # each element cast to INTEGER (null if failded), then mask where null\n",
    "    .list.sum()  # count True\n",
    "    .alias(\"errors\"),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Row-wise computations in list (cross columns in same row)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10, 4)\n",
      "┌────────────┬───────┬───────┬───────┐\n",
      "│ station    ┆ day_1 ┆ day_2 ┆ day_3 │\n",
      "│ ---        ┆ ---   ┆ ---   ┆ ---   │\n",
      "│ str        ┆ i64   ┆ i64   ┆ i64   │\n",
      "╞════════════╪═══════╪═══════╪═══════╡\n",
      "│ Station 1  ┆ 17    ┆ 15    ┆ 16    │\n",
      "│ Station 2  ┆ 11    ┆ 11    ┆ 15    │\n",
      "│ Station 3  ┆ 8     ┆ 10    ┆ 24    │\n",
      "│ Station 4  ┆ 22    ┆ 8     ┆ 24    │\n",
      "│ Station 5  ┆ 9     ┆ 7     ┆ 8     │\n",
      "│ Station 6  ┆ 21    ┆ 14    ┆ 23    │\n",
      "│ Station 7  ┆ 20    ┆ 18    ┆ 19    │\n",
      "│ Station 8  ┆ 8     ┆ 21    ┆ 23    │\n",
      "│ Station 9  ┆ 8     ┆ 15    ┆ 16    │\n",
      "│ Station 10 ┆ 17    ┆ 13    ┆ 10    │\n",
      "└────────────┴───────┴───────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "weather_by_day = pl.DataFrame(\n",
    "    {\n",
    "        \"station\": [f\"Station {idx}\" for idx in range(1, 11)],\n",
    "        \"day_1\": [17, 11, 8, 22, 9, 21, 20, 8, 8, 17],\n",
    "        \"day_2\": [15, 11, 10, 8, 7, 14, 18, 21, 15, 13],\n",
    "        \"day_3\": [16, 15, 24, 24, 8, 23, 19, 23, 16, 10],\n",
    "    }\n",
    ")\n",
    "print(weather_by_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10, 5)\n",
      "┌────────────┬───────┬───────┬───────┬────────────────────┐\n",
      "│ station    ┆ day_1 ┆ day_2 ┆ day_3 ┆ temps_rank         │\n",
      "│ ---        ┆ ---   ┆ ---   ┆ ---   ┆ ---                │\n",
      "│ str        ┆ i64   ┆ i64   ┆ i64   ┆ list[f64]          │\n",
      "╞════════════╪═══════╪═══════╪═══════╪════════════════════╡\n",
      "│ Station 1  ┆ 17    ┆ 15    ┆ 16    ┆ [0.33, 1.0, 0.67]  │\n",
      "│ Station 2  ┆ 11    ┆ 11    ┆ 15    ┆ [0.83, 0.83, 0.33] │\n",
      "│ Station 3  ┆ 8     ┆ 10    ┆ 24    ┆ [1.0, 0.67, 0.33]  │\n",
      "│ Station 4  ┆ 22    ┆ 8     ┆ 24    ┆ [0.67, 1.0, 0.33]  │\n",
      "│ Station 5  ┆ 9     ┆ 7     ┆ 8     ┆ [0.33, 1.0, 0.67]  │\n",
      "│ Station 6  ┆ 21    ┆ 14    ┆ 23    ┆ [0.67, 1.0, 0.33]  │\n",
      "│ Station 7  ┆ 20    ┆ 18    ┆ 19    ┆ [0.33, 1.0, 0.67]  │\n",
      "│ Station 8  ┆ 8     ┆ 21    ┆ 23    ┆ [1.0, 0.67, 0.33]  │\n",
      "│ Station 9  ┆ 8     ┆ 15    ┆ 16    ┆ [1.0, 0.67, 0.33]  │\n",
      "│ Station 10 ┆ 17    ┆ 13    ┆ 10    ┆ [0.33, 0.67, 1.0]  │\n",
      "└────────────┴───────┴───────┴───────┴────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "rank_pct = (pl.element().rank(descending=True) / pl.all().count()).round(2)\n",
    "\n",
    "result = weather_by_day.with_columns(\n",
    "    # create the list of homogeneous data\n",
    "    pl.concat_list(pl.all().exclude(\"station\")).alias(\"all_temps\")\n",
    ").select(\n",
    "    # select all columns except the intermediate list\n",
    "    pl.all().exclude(\"all_temps\"),\n",
    "    # compute the rank by calling `list.eval`\n",
    "    pl.col(\"all_temps\").list.eval(rank_pct, parallel=True).alias(\"temps_rank\"),\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Array (prefer)\n",
    "\n",
    "https://docs.pola.rs/api/python/stable/reference/expressions/array.html\n",
    "\n",
    "Suitable for multi-dimension and known and fixed shape\n",
    "\n",
    "In short, **prefer the data type `Array` over `List`** because it is more memory efficient and more performant. If you cannot use Array, then use List:\n",
    "- when the values within a column do not have a fixed shape; or\n",
    "- when you need functions that are only available in the list API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "┌───────────────────────┬─────────────────────────────────┐\n",
      "│ bit_flags             ┆ tic_tac_toe                     │\n",
      "│ ---                   ┆ ---                             │\n",
      "│ array[bool, 5]        ┆ array[str, (3, 3)]              │\n",
      "╞═══════════════════════╪═════════════════════════════════╡\n",
      "│ [true, true, … false] ┆ [[\" \", \"x\", \"o\"], [\" \", \"x\", \"… │\n",
      "│ [false, true, … true] ┆ [[\"o\", \"x\", \"x\"], [\" \", \"o\", \"… │\n",
      "└───────────────────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"bit_flags\": [\n",
    "            [True, True, True, True, False],\n",
    "            [False, True, True, True, True],\n",
    "        ],\n",
    "        \"tic_tac_toe\": [\n",
    "            [\n",
    "                [\" \", \"x\", \"o\"],\n",
    "                [\" \", \"x\", \" \"],\n",
    "                [\"o\", \"x\", \" \"],\n",
    "            ],\n",
    "            [\n",
    "                [\"o\", \"x\", \"x\"],\n",
    "                [\" \", \"o\", \"x\"],\n",
    "                [\" \", \" \", \"o\"],\n",
    "            ],\n",
    "        ],\n",
    "    },\n",
    "    schema={  # define array\n",
    "        \"bit_flags\": pl.Array(pl.Boolean, 5),\n",
    "        \"tic_tac_toe\": pl.Array(pl.String, (3, 3)),\n",
    "    },\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**access in namespace `arr`**: https://docs.pola.rs/api/python/stable/reference/expressions/array.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 5)\n",
      "┌─────────────────┬───────────────┬─────────────┬────────┬─────────┐\n",
      "│ name            ┆ fav_numbers   ┆ largest_fav ┆ summed ┆ likes_3 │\n",
      "│ ---             ┆ ---           ┆ ---         ┆ ---    ┆ ---     │\n",
      "│ str             ┆ array[i32, 3] ┆ i32         ┆ i32    ┆ bool    │\n",
      "╞═════════════════╪═══════════════╪═════════════╪════════╪═════════╡\n",
      "│ Anne Adams      ┆ [0, 1, 42]    ┆ 42          ┆ 43     ┆ false   │\n",
      "│ Brandon Branson ┆ [2, 3, 5]     ┆ 5           ┆ 10     ┆ true    │\n",
      "│ Camila Campbell ┆ [13, 21, 34]  ┆ 34          ┆ 68     ┆ false   │\n",
      "│ Dennis Doyle    ┆ [3, 7, 73]    ┆ 73          ┆ 83     ┆ true    │\n",
      "└─────────────────┴───────────────┴─────────────┴────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"first_last\": [\n",
    "            [\"Anne\", \"Adams\"],\n",
    "            [\"Brandon\", \"Branson\"],\n",
    "            [\"Camila\", \"Campbell\"],\n",
    "            [\"Dennis\", \"Doyle\"],\n",
    "        ],\n",
    "        \"fav_numbers\": [\n",
    "            [42, 0, 1],\n",
    "            [2, 3, 5],\n",
    "            [13, 21, 34],\n",
    "            [73, 3, 7],\n",
    "        ],\n",
    "    },\n",
    "    schema={\n",
    "        \"first_last\": pl.Array(pl.String, 2),\n",
    "        \"fav_numbers\": pl.Array(pl.Int32, 3),\n",
    "    },\n",
    ")\n",
    "\n",
    "result = df.select(\n",
    "    pl.col(\"first_last\").arr.join(\" \").alias(\"name\"),\n",
    "    pl.col(\"fav_numbers\").arr.sort(),\n",
    "    pl.col(\"fav_numbers\").arr.max().alias(\"largest_fav\"),\n",
    "    pl.col(\"fav_numbers\").arr.sum().alias(\"summed\"),\n",
    "    pl.col(\"fav_numbers\").arr.contains(3).alias(\"likes_3\"),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical and enums\n",
    "\n",
    "https://docs.pola.rs/api/python/stable/reference/expressions/categories.html\n",
    "\n",
    "Prefer `Enum` over `Categorical` whenever possible. \n",
    "- When the categories are fixed and known up front, use `Enum`. \n",
    "- When you don't know the categories or they are not fixed then you must use `Categorical`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structs\n",
    "\n",
    "**access in namespace `struct`**: https://docs.pola.rs/api/python/stable/reference/expressions/struct.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 1)\n",
      "┌───────────┐\n",
      "│ Theatre   │\n",
      "│ ---       │\n",
      "│ struct[2] │\n",
      "╞═══════════╡\n",
      "│ {\"NE\",4}  │\n",
      "│ {\"IL\",3}  │\n",
      "│ {\"ME\",1}  │\n",
      "│ {\"ND\",1}  │\n",
      "│ {\"SD\",1}  │\n",
      "└───────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "ratings = pl.DataFrame(\n",
    "    {\n",
    "        \"Movie\": [\n",
    "            \"Cars\",\n",
    "            \"IT\",\n",
    "            \"ET\",\n",
    "            \"Cars\",\n",
    "            \"Up\",\n",
    "            \"IT\",\n",
    "            \"Cars\",\n",
    "            \"ET\",\n",
    "            \"Up\",\n",
    "            \"Cars\",\n",
    "        ],\n",
    "        \"Theatre\": [\n",
    "            \"NE\",\n",
    "            \"ME\",\n",
    "            \"IL\",\n",
    "            \"ND\",\n",
    "            \"NE\",\n",
    "            \"SD\",\n",
    "            \"NE\",\n",
    "            \"IL\",\n",
    "            \"IL\",\n",
    "            \"NE\",\n",
    "        ],\n",
    "        \"Avg_Rating\": [4.5, 4.4, 4.6, 4.3, 4.8, 4.7, 4.5, 4.9, 4.7, 4.6],\n",
    "        \"Count\": [30, 27, 26, 29, 31, 28, 28, 26, 33, 28],\n",
    "    }\n",
    ")\n",
    "result = ratings.select(pl.col(\"Theatre\").value_counts(sort=True))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `unnest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌─────────┬───────┐\n",
      "│ Theatre ┆ count │\n",
      "│ ---     ┆ ---   │\n",
      "│ str     ┆ u32   │\n",
      "╞═════════╪═══════╡\n",
      "│ NE      ┆ 4     │\n",
      "│ IL      ┆ 3     │\n",
      "│ ME      ┆ 1     │\n",
      "│ ND      ┆ 1     │\n",
      "│ SD      ┆ 1     │\n",
      "└─────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "result = ratings.select(pl.col(\"Theatre\").value_counts(sort=True)).unnest(\n",
    "    \"Theatre\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `unnest` will turn each field of the `Struct` into its own column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2,)\n",
      "Series: 'ratings' [struct[3]]\n",
      "[\n",
      "\t{\"Cars\",\"NE\",4.5}\n",
      "\t{\"Toy Story\",\"ME\",4.9}\n",
      "]\n",
      "------\n",
      "Unnest Series: \n",
      " shape: (2, 3)\n",
      "┌───────────┬─────────┬────────────┐\n",
      "│ Movie     ┆ Theatre ┆ Avg_Rating │\n",
      "│ ---       ┆ ---     ┆ ---        │\n",
      "│ str       ┆ str     ┆ f64        │\n",
      "╞═══════════╪═════════╪════════════╡\n",
      "│ Cars      ┆ NE      ┆ 4.5        │\n",
      "│ Toy Story ┆ ME      ┆ 4.9        │\n",
      "└───────────┴─────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "rating_series = pl.Series(\n",
    "    \"ratings\",\n",
    "    [\n",
    "        {\"Movie\": \"Cars\", \"Theatre\": \"NE\", \"Avg_Rating\": 4.5},\n",
    "        {\"Movie\": \"Toy Story\", \"Theatre\": \"ME\", \"Avg_Rating\": 4.9},\n",
    "    ],\n",
    ")\n",
    "print(rating_series)\n",
    "\n",
    "unnest_sr = rating_series.struct.unnest()\n",
    "print(\"------\\nUnnest Series: \\n\", unnest_sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `field`: extract field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2,)\n",
      "Series: 'Movie' [str]\n",
      "[\n",
      "\t\"Cars\"\n",
      "\t\"Toy Story\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "result = rating_series.struct.field(\"Movie\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `rename_fields`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Film</th><th>State</th><th>Value</th></tr><tr><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Cars&quot;</td><td>&quot;NE&quot;</td><td>4.5</td></tr><tr><td>&quot;Toy Story&quot;</td><td>&quot;ME&quot;</td><td>4.9</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 3)\n",
       "┌───────────┬───────┬───────┐\n",
       "│ Film      ┆ State ┆ Value │\n",
       "│ ---       ┆ ---   ┆ ---   │\n",
       "│ str       ┆ str   ┆ f64   │\n",
       "╞═══════════╪═══════╪═══════╡\n",
       "│ Cars      ┆ NE    ┆ 4.5   │\n",
       "│ Toy Story ┆ ME    ┆ 4.9   │\n",
       "└───────────┴───────┴───────┘"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = rating_series.struct.rename_fields([\"Film\", \"State\", \"Value\"])\n",
    "result.to_frame().unnest(\"ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### detect duplicated / unique rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌───────┬─────────┬────────────┬───────┐\n",
      "│ Movie ┆ Theatre ┆ Avg_Rating ┆ Count │\n",
      "│ ---   ┆ ---     ┆ ---        ┆ ---   │\n",
      "│ str   ┆ str     ┆ f64        ┆ i64   │\n",
      "╞═══════╪═════════╪════════════╪═══════╡\n",
      "│ Cars  ┆ NE      ┆ 4.5        ┆ 30    │\n",
      "│ ET    ┆ IL      ┆ 4.6        ┆ 26    │\n",
      "│ Cars  ┆ NE      ┆ 4.5        ┆ 28    │\n",
      "│ ET    ┆ IL      ┆ 4.9        ┆ 26    │\n",
      "│ Cars  ┆ NE      ┆ 4.6        ┆ 28    │\n",
      "└───────┴─────────┴────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "result = ratings.filter(pl.struct(\"Movie\", \"Theatre\").is_duplicated())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌───────┬─────────┬────────────┬───────┐\n",
      "│ Movie ┆ Theatre ┆ Avg_Rating ┆ Count │\n",
      "│ ---   ┆ ---     ┆ ---        ┆ ---   │\n",
      "│ str   ┆ str     ┆ f64        ┆ i64   │\n",
      "╞═══════╪═════════╪════════════╪═══════╡\n",
      "│ IT    ┆ ME      ┆ 4.4        ┆ 27    │\n",
      "│ Cars  ┆ ND      ┆ 4.3        ┆ 29    │\n",
      "│ Up    ┆ NE      ┆ 4.8        ┆ 31    │\n",
      "│ IT    ┆ SD      ┆ 4.7        ┆ 28    │\n",
      "│ Up    ┆ IL      ┆ 4.7        ┆ 33    │\n",
      "└───────┴─────────┴────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "result = ratings.filter(pl.struct(\"Movie\", \"Theatre\").is_unique())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Movie</th><th>Theatre</th><th>Avg_Rating</th><th>Count</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Cars&quot;</td><td>&quot;ND&quot;</td><td>4.3</td><td>29</td></tr><tr><td>&quot;Up&quot;</td><td>&quot;IL&quot;</td><td>4.7</td><td>33</td></tr><tr><td>&quot;Cars&quot;</td><td>&quot;NE&quot;</td><td>4.5</td><td>28</td></tr><tr><td>&quot;IT&quot;</td><td>&quot;ME&quot;</td><td>4.4</td><td>27</td></tr><tr><td>&quot;IT&quot;</td><td>&quot;SD&quot;</td><td>4.7</td><td>28</td></tr><tr><td>&quot;ET&quot;</td><td>&quot;IL&quot;</td><td>4.6</td><td>26</td></tr><tr><td>&quot;Up&quot;</td><td>&quot;NE&quot;</td><td>4.8</td><td>31</td></tr><tr><td>&quot;ET&quot;</td><td>&quot;IL&quot;</td><td>4.9</td><td>26</td></tr><tr><td>&quot;Cars&quot;</td><td>&quot;NE&quot;</td><td>4.6</td><td>28</td></tr><tr><td>&quot;Cars&quot;</td><td>&quot;NE&quot;</td><td>4.5</td><td>30</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 4)\n",
       "┌───────┬─────────┬────────────┬───────┐\n",
       "│ Movie ┆ Theatre ┆ Avg_Rating ┆ Count │\n",
       "│ ---   ┆ ---     ┆ ---        ┆ ---   │\n",
       "│ str   ┆ str     ┆ f64        ┆ i64   │\n",
       "╞═══════╪═════════╪════════════╪═══════╡\n",
       "│ Cars  ┆ ND      ┆ 4.3        ┆ 29    │\n",
       "│ Up    ┆ IL      ┆ 4.7        ┆ 33    │\n",
       "│ Cars  ┆ NE      ┆ 4.5        ┆ 28    │\n",
       "│ IT    ┆ ME      ┆ 4.4        ┆ 27    │\n",
       "│ IT    ┆ SD      ┆ 4.7        ┆ 28    │\n",
       "│ ET    ┆ IL      ┆ 4.6        ┆ 26    │\n",
       "│ Up    ┆ NE      ┆ 4.8        ┆ 31    │\n",
       "│ ET    ┆ IL      ┆ 4.9        ┆ 26    │\n",
       "│ Cars  ┆ NE      ┆ 4.6        ┆ 28    │\n",
       "│ Cars  ┆ NE      ┆ 4.5        ┆ 30    │\n",
       "└───────┴─────────┴────────────┴───────┘"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Movie</th><th>Theatre</th><th>Avg_Rating</th><th>Count</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Cars&quot;</td><td>&quot;NE&quot;</td><td>4.5</td><td>30</td></tr><tr><td>&quot;IT&quot;</td><td>&quot;ME&quot;</td><td>4.4</td><td>27</td></tr><tr><td>&quot;ET&quot;</td><td>&quot;IL&quot;</td><td>4.6</td><td>26</td></tr><tr><td>&quot;Cars&quot;</td><td>&quot;ND&quot;</td><td>4.3</td><td>29</td></tr><tr><td>&quot;Up&quot;</td><td>&quot;NE&quot;</td><td>4.8</td><td>31</td></tr><tr><td>&quot;IT&quot;</td><td>&quot;SD&quot;</td><td>4.7</td><td>28</td></tr><tr><td>&quot;Cars&quot;</td><td>&quot;NE&quot;</td><td>4.5</td><td>28</td></tr><tr><td>&quot;ET&quot;</td><td>&quot;IL&quot;</td><td>4.9</td><td>26</td></tr><tr><td>&quot;Up&quot;</td><td>&quot;IL&quot;</td><td>4.7</td><td>33</td></tr><tr><td>&quot;Cars&quot;</td><td>&quot;NE&quot;</td><td>4.6</td><td>28</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 4)\n",
       "┌───────┬─────────┬────────────┬───────┐\n",
       "│ Movie ┆ Theatre ┆ Avg_Rating ┆ Count │\n",
       "│ ---   ┆ ---     ┆ ---        ┆ ---   │\n",
       "│ str   ┆ str     ┆ f64        ┆ i64   │\n",
       "╞═══════╪═════════╪════════════╪═══════╡\n",
       "│ Cars  ┆ NE      ┆ 4.5        ┆ 30    │\n",
       "│ IT    ┆ ME      ┆ 4.4        ┆ 27    │\n",
       "│ ET    ┆ IL      ┆ 4.6        ┆ 26    │\n",
       "│ Cars  ┆ ND      ┆ 4.3        ┆ 29    │\n",
       "│ Up    ┆ NE      ┆ 4.8        ┆ 31    │\n",
       "│ IT    ┆ SD      ┆ 4.7        ┆ 28    │\n",
       "│ Cars  ┆ NE      ┆ 4.5        ┆ 28    │\n",
       "│ ET    ┆ IL      ┆ 4.9        ┆ 26    │\n",
       "│ Up    ┆ IL      ┆ 4.7        ┆ 33    │\n",
       "│ Cars  ┆ NE      ┆ 4.6        ┆ 28    │\n",
       "└───────┴─────────┴────────────┴───────┘"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter unique rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Movie</th><th>Theatre</th><th>Avg_Rating</th><th>Count</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Cars&quot;</td><td>&quot;NE&quot;</td><td>4.5</td><td>30</td></tr><tr><td>&quot;IT&quot;</td><td>&quot;ME&quot;</td><td>4.4</td><td>27</td></tr><tr><td>&quot;Cars&quot;</td><td>&quot;NE&quot;</td><td>4.5</td><td>28</td></tr><tr><td>&quot;ET&quot;</td><td>&quot;IL&quot;</td><td>4.6</td><td>26</td></tr><tr><td>&quot;Up&quot;</td><td>&quot;NE&quot;</td><td>4.8</td><td>31</td></tr><tr><td>&quot;Cars&quot;</td><td>&quot;NE&quot;</td><td>4.6</td><td>28</td></tr><tr><td>&quot;Up&quot;</td><td>&quot;IL&quot;</td><td>4.7</td><td>33</td></tr><tr><td>&quot;IT&quot;</td><td>&quot;SD&quot;</td><td>4.7</td><td>28</td></tr><tr><td>&quot;ET&quot;</td><td>&quot;IL&quot;</td><td>4.9</td><td>26</td></tr><tr><td>&quot;Cars&quot;</td><td>&quot;ND&quot;</td><td>4.3</td><td>29</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 4)\n",
       "┌───────┬─────────┬────────────┬───────┐\n",
       "│ Movie ┆ Theatre ┆ Avg_Rating ┆ Count │\n",
       "│ ---   ┆ ---     ┆ ---        ┆ ---   │\n",
       "│ str   ┆ str     ┆ f64        ┆ i64   │\n",
       "╞═══════╪═════════╪════════════╪═══════╡\n",
       "│ Cars  ┆ NE      ┆ 4.5        ┆ 30    │\n",
       "│ IT    ┆ ME      ┆ 4.4        ┆ 27    │\n",
       "│ Cars  ┆ NE      ┆ 4.5        ┆ 28    │\n",
       "│ ET    ┆ IL      ┆ 4.6        ┆ 26    │\n",
       "│ Up    ┆ NE      ┆ 4.8        ┆ 31    │\n",
       "│ Cars  ┆ NE      ┆ 4.6        ┆ 28    │\n",
       "│ Up    ┆ IL      ┆ 4.7        ┆ 33    │\n",
       "│ IT    ┆ SD      ┆ 4.7        ┆ 28    │\n",
       "│ ET    ┆ IL      ┆ 4.9        ┆ 26    │\n",
       "│ Cars  ┆ ND      ┆ 4.3        ┆ 29    │\n",
       "└───────┴─────────┴────────────┴───────┘"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌───────┬─────────┬────────────┬───────┐\n",
      "│ Movie ┆ Theatre ┆ Avg_Rating ┆ Count │\n",
      "│ ---   ┆ ---     ┆ ---        ┆ ---   │\n",
      "│ str   ┆ str     ┆ f64        ┆ i64   │\n",
      "╞═══════╪═════════╪════════════╪═══════╡\n",
      "│ Cars  ┆ NE      ┆ 4.5        ┆ 30    │\n",
      "│ ET    ┆ IL      ┆ 4.6        ┆ 26    │\n",
      "│ Cars  ┆ NE      ┆ 4.5        ┆ 28    │\n",
      "│ ET    ┆ IL      ┆ 4.9        ┆ 26    │\n",
      "│ Cars  ┆ NE      ┆ 4.6        ┆ 28    │\n",
      "└───────┴─────────┴────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "result = ratings.filter(pl.struct(\"Movie\", \"Theatre\").is_duplicated())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect unique rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌───────┬─────────┬────────────┬───────┐\n",
      "│ Movie ┆ Theatre ┆ Avg_Rating ┆ Count │\n",
      "│ ---   ┆ ---     ┆ ---        ┆ ---   │\n",
      "│ str   ┆ str     ┆ f64        ┆ i64   │\n",
      "╞═══════╪═════════╪════════════╪═══════╡\n",
      "│ IT    ┆ ME      ┆ 4.4        ┆ 27    │\n",
      "│ Cars  ┆ ND      ┆ 4.3        ┆ 29    │\n",
      "│ Up    ┆ NE      ┆ 4.8        ┆ 31    │\n",
      "│ IT    ┆ SD      ┆ 4.7        ┆ 28    │\n",
      "│ Up    ┆ IL      ┆ 4.7        ┆ 33    │\n",
      "└───────┴─────────┴────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "result = ratings.filter(pl.struct(\"Movie\", \"Theatre\").is_unique())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing\n",
    "\n",
    "In Polars, missing data is represented by the value `null`. This missing value `null` is used for all data types, including numerical types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 1)\n",
      "┌───────┐\n",
      "│ value │\n",
      "│ ---   │\n",
      "│ i64   │\n",
      "╞═══════╡\n",
      "│ 1     │\n",
      "│ null  │\n",
      "└───────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"value\": [1, None],\n",
    "    },\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 1)\n",
      "┌───────┐\n",
      "│ value │\n",
      "│ ---   │\n",
      "│ u32   │\n",
      "╞═══════╡\n",
      "│ 1     │\n",
      "└───────┘\n"
     ]
    }
   ],
   "source": [
    "null_count_df = df.null_count()\n",
    "print(null_count_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 1)\n",
      "┌───────┐\n",
      "│ value │\n",
      "│ ---   │\n",
      "│ bool  │\n",
      "╞═══════╡\n",
      "│ false │\n",
      "│ true  │\n",
      "└───────┘\n"
     ]
    }
   ],
   "source": [
    "is_null_series = df.select(\n",
    "    pl.col(\"value\").is_null(),\n",
    ")\n",
    "print(is_null_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌──────┬──────┬─────────────────┬─────────────────┬──────────────┬───────────────┬─────────────────┐\n",
      "│ col1 ┆ col2 ┆ fill_by_literal ┆ fill_by_other_c ┆ fill_forward ┆ fill_backward ┆ fill_by_interpo │\n",
      "│ ---  ┆ ---  ┆ ---             ┆ ol              ┆ ---          ┆ ---           ┆ lation          │\n",
      "│ f64  ┆ i64  ┆ i64             ┆ ---             ┆ i64          ┆ i64           ┆ ---             │\n",
      "│      ┆      ┆                 ┆ i64             ┆              ┆               ┆ f64             │\n",
      "╞══════╪══════╪═════════════════╪═════════════════╪══════════════╪═══════════════╪═════════════════╡\n",
      "│ 0.5  ┆ 1    ┆ 1               ┆ 1               ┆ 1            ┆ 1             ┆ 1.0             │\n",
      "│ 1.0  ┆ null ┆ 3               ┆ 2               ┆ 1            ┆ 3             ┆ 2.0             │\n",
      "│ 1.5  ┆ 3    ┆ 3               ┆ 3               ┆ 3            ┆ 3             ┆ 3.0             │\n",
      "│ 2.0  ┆ null ┆ 3               ┆ 4               ┆ 3            ┆ 5             ┆ 4.0             │\n",
      "│ 2.5  ┆ 5    ┆ 5               ┆ 5               ┆ 5            ┆ 5             ┆ 5.0             │\n",
      "└──────┴──────┴─────────────────┴─────────────────┴──────────────┴───────────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"col1\": [0.5, 1, 1.5, 2, 2.5],\n",
    "        \"col2\": [1, None, 3, None, 5],\n",
    "    },\n",
    ")\n",
    "fill_df = df.with_columns(\n",
    "    pl.col(\"col2\").fill_null(3).alias(\"fill_by_literal\"),\n",
    "    pl.col(\"col2\")\n",
    "    .fill_null((2 * pl.col(\"col1\")).cast(pl.Int64))\n",
    "    .alias(\"fill_by_other_col\"),\n",
    "    pl.col(\"col2\").fill_null(strategy=\"forward\").alias(\"fill_forward\"),\n",
    "    pl.col(\"col2\").fill_null(strategy=\"backward\").alias(\"fill_backward\"),\n",
    "    pl.col(\"col2\").interpolate().alias(\"fill_by_interpolation\"),\n",
    ")\n",
    "print(fill_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>col1</th><th>col2</th></tr><tr><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>0.5</td><td>1</td></tr><tr><td>1.5</td><td>3</td></tr><tr><td>2.5</td><td>5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌──────┬──────┐\n",
       "│ col1 ┆ col2 │\n",
       "│ ---  ┆ ---  │\n",
       "│ f64  ┆ i64  │\n",
       "╞══════╪══════╡\n",
       "│ 0.5  ┆ 1    │\n",
       "│ 1.5  ┆ 3    │\n",
       "│ 2.5  ┆ 5    │\n",
       "└──────┴──────┘"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_nulls(\"col2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NaN value\n",
    "\n",
    "`NaN` (Not a Number) values are considered to be a type of floating point data and **are not considered to be missing data** (`null`) in Polars:\n",
    "- `NaN` values are not counted with the function `null_count`\n",
    "- `NaN` values are filled when you use the specialised function `fill_nan` method **but are not filled** with the function `fill_null`.\n",
    "- Polars has the functions `is_nan` and `fill_nan`, which work in a similar way to the functions `is_null` and `fill_null`, but only use for `NaN` value\n",
    "- Các phương thức tính toán (`mean`, `sum`, ...) sẽ bỏ qua giá trị missing `null` nhưng sẽ bao gồm cả giá trị `NaN`. Do đó, để tránh ảnh hưởng đến kết quả bởi giá trị `NaN`, ta cần fill `NaN` bởi `null` trước khi tính toán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF generate NaN value\n",
      "shape: (3, 1)\n",
      "┌──────────┐\n",
      "│ dividend │\n",
      "│ ---      │\n",
      "│ f64      │\n",
      "╞══════════╡\n",
      "│ 1.0      │\n",
      "│ NaN      │\n",
      "│ 1.0      │\n",
      "└──────────┘\n",
      "--------------\n",
      "DF with NaN value\n",
      "shape: (4, 1)\n",
      "┌────────────────────┐\n",
      "│ raw_value_with_NaN │\n",
      "│ ---                │\n",
      "│ f64                │\n",
      "╞════════════════════╡\n",
      "│ 1.0                │\n",
      "│ NaN                │\n",
      "│ NaN                │\n",
      "│ 3.0                │\n",
      "└────────────────────┘\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"DF generate NaN value\")\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"dividend\": [1, 0, -1],\n",
    "        \"divisor\": [1, 0, -1],\n",
    "    }\n",
    ")\n",
    "result = df.select(pl.col(\"dividend\") / pl.col(\"divisor\"))\n",
    "\n",
    "print(result, end=\"\\n--------------\\n\")\n",
    "\n",
    "print(\"DF with NaN value\")\n",
    "nan_df = pl.DataFrame(\n",
    "    {\n",
    "        \"raw_value_with_NaN\": [1.0, np.nan, float(\"nan\"), 3.0],\n",
    "    },\n",
    ")\n",
    "print(nan_df, end=\"\\n--------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling NaN value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>raw_value_with_NaN_mean</th><th>replaced_by_missing_null_mean</th><th>raw_value_with_NaN_sum</th><th>replaced_by_missing_null_sum</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>NaN</td><td>2.0</td><td>NaN</td><td>4.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 4)\n",
       "┌────────────────────────┬────────────────────────┬────────────────────────┬───────────────────────┐\n",
       "│ raw_value_with_NaN_mea ┆ replaced_by_missing_nu ┆ raw_value_with_NaN_sum ┆ replaced_by_missing_n │\n",
       "│ n                      ┆ ll_mean                ┆ ---                    ┆ ull_sum               │\n",
       "│ ---                    ┆ ---                    ┆ f64                    ┆ ---                   │\n",
       "│ f64                    ┆ f64                    ┆                        ┆ f64                   │\n",
       "╞════════════════════════╪════════════════════════╪════════════════════════╪═══════════════════════╡\n",
       "│ NaN                    ┆ 2.0                    ┆ NaN                    ┆ 4.0                   │\n",
       "└────────────────────────┴────────────────────────┴────────────────────────┴───────────────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Handling NaN value\")\n",
    "mean_nan_df = nan_df.with_columns(\n",
    "    pl.col(\"raw_value_with_NaN\")\n",
    "    .fill_nan(None)\n",
    "    .alias(\"replaced_by_missing_null\"),\n",
    ").select(\n",
    "    pl.all().mean().name.suffix(\"_mean\"),\n",
    "    pl.all().sum().name.suffix(\"_sum\"),\n",
    ")\n",
    "mean_nan_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace series\n",
    "\n",
    "`zip_with`: Where mask evaluates `true`, take values from `self`. Where mask evaluates `false`, take values from `other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th></th></tr><tr><td>i64</td></tr></thead><tbody><tr><td>1</td></tr><tr><td>2</td></tr><tr><td>3</td></tr><tr><td>2</td></tr><tr><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5,)\n",
       "Series: '' [i64]\n",
       "[\n",
       "\t1\n",
       "\t2\n",
       "\t3\n",
       "\t2\n",
       "\t1\n",
       "]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = pl.Series([1, 2, 3, 4, 5])\n",
    "s2 = pl.Series([5, 4, 3, 2, 1])\n",
    "s1.zip_with(s1 < s2, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "url = \"https://theunitedstates.io/congress-legislators/legislators-historical.csv\"\n",
    "\n",
    "schema_overrides = {\n",
    "    \"first_name\": pl.Categorical,\n",
    "    \"gender\": pl.Categorical,\n",
    "    \"type\": pl.Categorical,\n",
    "    \"state\": pl.Categorical,\n",
    "    \"party\": pl.Categorical,\n",
    "}\n",
    "\n",
    "dataset = pl.read_csv(url, schema_overrides=schema_overrides).with_columns(\n",
    "    pl.col(\"birthday\").str.to_date(strict=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 36)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>last_name</th><th>first_name</th><th>middle_name</th><th>suffix</th><th>nickname</th><th>full_name</th><th>birthday</th><th>gender</th><th>type</th><th>state</th><th>district</th><th>senate_class</th><th>party</th><th>url</th><th>address</th><th>phone</th><th>contact_form</th><th>rss_url</th><th>twitter</th><th>twitter_id</th><th>facebook</th><th>youtube</th><th>youtube_id</th><th>mastodon</th><th>bioguide_id</th><th>thomas_id</th><th>opensecrets_id</th><th>lis_id</th><th>fec_ids</th><th>cspan_id</th><th>govtrack_id</th><th>votesmart_id</th><th>ballotpedia_id</th><th>washington_post_id</th><th>icpsr_id</th><th>wikipedia_id</th></tr><tr><td>str</td><td>cat</td><td>str</td><td>str</td><td>str</td><td>str</td><td>date</td><td>cat</td><td>cat</td><td>cat</td><td>i64</td><td>i64</td><td>cat</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;Bassett&quot;</td><td>&quot;Richard&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1745-04-02</td><td>&quot;M&quot;</td><td>&quot;sen&quot;</td><td>&quot;DE&quot;</td><td>null</td><td>2</td><td>&quot;Anti-Administration&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;B000226&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>401222</td><td>null</td><td>null</td><td>null</td><td>507</td><td>&quot;Richard Bassett (Delaware poli…</td></tr><tr><td>&quot;Bland&quot;</td><td>&quot;Theodorick&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1742-03-21</td><td>&quot;M&quot;</td><td>&quot;rep&quot;</td><td>&quot;VA&quot;</td><td>9</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;B000546&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>401521</td><td>null</td><td>null</td><td>null</td><td>786</td><td>&quot;Theodorick Bland (congressman)&quot;</td></tr><tr><td>&quot;Burke&quot;</td><td>&quot;Aedanus&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1743-06-16</td><td>&quot;M&quot;</td><td>&quot;rep&quot;</td><td>&quot;SC&quot;</td><td>2</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;B001086&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>402032</td><td>null</td><td>null</td><td>null</td><td>1260</td><td>&quot;Aedanus Burke&quot;</td></tr><tr><td>&quot;Carroll&quot;</td><td>&quot;Daniel&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1730-07-22</td><td>&quot;M&quot;</td><td>&quot;rep&quot;</td><td>&quot;MD&quot;</td><td>6</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;C000187&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>402334</td><td>null</td><td>null</td><td>null</td><td>1538</td><td>&quot;Daniel Carroll&quot;</td></tr><tr><td>&quot;Clymer&quot;</td><td>&quot;George&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1739-03-16</td><td>&quot;M&quot;</td><td>&quot;rep&quot;</td><td>&quot;PA&quot;</td><td>-1</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;C000538&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>402671</td><td>null</td><td>null</td><td>null</td><td>1859</td><td>&quot;George Clymer&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 36)\n",
       "┌───────────┬────────────┬────────────┬────────┬───┬────────────┬───────────┬──────────┬───────────┐\n",
       "│ last_name ┆ first_name ┆ middle_nam ┆ suffix ┆ … ┆ ballotpedi ┆ washingto ┆ icpsr_id ┆ wikipedia │\n",
       "│ ---       ┆ ---        ┆ e          ┆ ---    ┆   ┆ a_id       ┆ n_post_id ┆ ---      ┆ _id       │\n",
       "│ str       ┆ cat        ┆ ---        ┆ str    ┆   ┆ ---        ┆ ---       ┆ i64      ┆ ---       │\n",
       "│           ┆            ┆ str        ┆        ┆   ┆ str        ┆ str       ┆          ┆ str       │\n",
       "╞═══════════╪════════════╪════════════╪════════╪═══╪════════════╪═══════════╪══════════╪═══════════╡\n",
       "│ Bassett   ┆ Richard    ┆ null       ┆ null   ┆ … ┆ null       ┆ null      ┆ 507      ┆ Richard   │\n",
       "│           ┆            ┆            ┆        ┆   ┆            ┆           ┆          ┆ Bassett   │\n",
       "│           ┆            ┆            ┆        ┆   ┆            ┆           ┆          ┆ (Delaware │\n",
       "│           ┆            ┆            ┆        ┆   ┆            ┆           ┆          ┆ poli…     │\n",
       "│ Bland     ┆ Theodorick ┆ null       ┆ null   ┆ … ┆ null       ┆ null      ┆ 786      ┆ Theodoric │\n",
       "│           ┆            ┆            ┆        ┆   ┆            ┆           ┆          ┆ k Bland   │\n",
       "│           ┆            ┆            ┆        ┆   ┆            ┆           ┆          ┆ (congress │\n",
       "│           ┆            ┆            ┆        ┆   ┆            ┆           ┆          ┆ man)      │\n",
       "│ Burke     ┆ Aedanus    ┆ null       ┆ null   ┆ … ┆ null       ┆ null      ┆ 1260     ┆ Aedanus   │\n",
       "│           ┆            ┆            ┆        ┆   ┆            ┆           ┆          ┆ Burke     │\n",
       "│ Carroll   ┆ Daniel     ┆ null       ┆ null   ┆ … ┆ null       ┆ null      ┆ 1538     ┆ Daniel    │\n",
       "│           ┆            ┆            ┆        ┆   ┆            ┆           ┆          ┆ Carroll   │\n",
       "│ Clymer    ┆ George     ┆ null       ┆ null   ┆ … ┆ null       ┆ null      ┆ 1859     ┆ George    │\n",
       "│           ┆            ┆            ┆        ┆   ┆            ┆           ┆          ┆ Clymer    │\n",
       "└───────────┴────────────┴────────────┴────────┴───┴────────────┴───────────┴──────────┴───────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`group_by`**\n",
    "\n",
    "After using `group_by` we use `agg` to apply aggregating expressions to the groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 14)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>first_name</th><th>birthyear</th><th>len</th><th>gender</th><th>last_name</th><th>count_govtrack_id</th><th>count_icpsr_id</th><th>anti</th><th>avg M birthday</th><th>avg F birthday</th><th>youngest</th><th>oldest</th><th>alphabetical_first</th><th>sort_by_another_column</th></tr><tr><td>cat</td><td>i32</td><td>u32</td><td>list[cat]</td><td>str</td><td>u32</td><td>u32</td><td>u32</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>cat</td></tr></thead><tbody><tr><td>&quot;John&quot;</td><td>1826</td><td>19</td><td>[&quot;M&quot;, &quot;M&quot;, … &quot;M&quot;]</td><td>&quot;Ferdon&quot;</td><td>19</td><td>19</td><td>0</td><td>198.0</td><td>null</td><td>&quot;John Ferdon&quot;</td><td>&quot;John Eden&quot;</td><td>&quot;John Burch&quot;</td><td>&quot;M&quot;</td></tr><tr><td>&quot;John&quot;</td><td>1825</td><td>16</td><td>[&quot;M&quot;, &quot;M&quot;, … &quot;M&quot;]</td><td>&quot;Hungerford&quot;</td><td>16</td><td>16</td><td>0</td><td>199.0</td><td>null</td><td>&quot;John Hungerford&quot;</td><td>&quot;John Hoge&quot;</td><td>&quot;John Atkins&quot;</td><td>&quot;M&quot;</td></tr><tr><td>&quot;John&quot;</td><td>1831</td><td>16</td><td>[&quot;M&quot;, &quot;M&quot;, … &quot;M&quot;]</td><td>&quot;McCormick&quot;</td><td>16</td><td>16</td><td>0</td><td>193.0</td><td>null</td><td>&quot;John McCormick&quot;</td><td>&quot;John Clark&quot;</td><td>&quot;John Arnot&quot;</td><td>&quot;M&quot;</td></tr><tr><td>&quot;John&quot;</td><td>1835</td><td>15</td><td>[&quot;M&quot;, &quot;M&quot;, … &quot;M&quot;]</td><td>&quot;Coghlan&quot;</td><td>15</td><td>14</td><td>0</td><td>189.0</td><td>null</td><td>&quot;John Coghlan&quot;</td><td>&quot;John Gilfillan&quot;</td><td>&quot;John Brown&quot;</td><td>&quot;M&quot;</td></tr><tr><td>&quot;John&quot;</td><td>1845</td><td>14</td><td>[&quot;M&quot;, &quot;M&quot;, … &quot;M&quot;]</td><td>&quot;Tarsney&quot;</td><td>14</td><td>14</td><td>0</td><td>179.0</td><td>null</td><td>&quot;John Tarsney&quot;</td><td>&quot;John Smith&quot;</td><td>&quot;John Allen&quot;</td><td>&quot;M&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 14)\n",
       "┌────────────┬───────────┬─────┬────────────┬───┬────────────┬────────────┬────────────┬───────────┐\n",
       "│ first_name ┆ birthyear ┆ len ┆ gender     ┆ … ┆ youngest   ┆ oldest     ┆ alphabetic ┆ sort_by_a │\n",
       "│ ---        ┆ ---       ┆ --- ┆ ---        ┆   ┆ ---        ┆ ---        ┆ al_first   ┆ nother_co │\n",
       "│ cat        ┆ i32       ┆ u32 ┆ list[cat]  ┆   ┆ str        ┆ str        ┆ ---        ┆ lumn      │\n",
       "│            ┆           ┆     ┆            ┆   ┆            ┆            ┆ str        ┆ ---       │\n",
       "│            ┆           ┆     ┆            ┆   ┆            ┆            ┆            ┆ cat       │\n",
       "╞════════════╪═══════════╪═════╪════════════╪═══╪════════════╪════════════╪════════════╪═══════════╡\n",
       "│ John       ┆ 1826      ┆ 19  ┆ [\"M\", \"M\", ┆ … ┆ John       ┆ John Eden  ┆ John Burch ┆ M         │\n",
       "│            ┆           ┆     ┆ … \"M\"]     ┆   ┆ Ferdon     ┆            ┆            ┆           │\n",
       "│ John       ┆ 1825      ┆ 16  ┆ [\"M\", \"M\", ┆ … ┆ John       ┆ John Hoge  ┆ John       ┆ M         │\n",
       "│            ┆           ┆     ┆ … \"M\"]     ┆   ┆ Hungerford ┆            ┆ Atkins     ┆           │\n",
       "│ John       ┆ 1831      ┆ 16  ┆ [\"M\", \"M\", ┆ … ┆ John       ┆ John Clark ┆ John Arnot ┆ M         │\n",
       "│            ┆           ┆     ┆ … \"M\"]     ┆   ┆ McCormick  ┆            ┆            ┆           │\n",
       "│ John       ┆ 1835      ┆ 15  ┆ [\"M\", \"M\", ┆ … ┆ John       ┆ John       ┆ John Brown ┆ M         │\n",
       "│            ┆           ┆     ┆ … \"M\"]     ┆   ┆ Coghlan    ┆ Gilfillan  ┆            ┆           │\n",
       "│ John       ┆ 1845      ┆ 14  ┆ [\"M\", \"M\", ┆ … ┆ John       ┆ John Smith ┆ John Allen ┆ M         │\n",
       "│            ┆           ┆     ┆ … \"M\"]     ┆   ┆ Tarsney    ┆            ┆            ┆           │\n",
       "└────────────┴───────────┴─────┴────────────┴───┴────────────┴────────────┴────────────┴───────────┘"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "\n",
    "def compute_age():\n",
    "    return date.today().year - pl.col(\"birthday\").dt.year()\n",
    "\n",
    "\n",
    "def avg_birthday(gender: str) -> pl.Expr:\n",
    "    return (\n",
    "        compute_age()\n",
    "        .filter(pl.col(\"gender\") == gender)\n",
    "        .mean()\n",
    "        .alias(f\"avg {gender} birthday\")\n",
    "    )\n",
    "\n",
    "\n",
    "def get_name() -> pl.Expr:\n",
    "    return pl.col(\"first_name\") + pl.lit(\" \") + pl.col(\"last_name\")\n",
    "\n",
    "\n",
    "q = (\n",
    "    dataset.lazy()\n",
    "    .filter(pl.col(\"type\").is_not_null())  # filter dataset before group by\n",
    "    .sort(\"birthday\", descending=True)  # sort dataset before aggregate\n",
    "    .group_by(\n",
    "        \"first_name\",\n",
    "        pl.col(\"birthday\").dt.year().alias(\"birthyear\"),\n",
    "    )\n",
    "    .agg(\n",
    "        # count the number of rows in the group (which means we count how many people in the data set have each unique first name)\n",
    "        pl.len(),\n",
    "        # combine the values of the column “gender” into a list by referring the column but omitting an aggregate function\n",
    "        pl.col(\"gender\"),\n",
    "        # get the first value of the column “last_name” within the group\n",
    "        pl.first(\"last_name\"),  # Short for `pl.col(\"last_name\").first()`\n",
    "        # Expression expansion\n",
    "        pl.col(\"govtrack_id\", \"icpsr_id\").count().name.prefix(\"count_\"),\n",
    "        # (Conditional expression) how many delegates of a state are “Pro” administration\n",
    "        (pl.col(\"party\") == \"Anti-Administration\").sum().alias(\"anti\"),\n",
    "        # filter group but dont need to filter dataset bởi vì có thể ảnh hưởng đến các expression khác\n",
    "        avg_birthday(\"M\"),\n",
    "        avg_birthday(\"F\"),\n",
    "        # after sort by birthday, we get the youngest and oldest\n",
    "        get_name().first().alias(\"youngest\"),\n",
    "        get_name().last().alias(\"oldest\"),\n",
    "        # sort in group (not use sorted in dataframe)\n",
    "        get_name().sort().first().alias(\"alphabetical_first\"),\n",
    "        # sort by another columns\n",
    "        pl.col(\"gender\")\n",
    "        .sort_by(get_name())\n",
    "        .first()\n",
    "        .alias(\"sort_by_another_column\"),\n",
    "    )\n",
    "    .filter(pl.col(\"birthyear\").is_not_null())  # filter dataset after group by\n",
    "    .sort(\"len\", descending=True)  # immediately sort the result\n",
    "    .limit(5)  # limit it to the top five rows\n",
    ")\n",
    "\n",
    "df = q.collect()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> the groups of that column as lists\n",
    "\n",
    "For multi-label of grouper and multi expressions each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 6)\n",
      "┌────────┬────────┬─────┬─────────┬────────────┬────────────┐\n",
      "│ decade ┆ short? ┆ len ┆ tallest ┆ avg_weight ┆ avg_height │\n",
      "│ ---    ┆ ---    ┆ --- ┆ ---     ┆ ---        ┆ ---        │\n",
      "│ i32    ┆ bool   ┆ u32 ┆ f64     ┆ f64        ┆ f64        │\n",
      "╞════════╪════════╪═════╪═════════╪════════════╪════════════╡\n",
      "│ 1980   ┆ true   ┆ 1   ┆ 1.65    ┆ 53.6       ┆ 1.65       │\n",
      "│ 1990   ┆ true   ┆ 1   ┆ 1.56    ┆ 57.9       ┆ 1.56       │\n",
      "│ 1980   ┆ false  ┆ 2   ┆ 1.77    ┆ 77.8       ┆ 1.76       │\n",
      "└────────┴────────┴─────┴─────────┴────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.group_by(\n",
    "    (pl.col(\"birthdate\").dt.year() // 10 * 10).alias(\n",
    "        \"decade\"\n",
    "    ),  # group by label 1\n",
    "    (pl.col(\"height\") < 1.7).alias(\"short?\"),  # group by label 2\n",
    ").agg(\n",
    "    pl.len(),\n",
    "    pl.col(\"height\").max().alias(\"tallest\"),\n",
    "    pl.col(\"weight\", \"height\").mean().name.prefix(\"avg_\"),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom Function in Group By**\n",
    "\n",
    "Python thường chậm hơn Rust. Ngoài chi phí chạy mã byte \"chậm\", Python còn phải nằm trong giới hạn của Khóa phiên dịch toàn cầu (GIL). Điều này có nghĩa là nếu bạn sử dụng lambda hoặc hàm Python tùy chỉnh để áp dụng trong giai đoạn song song, tốc độ của Polars sẽ bị giới hạn khi chạy mã Python, ngăn không cho nhiều luồng thực thi hàm. Polars sẽ cố gắng song song hóa việc tính toán các hàm tổng hợp trên các nhóm, vì vậy bạn nên tránh sử dụng lambda và các hàm Python tùy chỉnh càng nhiều càng tốt. Thay vào đó, hãy cố gắng duy trì trong phạm vi API biểu thức Polars. Tuy nhiên, điều này không phải lúc nào cũng thực hiện được, vì vậy nếu muốn tìm hiểu thêm về cách sử dụng `lambda`, bạn có thể xem [Custom Function](https://docs.pola.rs/user-guide/expressions/user-defined-python-functions/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `group_by_dynamic`\n",
    "\n",
    "(See in Time Series Section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom function\n",
    "\n",
    "(https://docs.pola.rs/user-guide/expressions/user-defined-python-functions/)\n",
    "\n",
    "**NOTE**: Việc sử dụng custom function có thể ảnh hướng đến performance khi thực hiện tính toán song song của polars. Do đó, hãy cố gắng tận dụng các [python API](https://docs.pola.rs/api/python/stable/reference/index.html), thay vì là các function tuỳ chỉnh. Tuy nhiên trong TH cần thiết, ta có:\n",
    "- `map_elements`: Mỗi 1 giá trị sẽ chạy qua 1 function nào đó, và không liên quan đến giá trị khác trong seri\n",
    "- `map_batches`: Pass full seri vào function và trả ra 1 seri tương ứng là các value đã được biến đổi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `map_elements`\n",
    "\n",
    "Mỗi 1 giá trị sẽ chạy qua 1 function nào đó, và không liên quan đến giá trị khác trong seri\n",
    "\n",
    "Problem with `map_elements`:\n",
    "- Limited to individual items: Thông thường, bạn sẽ muốn có một phép tính cần thực hiện trên toàn bộ Chuỗi, thay vì từng mục riêng lẻ.\n",
    "- Performance overhead: Ngay cả khi bạn muốn xử lý từng mục riêng lẻ, việc gọi một hàm cho từng mục riêng lẻ vẫn chậm; tất cả các lệnh gọi hàm bổ sung đó đều bổ sung thêm rất nhiều chi phí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 1)\n",
      "┌──────────┐\n",
      "│ values   │\n",
      "│ ---      │\n",
      "│ f64      │\n",
      "╞══════════╡\n",
      "│ 2.302585 │\n",
      "│ 1007.0   │\n",
      "│ 1001.0   │\n",
      "│ 1023.0   │\n",
      "└──────────┘\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"keys\": [\"a\", \"a\", \"b\", \"b\"],\n",
    "        \"values\": [10, 7, 1, 23],\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def my_log(value):\n",
    "    if (value % 2) == 0:\n",
    "        return math.log(value)\n",
    "    else:\n",
    "        return value + 1000\n",
    "\n",
    "\n",
    "out = df.select(pl.col(\"values\").map_elements(my_log, return_dtype=pl.Float64))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `map_batches`\n",
    "\n",
    "Pass full seri vào function và trả ra 1 seri tương ứng là các value đã được biến đổi.\n",
    "\n",
    "- You can pass a `return_dtype` argument to  `map_batches` if you want to override the inferred type.\n",
    "    - `int` -> `Int64`\n",
    "    - `float` -> `Float64`\n",
    "    - `bool` -> `Boolean`\n",
    "    - `str` -> `String`\n",
    "    - `list[tp]` -> `List[tp]` (where the inner type is inferred with the same rules)\n",
    "    - `dict[str, [tp]]` -> `struct`\n",
    "    - `Any` -> `object` (Prevent this at all times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== select() with UDF ==\n",
      "shape: (4, 2)\n",
      "┌──────┬────────┐\n",
      "│ keys ┆ values │\n",
      "│ ---  ┆ ---    │\n",
      "│ str  ┆ f64    │\n",
      "╞══════╪════════╡\n",
      "│ a    ┆ -0.25  │\n",
      "│ a    ┆ -3.25  │\n",
      "│ b    ┆ -9.25  │\n",
      "│ b    ┆ 12.75  │\n",
      "└──────┴────────┘\n",
      "== group_by() with UDF ==\n",
      "shape: (2, 2)\n",
      "┌──────┬───────────────┐\n",
      "│ keys ┆ values        │\n",
      "│ ---  ┆ ---           │\n",
      "│ str  ┆ list[f64]     │\n",
      "╞══════╪═══════════════╡\n",
      "│ b    ┆ [-11.0, 11.0] │\n",
      "│ a    ┆ [1.5, -1.5]   │\n",
      "└──────┴───────────────┘\n",
      "shape: (4, 3)\n",
      "┌──────┬────────┬─────────────────┐\n",
      "│ keys ┆ values ┆ values_each_grp │\n",
      "│ ---  ┆ ---    ┆ ---             │\n",
      "│ str  ┆ i64    ┆ f64             │\n",
      "╞══════╪════════╪═════════════════╡\n",
      "│ a    ┆ 10     ┆ 1.5             │\n",
      "│ a    ┆ 7      ┆ -1.5            │\n",
      "│ b    ┆ 1      ┆ -11.0           │\n",
      "│ b    ┆ 23     ┆ 11.0            │\n",
      "└──────┴────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "def diff_from_mean(series):\n",
    "    # This will be very slow for non-trivial Series, since it's all Python\n",
    "    # code:\n",
    "    total = 0\n",
    "    for value in series:\n",
    "        total += value\n",
    "    mean = total / len(series)\n",
    "    return pl.Series([value - mean for value in series])\n",
    "\n",
    "\n",
    "# Apply our custom function to a full Series with map_batches():\n",
    "out = df.with_columns(pl.col(\"values\").map_batches(diff_from_mean))\n",
    "print(\"== select() with UDF ==\")\n",
    "print(out)\n",
    "\n",
    "# Apply our custom function per group:\n",
    "print(\"== group_by() with UDF ==\")\n",
    "out = df.group_by(\"keys\").agg(pl.col(\"values\").map_batches(diff_from_mean))\n",
    "print(out)\n",
    "\n",
    "# Apply our custom function per group and get original df\n",
    "out2 = df.with_columns(\n",
    "    pl.col(\"values\")\n",
    "    .map_batches(diff_from_mean)\n",
    "    .over(\"keys\")\n",
    "    .alias(\"values_each_grp\")\n",
    ")\n",
    "print(out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize custom function\n",
    "\n",
    "- Sử dụng các hàm được viết bằng compiled language\n",
    "    - For numeric: các hàm `numpy`, `scipy`\n",
    "    - Sử dụng [`numba`](https://numba.readthedocs.io/en/stable/) để compiling lại function, đặc biệt có thể decorate bằng [@guvectorize](https://numba.readthedocs.io/en/stable/user/vectorize.html#the-guvectorize-decorator), cho phép tạo ra ufunc by compiling a Python function to fast machine code.\n",
    "    > NOTE: Missing data is not allowed when calling generalized ufuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== select() with UDF ==\n",
      "shape: (4, 1)\n",
      "┌────────┐\n",
      "│ values │\n",
      "│ ---    │\n",
      "│ f64    │\n",
      "╞════════╡\n",
      "│ -0.25  │\n",
      "│ -3.25  │\n",
      "│ -9.25  │\n",
      "│ 12.75  │\n",
      "└────────┘\n",
      "== group_by() with UDF ==\n",
      "shape: (2, 2)\n",
      "┌──────┬───────────────┐\n",
      "│ keys ┆ values        │\n",
      "│ ---  ┆ ---           │\n",
      "│ str  ┆ list[f64]     │\n",
      "╞══════╪═══════════════╡\n",
      "│ a    ┆ [1.5, -1.5]   │\n",
      "│ b    ┆ [-11.0, 11.0] │\n",
      "└──────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "from numba import float64, guvectorize, int64\n",
    "\n",
    "\n",
    "# This will be compiled to machine code, so it will be fast. The Series is\n",
    "# converted to a NumPy array before being passed to the function. See the\n",
    "# Numba documentation for more details:\n",
    "# https://numba.readthedocs.io/en/stable/user/vectorize.html\n",
    "@guvectorize([(int64[:], float64[:])], \"(n)->(n)\")\n",
    "def diff_from_mean_numba(arr, result):\n",
    "    total = 0\n",
    "    for value in arr:\n",
    "        total += value\n",
    "    mean = total / len(arr)\n",
    "    for i, value in enumerate(arr):\n",
    "        result[i] = value - mean\n",
    "\n",
    "\n",
    "out = df.select(pl.col(\"values\").map_batches(diff_from_mean_numba))\n",
    "print(\"== select() with UDF ==\")\n",
    "print(out)\n",
    "\n",
    "out = df.group_by(\"keys\").agg(\n",
    "    pl.col(\"values\").map_batches(diff_from_mean_numba)\n",
    ")\n",
    "print(\"== group_by() with UDF ==\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sử dụng `is_elementwise=True` argument in `map_batches` to stream results into the function, which means it might not get all values at once. Nhưng phải đảm bảo function được thực hiện trên từng element (thay vì cần dựa trên các elements khác nữa)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For multi-columns\n",
    "\n",
    "Combine multiple columns into a `Struct`, and then the function can extract the columns back out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 1)\n",
      "┌─────────────┐\n",
      "│ add_columns │\n",
      "│ ---         │\n",
      "│ f64         │\n",
      "╞═════════════╡\n",
      "│ 11.0        │\n",
      "│ 22.0        │\n",
      "│ 33.0        │\n",
      "└─────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Add two arrays together:\n",
    "@guvectorize([(int64[:], int64[:], float64[:])], \"(n),(n)->(n)\")\n",
    "def add(arr, arr2, result):\n",
    "    for i in range(len(arr)):\n",
    "        result[i] = arr[i] + arr2[i]\n",
    "\n",
    "\n",
    "df3 = pl.DataFrame({\"values1\": [1, 2, 3], \"values2\": [10, 20, 30]})\n",
    "\n",
    "out = df3.select(\n",
    "    # Create a struct that has two columns in it:\n",
    "    pl.struct([\"values1\", \"values2\"])\n",
    "    # Pass the struct to a lambda that then passes the individual columns to\n",
    "    # the add() function:\n",
    "    .map_batches(\n",
    "        lambda combined: add(\n",
    "            combined.struct.field(\"values1\"), combined.struct.field(\"values2\")\n",
    "        )\n",
    "    )\n",
    "    .alias(\"add_columns\")\n",
    ")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window functions\n",
    "\n",
    "Là hàm cho phép tính toán trên từng group và trả kết quả trong df ban đầu thông qua method `over` giống như window để tính toán\n",
    "\n",
    "Tham số:\n",
    "- `mapping_strategy` that determines how the results of the expression over the group are mapped back to the rows of the dataframe.\n",
    "    - `mapping_strategy = 'group_to_rows'`: kết quả trả ra có thứ tự các dòng giống với original dataframe\n",
    "    - `mapping_strategy = 'explode'`: Nếu không quan trọng thứ tự dòng trong original dataframe, nên sử dụng `explode` để cải thiện perform, khi đó các dòng cùng group sẽ đứng cạnh nhau.\n",
    "    - `mapping_strategy = 'join'`: biểu diễn kết quả thành list các giá trị output trong group đó, và repeat lại cho các dòng trong cùng 1 group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 13)\n",
      "┌─────┬───────────────────────┬────────┬────────┬───┬─────────┬───────┬────────────┬───────────┐\n",
      "│ #   ┆ Name                  ┆ Type 1 ┆ Type 2 ┆ … ┆ Sp. Def ┆ Speed ┆ Generation ┆ Legendary │\n",
      "│ --- ┆ ---                   ┆ ---    ┆ ---    ┆   ┆ ---     ┆ ---   ┆ ---        ┆ ---       │\n",
      "│ i64 ┆ str                   ┆ enum   ┆ enum   ┆   ┆ i64     ┆ i64   ┆ i64        ┆ bool      │\n",
      "╞═════╪═══════════════════════╪════════╪════════╪═══╪═════════╪═══════╪════════════╪═══════════╡\n",
      "│ 1   ┆ Bulbasaur             ┆ Grass  ┆ Poison ┆ … ┆ 65      ┆ 45    ┆ 1          ┆ false     │\n",
      "│ 2   ┆ Ivysaur               ┆ Grass  ┆ Poison ┆ … ┆ 80      ┆ 60    ┆ 1          ┆ false     │\n",
      "│ 3   ┆ Venusaur              ┆ Grass  ┆ Poison ┆ … ┆ 100     ┆ 80    ┆ 1          ┆ false     │\n",
      "│ 3   ┆ VenusaurMega Venusaur ┆ Grass  ┆ Poison ┆ … ┆ 120     ┆ 80    ┆ 1          ┆ false     │\n",
      "│ 4   ┆ Charmander            ┆ Fire   ┆ null   ┆ … ┆ 50      ┆ 65    ┆ 1          ┆ false     │\n",
      "└─────┴───────────────────────┴────────┴────────┴───┴─────────┴───────┴────────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "types = \"Grass Water Fire Normal Ground Electric Psychic Fighting Bug Steel Flying Dragon Dark Ghost Poison Rock Ice Fairy\".split()\n",
    "type_enum = pl.Enum(types)\n",
    "# then let's load some csv data with information about pokemon\n",
    "pokemon = pl.read_csv(\n",
    "    \"https://gist.githubusercontent.com/ritchie46/cac6b337ea52281aa23c049250a4ff03/raw/89a957ff3919d90e6ef2d34235e6bf22304f3366/pokemon.csv\",\n",
    ").cast({\"Type 1\": type_enum, \"Type 2\": type_enum})\n",
    "print(pokemon.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (163, 3)\n",
      "┌───────────────────────┬─────────┬────────────┐\n",
      "│ Name                  ┆ Type 1  ┆ Speed rank │\n",
      "│ ---                   ┆ ---     ┆ ---        │\n",
      "│ str                   ┆ enum    ┆ u32        │\n",
      "╞═══════════════════════╪═════════╪════════════╡\n",
      "│ Bulbasaur             ┆ Grass   ┆ 6          │\n",
      "│ Ivysaur               ┆ Grass   ┆ 3          │\n",
      "│ Venusaur              ┆ Grass   ┆ 1          │\n",
      "│ VenusaurMega Venusaur ┆ Grass   ┆ 1          │\n",
      "│ Charmander            ┆ Fire    ┆ 7          │\n",
      "│ …                     ┆ …       ┆ …          │\n",
      "│ Moltres               ┆ Fire    ┆ 5          │\n",
      "│ Dratini               ┆ Dragon  ┆ 3          │\n",
      "│ Dragonair             ┆ Dragon  ┆ 2          │\n",
      "│ Dragonite             ┆ Dragon  ┆ 1          │\n",
      "│ Mewtwo                ┆ Psychic ┆ 2          │\n",
      "└───────────────────────┴─────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Rank by each group\n",
    "result = pokemon.select(\n",
    "    pl.col(\"Name\", \"Type 1\"),\n",
    "    pl.col(\"Speed\")\n",
    "    .rank(\"dense\", descending=True)\n",
    "    .over(\"Type 1\")\n",
    "    .alias(\"Speed rank\"),\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Over multi-group**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (163, 4)\n",
      "┌───────────────────────┬─────────┬────────┬────────────┐\n",
      "│ Name                  ┆ Type 1  ┆ Type 2 ┆ Speed rank │\n",
      "│ ---                   ┆ ---     ┆ ---    ┆ ---        │\n",
      "│ str                   ┆ enum    ┆ enum   ┆ u32        │\n",
      "╞═══════════════════════╪═════════╪════════╪════════════╡\n",
      "│ Bulbasaur             ┆ Grass   ┆ Poison ┆ 6          │\n",
      "│ Ivysaur               ┆ Grass   ┆ Poison ┆ 3          │\n",
      "│ Venusaur              ┆ Grass   ┆ Poison ┆ 1          │\n",
      "│ VenusaurMega Venusaur ┆ Grass   ┆ Poison ┆ 1          │\n",
      "│ Charmander            ┆ Fire    ┆ null   ┆ 7          │\n",
      "│ …                     ┆ …       ┆ …      ┆ …          │\n",
      "│ Moltres               ┆ Fire    ┆ Flying ┆ 2          │\n",
      "│ Dratini               ┆ Dragon  ┆ null   ┆ 2          │\n",
      "│ Dragonair             ┆ Dragon  ┆ null   ┆ 1          │\n",
      "│ Dragonite             ┆ Dragon  ┆ Flying ┆ 1          │\n",
      "│ Mewtwo                ┆ Psychic ┆ null   ┆ 2          │\n",
      "└───────────────────────┴─────────┴────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = pokemon.select(\n",
    "    pl.col(\"Name\", \"Type 1\", \"Type 2\"),\n",
    "    pl.col(\"Speed\")\n",
    "    .rank(\"dense\", descending=True)\n",
    "    .over(\"Type 1\", \"Type 2\")\n",
    "    .alias(\"Speed rank\"),\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result is scalar value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (163, 4)\n",
      "┌───────────────────────┬─────────┬───────┬─────────────────────┐\n",
      "│ Name                  ┆ Type 1  ┆ Speed ┆ Mean speed in group │\n",
      "│ ---                   ┆ ---     ┆ ---   ┆ ---                 │\n",
      "│ str                   ┆ enum    ┆ i64   ┆ f64                 │\n",
      "╞═══════════════════════╪═════════╪═══════╪═════════════════════╡\n",
      "│ Bulbasaur             ┆ Grass   ┆ 45    ┆ 54.230769           │\n",
      "│ Ivysaur               ┆ Grass   ┆ 60    ┆ 54.230769           │\n",
      "│ Venusaur              ┆ Grass   ┆ 80    ┆ 54.230769           │\n",
      "│ VenusaurMega Venusaur ┆ Grass   ┆ 80    ┆ 54.230769           │\n",
      "│ Charmander            ┆ Fire    ┆ 65    ┆ 86.285714           │\n",
      "│ …                     ┆ …       ┆ …     ┆ …                   │\n",
      "│ Moltres               ┆ Fire    ┆ 90    ┆ 86.285714           │\n",
      "│ Dratini               ┆ Dragon  ┆ 50    ┆ 66.666667           │\n",
      "│ Dragonair             ┆ Dragon  ┆ 70    ┆ 66.666667           │\n",
      "│ Dragonite             ┆ Dragon  ┆ 80    ┆ 66.666667           │\n",
      "│ Mewtwo                ┆ Psychic ┆ 130   ┆ 99.25               │\n",
      "└───────────────────────┴─────────┴───────┴─────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = pokemon.select(\n",
    "    pl.col(\"Name\", \"Type 1\", \"Speed\"),\n",
    "    pl.col(\"Speed\").mean().over(pl.col(\"Type 1\")).alias(\"Mean speed in group\"),\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (43, 4)\n",
      "┌────────┬───────────────────────┬───────────────────────┬─────────────────────────┐\n",
      "│ Type 1 ┆ fastest/group         ┆ strongest/group       ┆ sorted_by_alphabet      │\n",
      "│ ---    ┆ ---                   ┆ ---                   ┆ ---                     │\n",
      "│ enum   ┆ str                   ┆ str                   ┆ str                     │\n",
      "╞════════╪═══════════════════════╪═══════════════════════╪═════════════════════════╡\n",
      "│ Grass  ┆ Venusaur              ┆ Victreebel            ┆ Bellsprout              │\n",
      "│ Grass  ┆ VenusaurMega Venusaur ┆ VenusaurMega Venusaur ┆ Bulbasaur               │\n",
      "│ Grass  ┆ Victreebel            ┆ Exeggutor             ┆ Exeggcute               │\n",
      "│ Water  ┆ Starmie               ┆ GyaradosMega Gyarados ┆ Blastoise               │\n",
      "│ Water  ┆ Tentacruel            ┆ Kingler               ┆ BlastoiseMega Blastoise │\n",
      "│ …      ┆ …                     ┆ …                     ┆ …                       │\n",
      "│ Rock   ┆ Kabutops              ┆ Kabutops              ┆ Geodude                 │\n",
      "│ Ice    ┆ Jynx                  ┆ Articuno              ┆ Articuno                │\n",
      "│ Ice    ┆ Articuno              ┆ Jynx                  ┆ Jynx                    │\n",
      "│ Fairy  ┆ Clefable              ┆ Clefable              ┆ Clefable                │\n",
      "│ Fairy  ┆ Clefairy              ┆ Clefairy              ┆ Clefairy                │\n",
      "└────────┴───────────────────────┴───────────────────────┴─────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = pokemon.sort(\"Type 1\").select(\n",
    "    pl.col(\"Type 1\").head(3).over(\"Type 1\", mapping_strategy=\"explode\"),\n",
    "    pl.col(\"Name\")\n",
    "    .sort_by(pl.col(\"Speed\"), descending=True)\n",
    "    .head(3)\n",
    "    .over(\"Type 1\", mapping_strategy=\"explode\")\n",
    "    .alias(\"fastest/group\"),\n",
    "    pl.col(\"Name\")\n",
    "    .sort_by(pl.col(\"Attack\"), descending=True)\n",
    "    .head(3)\n",
    "    .over(\"Type 1\", mapping_strategy=\"explode\")\n",
    "    .alias(\"strongest/group\"),\n",
    "    pl.col(\"Name\")\n",
    "    .sort()\n",
    "    .head(3)\n",
    "    .over(\"Type 1\", mapping_strategy=\"explode\")\n",
    "    .alias(\"sorted_by_alphabet\"),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folds functions (across multi-columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fold` là một phương pháp được sử dụng để thực hiện các thao tác trên nhiều cột bằng cách áp dụng một hàm tùy chỉnh một cách tuần tự. Nó giúp kết hợp hoặc tổng hợp dữ liệu từ nhiều cột thành một kết quả duy nhất.\n",
    "\n",
    "**Cách hoạt động của fold:**\n",
    "- `fold` bắt đầu với một giá trị khởi tạo (**init value**) `acc` và sau đó áp dụng một hàm kết hợp (**binary function**) `function` để xử lý dữ liệu từng cột theo cách tuần tự trên các cột `exprs`.\n",
    "- Giá trị khởi tạo sẽ được kết hợp với dữ liệu từ các cột `exprs`, và kết quả của bước trước đó sẽ được sử dụng làm đầu vào cho bước tiếp theo.\n",
    "\n",
    "**Tại sao phải dùng fold?**\n",
    "\n",
    "- **Xử lý nhiều cột linh hoạt**: fold giúp bạn dễ dàng áp dụng một logic phức tạp trên nhiều cột mà không cần viết nhiều câu lệnh hoặc vòng lặp.\n",
    "- **Hiệu năng cao**: Vì Polars được thiết kế để tối ưu hóa hiệu năng, sử dụng fold sẽ nhanh hơn so với cách xử lý truyền thống như vòng lặp Python hoặc các thao tác pandas.\n",
    "- **Tương thích với lazy execution**: Khi dùng Polars ở chế độ lazy, fold giúp tận dụng các tối ưu hóa mà Polars cung cấp.\n",
    "- **Tính tổng quát**: fold rất mạnh mẽ vì nó cho phép định nghĩa bất kỳ phép toán tùy chỉnh nào (như tổng, tích, tìm giá trị lớn nhất/nhỏ nhất, v.v.).\n",
    "\n",
    "**Cú pháp**:\n",
    "```python\n",
    "pl.fold(init_value, lambda acc, col: <hàm tùy chỉnh>, exprs)\n",
    "```\n",
    "- `init_value`: Giá trị khởi tạo.\n",
    "- `lambda acc, col`: Hàm tùy chỉnh, trong đó:\n",
    "    - `acc` là giá trị được tích lũy qua các bước.\n",
    "    - `col` là giá trị của cột hiện tại.\n",
    "- `exprs`: Danh sách các cột hoặc các biểu thức cần xử lý.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 2)\n",
      "┌──────────┬──────────┐\n",
      "│ sum_fold ┆ sum_horz │\n",
      "│ ---      ┆ ---      │\n",
      "│ i64      ┆ i64      │\n",
      "╞══════════╪══════════╡\n",
      "│ 11       ┆ 11       │\n",
      "│ 22       ┆ 22       │\n",
      "│ 33       ┆ 33       │\n",
      "└──────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import polars as pl\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"label\": [\"foo\", \"bar\", \"spam\"],\n",
    "        \"a\": [1, 2, 3],\n",
    "        \"b\": [10, 20, 30],\n",
    "    }\n",
    ")\n",
    "\n",
    "result = df.select(\n",
    "    pl.fold(\n",
    "        acc=pl.lit(0),\n",
    "        function=operator.add,\n",
    "        exprs=pl.col(\"a\", \"b\"),\n",
    "    ).alias(\"sum_fold\"),\n",
    "    pl.sum_horizontal(pl.col(\"a\", \"b\")).alias(\"sum_horz\"),\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bài toán tìm giá trị lớn nhất giữa các cột"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 4)\n",
      "┌──────┬──────┬──────┬────────────┐\n",
      "│ col1 ┆ col2 ┆ col3 ┆ max_values │\n",
      "│ ---  ┆ ---  ┆ ---  ┆ ---        │\n",
      "│ i64  ┆ i64  ┆ i64  ┆ f64        │\n",
      "╞══════╪══════╪══════╪════════════╡\n",
      "│ 11   ┆ 4    ┆ 7    ┆ 11.0       │\n",
      "│ 2    ┆ 10   ┆ 8    ┆ 10.0       │\n",
      "│ 3    ┆ 6    ┆ 9    ┆ 9.0        │\n",
      "└──────┴──────┴──────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame({\"col1\": [11, 2, 3], \"col2\": [4, 10, 6], \"col3\": [7, 8, 9]})\n",
    "\n",
    "result = df.with_columns(\n",
    "    pl.fold(\n",
    "        acc=float(\"-inf\"),\n",
    "        function=lambda acc, col: pl.Series(\n",
    "            \"max\", acc.zip_with(acc > col, col)\n",
    "        ),\n",
    "        exprs=[pl.col(\"col1\"), pl.col(\"col2\"), pl.col(\"col3\")],\n",
    "    ).alias(\"max_values\")\n",
    ")\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy function\n",
    "\n",
    "This means that if a function is not provided by Polars, we can use NumPy and we still have fast columnar operations through the NumPy API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 2)\n",
      "┌──────────┬──────────┐\n",
      "│ a_log    ┆ b_log    │\n",
      "│ ---      ┆ ---      │\n",
      "│ f64      ┆ f64      │\n",
      "╞══════════╪══════════╡\n",
      "│ 0.0      ┆ 1.386294 │\n",
      "│ 0.693147 ┆ 1.609438 │\n",
      "│ 1.098612 ┆ 1.791759 │\n",
      "└──────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "df = pl.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n",
    "\n",
    "out = df.select(np.log(pl.all()).name.suffix(\"_log\"))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join\n",
    "\n",
    "| Loại Join                | Cú pháp                           | Mô tả                                                                                           |\n",
    "|--------------------------|------------------------------------|-------------------------------------------------------------------------------------------------|\n",
    "| **Equi inner join**      | `join(..., how=\"inner\")`          | Giữ lại các hàng khớp ở cả hai bảng (bên trái và bên phải).                                    |\n",
    "| **Equi left outer join** | `join(..., how=\"left\")`           | Giữ lại tất cả các hàng từ bảng bên trái và các hàng khớp từ bảng bên phải. Hàng không khớp ở bên trái sẽ có giá trị null ở cột bên phải. |\n",
    "| **Equi right outer join**| `join(..., how=\"right\")`          | Giữ lại tất cả các hàng từ bảng bên phải và các hàng khớp từ bảng bên trái. Hàng không khớp ở bên phải sẽ có giá trị null ở cột bên trái. |\n",
    "| **Equi full join**       | `join(..., how=\"full\")`           | Giữ lại tất cả các hàng từ cả hai bảng, bất kể có khớp hay không. Hàng không khớp ở bảng này sẽ có giá trị null ở cột của bảng kia. |\n",
    "| **Equi semi join**       | `join(..., how=\"semi\")`           | Giữ lại các hàng từ bảng bên trái mà có khớp ở bảng bên phải.                                   |\n",
    "| **Equi anti join**       | `join(..., how=\"anti\")`           | Giữ lại các hàng từ bảng bên trái mà không có khớp ở bảng bên phải.                             |\n",
    "| **Non-equi inner join**  | `join_where`                     | Tìm tất cả các cặp hàng từ bảng bên trái và bảng bên phải thỏa mãn điều kiện (predicate) cụ thể.|\n",
    "| **Asof join**            | `join_asof/join_asof_by`         | Giống left outer join nhưng thay vì khớp chính xác, nó khớp với giá trị khóa gần nhất.          |\n",
    "| **Cartesian product**    | `join(..., how=\"cross\")`          | Tính tích Descartes của hai bảng (kết hợp tất cả các hàng từ bảng này với tất cả các hàng từ bảng kia). |\n",
    "\n",
    "- **Equi join**: Khớp các hàng dựa trên giá trị chính xác của khóa (key).\n",
    "- **Non-equi join**: Khớp các hàng dựa trên điều kiện tùy chỉnh (ví dụ: lớn hơn, nhỏ hơn...).\n",
    "- **Asof join**: Hữu ích khi làm việc với dữ liệu chuỗi thời gian, khớp các giá trị gần nhất theo thứ tự.\n",
    "- **Cartesian product**: Kết hợp tất cả các hàng của cả hai bảng, dẫn đến một bảng kết quả lớn. Thường ít được sử dụng do tốn tài nguyên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equi join (giống key merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Table:\n",
      "shape: (3, 2)\n",
      "┌─────┬────────────┐\n",
      "│ id  ┆ value_left │\n",
      "│ --- ┆ ---        │\n",
      "│ i64 ┆ str        │\n",
      "╞═════╪════════════╡\n",
      "│ 1   ┆ A          │\n",
      "│ 2   ┆ B          │\n",
      "│ 3   ┆ C          │\n",
      "└─────┴────────────┘\n",
      "\n",
      "Right Table:\n",
      "shape: (3, 2)\n",
      "┌─────┬─────────────┐\n",
      "│ id  ┆ value_right │\n",
      "│ --- ┆ ---         │\n",
      "│ i64 ┆ str         │\n",
      "╞═════╪═════════════╡\n",
      "│ 2   ┆ X           │\n",
      "│ 3   ┆ Y           │\n",
      "│ 4   ┆ Z           │\n",
      "└─────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Tạo hai bảng DataFrame mẫu\n",
    "df_left = pl.DataFrame({\"id\": [1, 2, 3], \"value_left\": [\"A\", \"B\", \"C\"]})\n",
    "\n",
    "df_right = pl.DataFrame({\"id\": [2, 3, 4], \"value_right\": [\"X\", \"Y\", \"Z\"]})\n",
    "\n",
    "# In các bảng\n",
    "print(\"Left Table:\")\n",
    "print(df_left)\n",
    "print(\"\\nRight Table:\")\n",
    "print(df_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "┌─────┬────────────┐\n",
      "│ id  ┆ value_left │\n",
      "│ --- ┆ ---        │\n",
      "│ i64 ┆ str        │\n",
      "╞═════╪════════════╡\n",
      "│ 2   ┆ B          │\n",
      "│ 3   ┆ C          │\n",
      "└─────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Equi semi join\n",
    "\n",
    "result = df_left.join(df_right, on=\"id\", how=\"semi\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 2)\n",
      "┌─────┬────────────┐\n",
      "│ id  ┆ value_left │\n",
      "│ --- ┆ ---        │\n",
      "│ i64 ┆ str        │\n",
      "╞═════╪════════════╡\n",
      "│ 1   ┆ A          │\n",
      "└─────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Equi anti join\n",
    "\n",
    "\n",
    "result = df_left.join(df_right, on=\"id\", how=\"anti\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-equi inner join (key thoả mãn điều kiện)\n",
    "\n",
    "`join_where` (Non-equi inner join)\n",
    "\n",
    "For example: join những thằng có khả năng mua item (điều kiện là cast của user phải lớn hơn giá của item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌─────────┬───────┬─────────┬────────────────┐\n",
      "│ item_id ┆ price ┆ user_id ┆ cast_availabel │\n",
      "│ ---     ┆ ---   ┆ ---     ┆ ---            │\n",
      "│ i64     ┆ i64   ┆ str     ┆ i64            │\n",
      "╞═════════╪═══════╪═════════╪════════════════╡\n",
      "│ 1       ┆ 10    ┆ B       ┆ 27             │\n",
      "│ 1       ┆ 10    ┆ C       ┆ 35             │\n",
      "│ 2       ┆ 25    ┆ B       ┆ 27             │\n",
      "│ 2       ┆ 25    ┆ C       ┆ 35             │\n",
      "│ 3       ┆ 30    ┆ C       ┆ 35             │\n",
      "└─────────┴───────┴─────────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Non-equi inner join: join_where\n",
    "\n",
    "df_left = pl.DataFrame({\"item_id\": [1, 2, 3], \"price\": [10, 25, 30]})\n",
    "\n",
    "df_right = pl.DataFrame(\n",
    "    {\"user_id\": [\"A\", \"B\", \"C\"], \"cast_availabel\": [5, 27, 35]}\n",
    ")\n",
    "\n",
    "result = df_left.join_where(\n",
    "    df_right, pl.col(\"price\") <= pl.col(\"cast_availabel\")\n",
    ")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asof join (key gần đúng, thay vì chính xác)\n",
    "\n",
    "Asof Join (Approximate Sorted Join) là một kỹ thuật rất hữu ích trong xử lý dữ liệu chuỗi thời gian hoặc dữ liệu liên tục, đặc biệt khi cần khớp các giá trị gần nhất thay vì khớp chính xác. Đây là một công cụ mạnh mẽ cho các ứng dụng sau:\n",
    "- **Financial Data**: Giả sử bạn có một bảng giá cổ phiếu và một bảng các sự kiện kinh tế, bạn có thể sử dụng asof join để lấy giá cổ phiếu gần nhất trước mỗi sự kiện kinh tế.\n",
    "- **Log and Monitoring Analysis**: Giả sử bạn có một bảng log lỗi hệ thống và một bảng ghi trạng thái máy chủ, bạn có thể dùng asof join để lấy trạng thái gần nhất tại thời điểm lỗi xảy ra.\n",
    "- **User Behavior Analysis**: bạn có dữ liệu clickstream (hành động người dùng trên website) và các mốc thời gian chạy chiến dịch quảng cáo, bạn có thể dùng asof join để xác định chiến dịch nào ảnh hưởng đến hành vi người dùng.\n",
    "- **Healthcare and Patient Monitoring**: Giả sử bạn có dữ liệu đo nhịp tim liên tục và danh sách các lần bệnh nhân dùng thuốc, bạn có thể sử dụng asof join để xem xét ảnh hưởng của thuốc lên nhịp tim.\n",
    "- Time Series in Manufacturing: Trong một dây chuyền sản xuất, bạn có dữ liệu từ các cảm biến và các bản ghi bảo trì. Asof join có thể giúp bạn kết hợp dữ liệu cảm biến với các hoạt động bảo trì gần nhất để phân tích nguyên nhân lỗi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cartesian product (cross join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat\n",
    "\n",
    "How:\n",
    "- `vertical`: mở rộng theo chiều dọc\n",
    "- `horizontal`: mở rộng theo chiều ngang\n",
    "- `diagonal`: mở rộng theo cả hai chiều, fill `null` bởi các giá trị không có"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "┌─────┬─────┐\n",
      "│ a   ┆ b   │\n",
      "│ --- ┆ --- │\n",
      "│ i64 ┆ i64 │\n",
      "╞═════╪═════╡\n",
      "│ 1   ┆ 3   │\n",
      "│ 2   ┆ 4   │\n",
      "└─────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "df_v1 = pl.DataFrame(\n",
    "    {\n",
    "        \"a\": [1],\n",
    "        \"b\": [3],\n",
    "    }\n",
    ")\n",
    "df_v2 = pl.DataFrame(\n",
    "    {\n",
    "        \"a\": [2],\n",
    "        \"b\": [4],\n",
    "    }\n",
    ")\n",
    "df_vertical_concat = pl.concat(\n",
    "    [\n",
    "        df_v1,\n",
    "        df_v2,\n",
    "    ],\n",
    "    how=\"vertical\",\n",
    ")\n",
    "print(df_vertical_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌─────┬─────┬─────┐\n",
      "│ foo ┆ N   ┆ bar │\n",
      "│ --- ┆ --- ┆ --- │\n",
      "│ str ┆ i64 ┆ str │\n",
      "╞═════╪═════╪═════╡\n",
      "│ A   ┆ 1   ┆ k   │\n",
      "│ A   ┆ 2   ┆ l   │\n",
      "│ B   ┆ 2   ┆ m   │\n",
      "│ B   ┆ 4   ┆ n   │\n",
      "│ C   ┆ 2   ┆ o   │\n",
      "└─────┴─────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"foo\": [\"A\", \"A\", \"B\", \"B\", \"C\"],\n",
    "        \"N\": [1, 2, 2, 4, 2],\n",
    "        \"bar\": [\"k\", \"l\", \"m\", \"n\", \"o\"],\n",
    "    }\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 6)\n",
      "┌─────┬──────┬──────┬──────┬──────┬──────┐\n",
      "│ foo ┆ k    ┆ l    ┆ m    ┆ n    ┆ o    │\n",
      "│ --- ┆ ---  ┆ ---  ┆ ---  ┆ ---  ┆ ---  │\n",
      "│ str ┆ i64  ┆ i64  ┆ i64  ┆ i64  ┆ i64  │\n",
      "╞═════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│ A   ┆ 1    ┆ 2    ┆ null ┆ null ┆ null │\n",
      "│ B   ┆ null ┆ null ┆ 2    ┆ 4    ┆ null │\n",
      "│ C   ┆ null ┆ null ┆ null ┆ null ┆ 2    │\n",
      "└─────┴──────┴──────┴──────┴──────┴──────┘\n"
     ]
    }
   ],
   "source": [
    "# eager mode\n",
    "out = df.pivot(\"bar\", index=\"foo\", values=\"N\", aggregate_function=\"first\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 4)\n",
      "┌─────┬─────┬─────┬─────┐\n",
      "│ A   ┆ B   ┆ C   ┆ D   │\n",
      "│ --- ┆ --- ┆ --- ┆ --- │\n",
      "│ str ┆ i64 ┆ i64 ┆ i64 │\n",
      "╞═════╪═════╪═════╪═════╡\n",
      "│ a   ┆ 1   ┆ 10  ┆ 2   │\n",
      "│ b   ┆ 3   ┆ 11  ┆ 4   │\n",
      "│ a   ┆ 5   ┆ 12  ┆ 6   │\n",
      "└─────┴─────┴─────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"a\", \"b\", \"a\"],\n",
    "        \"B\": [1, 3, 5],\n",
    "        \"C\": [10, 11, 12],\n",
    "        \"D\": [2, 4, 6],\n",
    "    }\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (6, 4)\n",
      "┌─────┬─────┬──────────┬───────┐\n",
      "│ A   ┆ B   ┆ variable ┆ value │\n",
      "│ --- ┆ --- ┆ ---      ┆ ---   │\n",
      "│ str ┆ i64 ┆ str      ┆ i64   │\n",
      "╞═════╪═════╪══════════╪═══════╡\n",
      "│ a   ┆ 1   ┆ C        ┆ 10    │\n",
      "│ b   ┆ 3   ┆ C        ┆ 11    │\n",
      "│ a   ┆ 5   ┆ C        ┆ 12    │\n",
      "│ a   ┆ 1   ┆ D        ┆ 2     │\n",
      "│ b   ┆ 3   ┆ D        ┆ 4     │\n",
      "│ a   ┆ 5   ┆ D        ┆ 6     │\n",
      "└─────┴─────┴──────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "out = df.unpivot([\"C\", \"D\"], index=[\"A\", \"B\"])\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When read file\n",
    "df = pl.read_csv(\"docs/assets/data/apple_stock.csv\", try_parse_dates=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string column to datetime\n",
    "df = df.with_columns(pl.col(\"Date\").str.to_date(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equal datetime\n",
    "filtered_df = df.filter(\n",
    "    pl.col(\"Date\") == datetime(1995, 10, 16),\n",
    ")\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Between range\n",
    "filtered_range_df = df.filter(\n",
    "    pl.col(\"Date\").is_between(datetime(1995, 7, 1), datetime(1995, 11, 1)),\n",
    ")\n",
    "print(filtered_range_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping\n",
    "\n",
    "Parameters for `group_by_dynamic` ([detail](https://docs.pola.rs/user-guide/transformations/time-series/rolling/))\n",
    "- `every`: indicates the interval of the window\n",
    "- `period`: indicates the duration of the window\n",
    "- `offset`: can be used to offset the start of the windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_average_df = df.group_by_dynamic(\"Date\", every=\"1y\").agg(\n",
    "    pl.col(\"Close\").mean()\n",
    ")\n",
    "\n",
    "df_with_year = annual_average_df.with_columns(\n",
    "    pl.col(\"Date\").dt.year().alias(\"year\")\n",
    ")\n",
    "print(df_with_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy API\n",
    "\n",
    "Thay vì thực hiện ngay lập tức mỗi thao tác (như trong DataFrame thông thường), LazyFrame ghi nhận các thao tác thành một cây kế hoạch (query plan). Điều này mang lại một số lợi ích:\n",
    "\n",
    "- Tối ưu hóa toàn diện: Polars có thể phân tích toàn bộ cây kế hoạch để thực hiện các tối ưu hóa như loại bỏ thao tác không cần thiết, giảm số lượng đọc/ghi dữ liệu, và sắp xếp lại thứ tự các phép tính để tăng hiệu suất.\n",
    "- Hạn chế I/O: Lazy API giảm thiểu số lần truy cập dữ liệu, làm tăng tốc độ xử lý.\n",
    "- Xử lý dữ liệu lớn: Lazy API phù hợp để làm việc với dữ liệu lớn vì nó giảm tải bộ nhớ.\n",
    "- Bắt được lỗi liên quan đến schema trong quá trình precessing thay vì phải load hết toàn bộ data\n",
    "\n",
    "---\n",
    "\n",
    "**LazyFrame vs DataFrame**\n",
    "\n",
    "- **DataFrame (Eager API)**: Thực hiện các thao tác ngay lập tức. Tốt cho các bài toán nhỏ và dễ thử nghiệm.\n",
    "- **LazyFrame (Lazy API)**: Chỉ ghi nhận thao tác và thực thi chúng khi bạn gọi `collect()`.\n",
    "\n",
    "---\n",
    "**Tối ưu hóa của Lazy API**\n",
    "\n",
    "Polars sử dụng nhiều kỹ thuật tối ưu hóa như:\n",
    "\n",
    "- **Predicate Pushdown**: Đẩy các phép lọc xuống sớm để giảm lượng dữ liệu xử lý.\n",
    "- **Projection Pushdown**: Chỉ đọc các cột cần thiết thay vì đọc toàn bộ dữ liệu.\n",
    "- **Expression Simplification**: Tái cấu trúc các biểu thức phức tạp để giảm chi phí tính toán.\n",
    "- **Joins Optimization**: Tối ưu các phép nối (join) dữ liệu.\n",
    "\n",
    "--- \n",
    "**Apply Lazy API**\n",
    "- read file: `pl.scan_`\n",
    "- convert exist dataframe: `.lazy()`\n",
    "- execute query plan: `.collect()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "q1 = (\n",
    "    pl.scan_csv(\n",
    "        r\"coding\\learning\\contents\\3_programming_and_frameworks\\python\\python_frameworks\\polars\\data\\data.csv\"\n",
    "    )\n",
    "    .with_columns(pl.col(\"symbol\").str.to_uppercase())\n",
    "    .filter(pl.col(\"capital\") > 100_000_000_000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show query graph\n",
    "\n",
    "# check: optimized = False\n",
    "q1.show_graph(optimized=False)\n",
    "\n",
    "# optimal query plan\n",
    "q1.show_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
