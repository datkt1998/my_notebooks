{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "**1. So sánh Pandas, Polars, PySpark, và Dask**\n",
    "\n",
    "| **Tiêu chí**              | **Pandas**                                         | **Polars**                                         | **PySpark**                                      | **Dask**                                       |\n",
    "|---------------------------|---------------------------------------------------|---------------------------------------------------|-------------------------------------------------|-----------------------------------------------|\n",
    "| **Hiệu năng**             | Trung bình (single-threaded).                     | Rất cao (Rust, multi-threaded).                  | Cao (phân tán trên nhiều cluster).             | Cao (đa luồng hoặc phân tán).                 |\n",
    "| **Kích thước dữ liệu**    | Giới hạn bởi bộ nhớ RAM.                          | Lớn (out-of-core và Apache Arrow).               | Rất lớn (phân tán trên nhiều node).            | Lớn (out-of-core, phân tán).                  |\n",
    "| **Lazy Evaluation**       | Không.                                            | Có (tối ưu hóa pipeline).                        | Có (nhưng chậm hơn Polars).                    | Có.                                           |\n",
    "| **Dễ sử dụng**            | Rất dễ (API quen thuộc với Python).               | Dễ (API tương tự Pandas).                        | Trung bình (cần hiểu rõ Spark API).            | Trung bình (API tương tự Pandas).            |\n",
    "| **Khả năng mở rộng**      | Hạn chế (thích hợp cho dữ liệu nhỏ).              | Tốt (Arrow, Parquet, ORC).                       | Rất cao (được thiết kế cho hệ thống lớn).      | Cao (hỗ trợ phân tán và dữ liệu lớn).         |\n",
    "| **Thời gian khởi chạy**   | Nhanh.                                            | Nhanh.                                           | Chậm (cần thiết lập SparkContext).             | Trung bình.                                   |\n",
    "| **Quản lý tài nguyên**    | Không hỗ trợ quản lý phân tán.                    | Không hỗ trợ quản lý phân tán.                   | Có (hỗ trợ cluster phân tán).                  | Có (quản lý song song, cluster nhỏ).          |\n",
    "| **Ngôn ngữ cốt lõi**      | Python.                                           | Rust.                                            | Scala/Java (API Python là giao diện).          | Python.                                       |\n",
    "| **Định dạng hỗ trợ**      | CSV, Excel, SQL, JSON.                            | CSV, Parquet, JSON, IPC, ORC.                    | CSV, Parquet, ORC, Avro, JSON.                 | CSV, Parquet, JSON, Zarr.                    |\n",
    "| **Xử lý song song**       | Không (single-threaded).                          | Có (tích hợp đa luồng).                          | Có (phân tán trên cluster).                    | Có (đa luồng hoặc phân tán).                  |\n",
    "| **Ưu điểm chính**         | Dễ dùng, phổ biến, nhiều tài liệu hỗ trợ.          | Rất nhanh, hỗ trợ lazy evaluation, tối ưu hóa.   | Tốt cho dữ liệu cực lớn và xử lý phân tán.      | Tốt cho dữ liệu lớn nhưng quen thuộc với Pandas. |\n",
    "| **Nhược điểm chính**      | Hiệu năng thấp với dữ liệu lớn.                   | Còn mới, tài liệu ít hơn Pandas.                 | Cần tài nguyên cluster, phức tạp hơn.          | Hiệu năng kém hơn Polars với dữ liệu nhỏ.     |\n",
    "| **Khi nào sử dụng?**      | Xử lý dữ liệu nhỏ và vừa, phân tích nhanh.         | Dữ liệu lớn, cần hiệu năng cao, xử lý nhanh.     | Dữ liệu cực lớn, xử lý phân tán trên cluster.   | Khi cần xử lý dữ liệu lớn và sử dụng API quen thuộc Pandas. |\n",
    "\n",
    "- **Pandas**: Lý tưởng cho xử lý dữ liệu nhỏ và vừa, dễ học, nhiều tài liệu hỗ trợ.\n",
    "- **Polars**: Phù hợp khi cần hiệu năng cao hoặc xử lý dữ liệu lớn nhanh chóng.\n",
    "- **PySpark**: Dành cho dữ liệu cực lớn, đòi hỏi xử lý phân tán trên cluster.\n",
    "- **Dask**: Là lựa chọn tốt nếu bạn cần xử lý dữ liệu lớn với cách tiếp cận quen thuộc từ Pandas.\n",
    "\n",
    "**2. Differences in concepts between Polars and pandas**\n",
    "\n",
    "**Polars không có multi-index/index**\n",
    "- pandas gắn nhãn cho mỗi hàng bằng “index”, trong khi Polars không dùng index mà đánh chỉ số các hàng bằng vị trí số nguyên.\n",
    "- Polars thiết kế để kết quả dễ dự đoán và câu lệnh dễ đọc, tránh sự phức tạp do “index” gây ra.\n",
    "\n",
    "**Polars sử dụng Apache Arrow thay vì NumPy arrays**\n",
    "- Polars lưu trữ dữ liệu theo chuẩn Apache Arrow, tối ưu hóa việc phân tích dữ liệu, tăng tốc độ tải, giảm bộ nhớ, và tính toán nhanh hơn. pandas sử dụng NumPy arrays.\n",
    "- Polars utilizes the Arrow Columnar Format for its data orientation\n",
    "\n",
    "**Polars hỗ trợ hoạt động song song tốt hơn pandas**\n",
    "- Polars khai thác khả năng xử lý đồng thời mạnh mẽ của Rust, cho phép nhiều hoạt động chạy song song. pandas chủ yếu hoạt động đơn luồng, cần thư viện bổ sung (như Dask) để chạy song song.\n",
    "\n",
    "**Polars có thể đánh giá lười biếng và tối ưu hóa câu truy vấn**\n",
    "- pandas chỉ hỗ trợ đánh giá tức thời (eager evaluation). Polars hỗ trợ cả đánh giá tức thời và đánh giá lười biếng (lazy evaluation).\n",
    "- Khi dùng lazy evaluation, Polars tối ưu hóa tự động các câu truy vấn, cải thiện tốc độ và giảm tiêu thụ bộ nhớ.\n",
    "\n",
    "**Sử dụng index như một kỹ thuật tối ưu hóa**\n",
    "- Polars có thể sử dụng cấu trúc dữ liệu “index” tương tự như cơ sở dữ liệu để tối ưu hóa, nhưng không dùng nó để quản lý dữ liệu như pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**3. Differences in Key syntax between Polars and pandas**\n",
    "\n",
    "Use the same syntax like pandas might be run, but it likely runs slower than it should. Then, it should be used by rewrite code syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.DataFrame({\"foo\": [1, 2, 3], \"bar\": [None, \"bak\", \"baz\"]})\n",
    "csv_file = \"docs/assets/data/path.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- selecting data in parallel optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns\n",
    "df.select(\"a\")\n",
    "\n",
    "# filter\n",
    "df.filter(pl.col(\"a\") < 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lazy model to optimize query by identify that only the relevant. By calling the `.collect` method at the end con **eagerly evaluate** the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lazy mode: scan_csv\n",
    "df = pl.scan_csv(csv_file)\n",
    "\n",
    "# eager mode: read_csv\n",
    "df = pl.read_csv(csv_file)\n",
    "grouped_df = df.group_by(\"id1\").agg(pl.col(\"v1\").sum()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Column assignment in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column assignment\n",
    "\n",
    "# in Pandas\n",
    "df.assign(\n",
    "    tenXValue=lambda df_: df_.value * 10,\n",
    "    hundredXValue=lambda df_: df_.value * 100,\n",
    ")\n",
    "\n",
    "# in Polars\n",
    "df.with_columns(\n",
    "    tenXValue=pl.col(\"value\") * 10,\n",
    "    hundredXValue=pl.col(\"value\") * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column assignment based on predicate\n",
    "\n",
    "# in Pandas\n",
    "df.assign(a=lambda df_: df_.a.where(df_.c != 2, df_.b))\n",
    "\n",
    "# in Polars: Polars compute every branch of an when -> then -> otherwise in parallel\n",
    "df.with_columns(\n",
    "    pl.when(pl.col(\"c\") == 2)  # when\n",
    "    .then(pl.col(\"b\"))  # then\n",
    "    .otherwise(pl.col(\"a\"))  # otherwise\n",
    "    .alias(\"a\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- filter in Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter((pl.col(\"m2_living\") > 2500) & (pl.col(\"price\") < 300000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dataframe transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"c\": [1, 1, 1, 2, 2, 2, 2],\n",
    "        \"type\": [\"m\", \"n\", \"o\", \"m\", \"m\", \"n\", \"n\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# in pandas\n",
    "df[\"size\"] = df.groupby(\"c\")[\"type\"].transform(len)\n",
    "\n",
    "# in polars\n",
    "df.with_columns(pl.col(\"type\").count().over(\"c\").alias(\"size\"))\n",
    "\n",
    "# multi\n",
    "df.with_columns(\n",
    "    pl.col(\"c\").count().over(\"c\").alias(\"size\"),\n",
    "    pl.col(\"c\").sum().over(\"type\").alias(\"sum\"),\n",
    "    pl.col(\"type\").reverse().over(\"c\").alias(\"reverse_type\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data type and structures\n",
    "\n",
    "### Data-types\n",
    "\n",
    "| **Category**     | **Datatype**            |\n",
    "|-------------------|-------------------------|\n",
    "| **Numeric**       | `Int8`, `Int16`, `Int32`, `Int64` (both negative and positive) |\n",
    "|                   | `UInt8`, `UInt16`, `UInt32`, `UInt64` (non-negative) |\n",
    "|                   | `Float32`, `Float64`     (need fast calculation by approximation)    |\n",
    "|                   | `Decimal` (need precision calculation)               | \n",
    "| **Nested**        | `List`                    | \n",
    "|                   | `Array`                   | \n",
    "|                   | `Struct`  (like `Dict`)                | \n",
    "| **Temporal**      | `Date`                    | \n",
    "|                   | `Time`                    | \n",
    "|                   | `Datetime`                | \n",
    "|                   | `Duration`                | \n",
    "| **Miscellaneous** | `Boolean`                 | \n",
    "|                   | `String` (UTF-8 encoded)  | \n",
    "|                   | `Binary`                  | \n",
    "|                   | `Categorical`  (inferred strings at runtime)          | \n",
    "|                   | `Enum` (Set predetermined strings)                   | \n",
    "|                   | `Object`                  | \n",
    "|                   | `Null`                    | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5,)\n",
      "Series: 'ints' [i64]\n",
      "[\n",
      "\t1\n",
      "\t2\n",
      "\t3\n",
      "\t4\n",
      "\t5\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "s1 = pl.Series(\"ints\", [1, 2, 3, 4, 5])\n",
    "s2 = pl.Series(\"uints\", [1, 2, 3, 4, 5], dtype=pl.UInt64)\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Int64, UInt64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(s1.dtype, s2.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 4)\n",
      "┌────────────────┬────────────┬────────┬────────┐\n",
      "│ name           ┆ birthdate  ┆ weight ┆ height │\n",
      "│ ---            ┆ ---        ┆ ---    ┆ ---    │\n",
      "│ str            ┆ date       ┆ f64    ┆ f64    │\n",
      "╞════════════════╪════════════╪════════╪════════╡\n",
      "│ Alice Archer   ┆ 1997-01-10 ┆ 57.9   ┆ 1.56   │\n",
      "│ Ben Brown      ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
      "│ Chloe Cooper   ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   │\n",
      "│ Daniel Donovan ┆ 1981-04-30 ┆ 83.1   ┆ 1.75   │\n",
      "└────────────────┴────────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"name\": [\n",
    "            \"Alice Archer\",\n",
    "            \"Ben Brown\",\n",
    "            \"Chloe Cooper\",\n",
    "            \"Daniel Donovan\",\n",
    "        ],\n",
    "        \"birthdate\": [\n",
    "            date(1997, 1, 10),\n",
    "            date(1985, 2, 15),\n",
    "            date(1983, 3, 22),\n",
    "            date(1981, 4, 30),\n",
    "        ],\n",
    "        \"weight\": [57.9, 72.5, 53.6, 83.1],  # (kg)\n",
    "        \"height\": [1.56, 1.77, 1.65, 1.75],  # (m)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>birthdate</th><th>weight</th><th>height</th></tr><tr><td>str</td><td>date</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Alice Archer&quot;</td><td>1997-01-10</td><td>57.9</td><td>1.56</td></tr><tr><td>&quot;Ben Brown&quot;</td><td>1985-02-15</td><td>72.5</td><td>1.77</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 4)\n",
       "┌──────────────┬────────────┬────────┬────────┐\n",
       "│ name         ┆ birthdate  ┆ weight ┆ height │\n",
       "│ ---          ┆ ---        ┆ ---    ┆ ---    │\n",
       "│ str          ┆ date       ┆ f64    ┆ f64    │\n",
       "╞══════════════╪════════════╪════════╪════════╡\n",
       "│ Alice Archer ┆ 1997-01-10 ┆ 57.9   ┆ 1.56   │\n",
       "│ Ben Brown    ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
       "└──────────────┴────────────┴────────┴────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>birthdate</th><th>weight</th><th>height</th></tr><tr><td>str</td><td>date</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Chloe Cooper&quot;</td><td>1983-03-22</td><td>53.6</td><td>1.65</td></tr><tr><td>&quot;Daniel Donovan&quot;</td><td>1981-04-30</td><td>83.1</td><td>1.75</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 4)\n",
       "┌────────────────┬────────────┬────────┬────────┐\n",
       "│ name           ┆ birthdate  ┆ weight ┆ height │\n",
       "│ ---            ┆ ---        ┆ ---    ┆ ---    │\n",
       "│ str            ┆ date       ┆ f64    ┆ f64    │\n",
       "╞════════════════╪════════════╪════════╪════════╡\n",
       "│ Chloe Cooper   ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   │\n",
       "│ Daniel Donovan ┆ 1981-04-30 ┆ 83.1   ┆ 1.75   │\n",
       "└────────────────┴────────────┴────────┴────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>birthdate</th><th>weight</th><th>height</th></tr><tr><td>str</td><td>date</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Chloe Cooper&quot;</td><td>1983-03-22</td><td>53.6</td><td>1.65</td></tr><tr><td>&quot;Ben Brown&quot;</td><td>1985-02-15</td><td>72.5</td><td>1.77</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 4)\n",
       "┌──────────────┬────────────┬────────┬────────┐\n",
       "│ name         ┆ birthdate  ┆ weight ┆ height │\n",
       "│ ---          ┆ ---        ┆ ---    ┆ ---    │\n",
       "│ str          ┆ date       ┆ f64    ┆ f64    │\n",
       "╞══════════════╪════════════╪════════╪════════╡\n",
       "│ Chloe Cooper ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   │\n",
       "│ Ben Brown    ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
       "└──────────────┴────────────┴────────┴────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 4\n",
      "Columns: 4\n",
      "$ name       <str> 'Alice Archer', 'Ben Brown', 'Chloe Cooper', 'Daniel Donovan'\n",
      "$ birthdate <date> 1997-01-10, 1985-02-15, 1983-03-22, 1981-04-30\n",
      "$ weight     <f64> 57.9, 72.5, 53.6, 83.1\n",
      "$ height     <f64> 1.56, 1.77, 1.65, 1.75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.glimpse(return_as_string=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (9, 5)\n",
      "┌────────────┬────────────────┬─────────────────────┬───────────┬──────────┐\n",
      "│ statistic  ┆ name           ┆ birthdate           ┆ weight    ┆ height   │\n",
      "│ ---        ┆ ---            ┆ ---                 ┆ ---       ┆ ---      │\n",
      "│ str        ┆ str            ┆ str                 ┆ f64       ┆ f64      │\n",
      "╞════════════╪════════════════╪═════════════════════╪═══════════╪══════════╡\n",
      "│ count      ┆ 4              ┆ 4                   ┆ 4.0       ┆ 4.0      │\n",
      "│ null_count ┆ 0              ┆ 0                   ┆ 0.0       ┆ 0.0      │\n",
      "│ mean       ┆ null           ┆ 1986-09-04 00:00:00 ┆ 66.775    ┆ 1.6825   │\n",
      "│ std        ┆ null           ┆ null                ┆ 13.560082 ┆ 0.097082 │\n",
      "│ min        ┆ Alice Archer   ┆ 1981-04-30          ┆ 53.6      ┆ 1.56     │\n",
      "│ 25%        ┆ null           ┆ 1983-03-22          ┆ 57.9      ┆ 1.65     │\n",
      "│ 50%        ┆ null           ┆ 1985-02-15          ┆ 72.5      ┆ 1.75     │\n",
      "│ 75%        ┆ null           ┆ 1985-02-15          ┆ 72.5      ┆ 1.75     │\n",
      "│ max        ┆ Daniel Donovan ┆ 1997-01-10          ┆ 83.1      ┆ 1.77     │\n",
      "└────────────┴────────────────┴─────────────────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "┌────────┬─────┐\n",
      "│ name   ┆ age │\n",
      "│ ---    ┆ --- │\n",
      "│ str    ┆ u8  │\n",
      "╞════════╪═════╡\n",
      "│ Alice  ┆ 27  │\n",
      "│ Ben    ┆ 39  │\n",
      "│ Chloe  ┆ 41  │\n",
      "│ Daniel ┆ 43  │\n",
      "└────────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "# set schema\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice\", \"Ben\", \"Chloe\", \"Daniel\"],\n",
    "        \"age\": [27, 39, 41, 43],\n",
    "    },\n",
    "    schema={\"name\": None, \"age\": pl.UInt8},\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "┌────────┬─────┐\n",
      "│ name   ┆ age │\n",
      "│ ---    ┆ --- │\n",
      "│ str    ┆ u16 │\n",
      "╞════════╪═════╡\n",
      "│ Alice  ┆ 27  │\n",
      "│ Ben    ┆ 39  │\n",
      "│ Chloe  ┆ 41  │\n",
      "│ Daniel ┆ 43  │\n",
      "└────────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "# override datatype in some of columns (not all columns)\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice\", \"Ben\", \"Chloe\", \"Daniel\"],\n",
    "        \"age\": [27, 39, 41, 43],\n",
    "    },\n",
    "    schema_overrides={\"age\": pl.UInt16},\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in eager mode (executed immediately)\n",
    "df = pl.read_csv(\"docs/assets/data/path.csv\")\n",
    "\n",
    "# lazy mode (prefer)\n",
    "df = pl.scan_csv(\"docs/assets/data/path.csv\")\n",
    "\n",
    "# write csv\n",
    "df.write_csv(\"docs/assets/data/path.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Excel files** : https://docs.pola.rs/user-guide/io/excel/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Multiple files strategy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If data in multiple file is the same schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in eager mode\n",
    "df = pl.read_csv(\"docs/assets/data/my_many_files_*.csv\")\n",
    "\n",
    "# lazy mode (prefer)\n",
    "df = pl.scan_csv(\"docs/assets/data/my_many_files_*.csv\")\n",
    "df.show_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If data in multiple file is not in 1 table, but do same task (parallel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "queries = []\n",
    "for file in glob.glob(\"docs/assets/data/my_many_files_*.csv\"):\n",
    "    q = pl.scan_csv(file).group_by(\"bar\").agg(pl.len(), pl.sum(\"foo\"))\n",
    "    queries.append(q)\n",
    "\n",
    "dataframes = pl.collect_all(queries)\n",
    "print(dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet (prefer than CSV)\n",
    "\n",
    "Polars is optimize to load and write `parquet` file format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in eager mode (executed immediately)\n",
    "df = pl.read_parquet(\"docs/assets/data/path.parquet\")\n",
    "\n",
    "# lazy mode (prefer)\n",
    "df = pl.scan_parquet(\"docs/assets/data/path.parquet\")\n",
    "\n",
    "# write csv\n",
    "df.write_parquet(\"docs/assets/data/path.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we scan a Parquet file stored in the cloud, we can also apply predicate and projection pushdowns. This can significantly reduce the amount of data that needs to be downloaded. For scanning a Parquet file in the cloud, see Cloud storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hive partitioned data\n",
    "\n",
    "https://docs.pola.rs/user-guide/io/hive/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For READ hive partitioned data:**\n",
    "```\n",
    "┌───────────────────────────────────────────────────────┐\n",
    "│ File path                                             │\n",
    "╞═══════════════════════════════════════════════════════╡\n",
    "│ docs/assets/data/hive/year=2023/month=11/data.parquet │\n",
    "│ docs/assets/data/hive/year=2023/month=12/data.parquet │\n",
    "│ docs/assets/data/hive/year=2024/month=01/data.parquet │\n",
    "│ docs/assets/data/hive/year=2024/month=02/data.parquet │\n",
    "└───────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.scan_parquet(\"docs/assets/data/hive/\").collect()\n",
    "\n",
    "with pl.Config(tbl_rows=99):\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For READ Handling mixed files:**\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│ File path                                                   │\n",
    "╞═════════════════════════════════════════════════════════════╡\n",
    "│ docs/assets/data/hive_mixed/description.txt                 │\n",
    "│ docs/assets/data/hive_mixed/year=2023/month=11/data.parquet │\n",
    "│ docs/assets/data/hive_mixed/year=2023/month=12/data.parquet │\n",
    "│ docs/assets/data/hive_mixed/year=2024/month=01/data.parquet │\n",
    "│ docs/assets/data/hive_mixed/year=2024/month=02/data.parquet │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.scan_parquet(\n",
    "    \"docs/assets/data/hive_mixed/**/*.parquet\", hive_partitioning=True\n",
    ").collect()\n",
    "\n",
    "with pl.Config(tbl_rows=99):\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For READ specific hive files:**\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│ File path                                                   │\n",
    "╞═════════════════════════════════════════════════════════════╡\n",
    "│ docs/assets/data/hive_mixed/description.txt                 │\n",
    "│ docs/assets/data/hive_mixed/year=2023/month=11/data.parquet │\n",
    "│ docs/assets/data/hive_mixed/year=2023/month=12/data.parquet │\n",
    "│ docs/assets/data/hive_mixed/year=2024/month=01/data.parquet │\n",
    "│ docs/assets/data/hive_mixed/year=2024/month=02/data.parquet │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.scan_parquet(\n",
    "    [\n",
    "        \"docs/assets/data/hive/year=2024/month=01/data.parquet\",\n",
    "        \"docs/assets/data/hive/year=2024/month=02/data.parquet\",\n",
    "    ],\n",
    "    hive_partitioning=True,\n",
    ").collect()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For WRITE to hive files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌─────┬─────┬─────┐\n",
      "│ a   ┆ b   ┆ c   │\n",
      "│ --- ┆ --- ┆ --- │\n",
      "│ i64 ┆ i64 ┆ i32 │\n",
      "╞═════╪═════╪═════╡\n",
      "│ 1   ┆ 1   ┆ 1   │\n",
      "│ 1   ┆ 1   ┆ 1   │\n",
      "│ 2   ┆ 1   ┆ 1   │\n",
      "│ 2   ┆ 2   ┆ 1   │\n",
      "│ 3   ┆ 2   ┆ 1   │\n",
      "└─────┴─────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame({\"a\": [1, 1, 2, 2, 3], \"b\": [1, 1, 1, 2, 2], \"c\": 1})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partitioned by the columns a and b\n",
    "df.write_parquet(\"docs/assets/data/hive_write/\", partition_by=[\"a\", \"b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output following paths:\n",
    "```\n",
    "┌──────────────────────────────────────────────────────┐\n",
    "│ File path                                            │\n",
    "╞══════════════════════════════════════════════════════╡\n",
    "│ docs/assets/data/hive_write/a=1/b=1/00000000.parquet │\n",
    "│ docs/assets/data/hive_write/a=2/b=1/00000000.parquet │\n",
    "│ docs/assets/data/hive_write/a=2/b=2/00000000.parquet │\n",
    "│ docs/assets/data/hive_write/a=3/b=2/00000000.parquet │\n",
    "└──────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in eager mode (executed immediately)\n",
    "df = pl.read_json(\"docs/assets/data/path.json\")\n",
    "\n",
    "# read Newline Delimited JSON\n",
    "df = pl.read_ndjson(\"docs/assets/data/path.json\")\n",
    "\n",
    "# lazy mode (prefer - only Newline Delimited JSON)\n",
    "df = pl.scan_ndjson(\"docs/assets/data/path.csv\")\n",
    "\n",
    "# write csv\n",
    "df.write_json(\"docs/assets/data/path.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database\n",
    "\n",
    "detail: https://docs.pola.rs/user-guide/io/database/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engine\n",
    "\n",
    "Polars xử lý data theo cơ chế **column-wise Apache Arrow format** nên một số engine có thể bị chậm do phải load data row-wise vào Python trước khi copying data lại vào the column-wise Apache Arrow format\n",
    "- row-wise engine: **SQLAlchemy** or **DBAPI2** connection\n",
    "- column-wise engine: [ConnectorX](https://github.com/sfu-db/connector-x) or [ADBC](https://arrow.apache.org/docs/format/ADBC.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read\n",
    "\n",
    "`read_database_uri` faster than `read_database` for **SQLAlchemy** or **DBAPI2** connection if you are using a SQLAlchemy or DBAPI2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "via **URI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# via URI\n",
    "uri = \"postgresql://username:password@server:port/database\"\n",
    "query = \"SELECT * FROM foo\"\n",
    "\n",
    "pl.read_database_uri(query=query, uri=uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "via **connection engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# via connection engine\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "conn = create_engine(\"sqlite:///test.db\")\n",
    "# conn = sqlite3.connect(\"test.db\")\n",
    "\n",
    "query = \"SELECT * FROM foo\"\n",
    "\n",
    "pl.read_database(query=query, connection=conn.connect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write\n",
    "support engine:\n",
    "- SQLAlchemy\n",
    "- Arrow Database Connectivity (ADBC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"postgresql://username:password@server:port/database\"\n",
    "df = pl.DataFrame({\"foo\": [1, 2, 3]})\n",
    "\n",
    "df.write_database(table_name=\"records\", connection=uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"postgresql://username:password@server:port/database\"\n",
    "df = pl.DataFrame({\"foo\": [1, 2, 3]})\n",
    "\n",
    "df.write_database(table_name=\"records\", connection=uri, engine=\"adbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud Storage\n",
    "\n",
    "- **Service**: `AWS S3`, `Azure Blob Storage`, `Google Cloud Storage`\n",
    "\n",
    "- **File-format**: `Parquet`, `CSV`, `IPC`, `NDJSON`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Authen cloud](https://docs.pola.rs/user-guide/io/cloud-storage/#cloud-authentication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "source = \"s3://bucket/*.parquet\"\n",
    "\n",
    "storage_options = {\n",
    "    \"aws_access_key_id\": \"<secret>\",\n",
    "    \"aws_secret_access_key\": \"<secret>\",\n",
    "    \"aws_region\": \"us-east-1\",\n",
    "}\n",
    "df = pl.scan_parquet(source, storage_options=storage_options).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read\n",
    "\n",
    "Using `pl.scan_*` functions to read from cloud storage can benefit from [predicate and projection pushdowns](https://docs.pola.rs/user-guide/lazy/optimizations/), where the query optimizer will apply them before the file is downloaded. This can significantly reduce the amount of data that needs to be downloaded. The query evaluation is triggered by calling `collect`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"s3://bucket/*.parquet\"\n",
    "\n",
    "# Read file\n",
    "df = pl.read_parquet(source)\n",
    "\n",
    "# Scanning (query optimization)\n",
    "df = (\n",
    "    pl.scan_parquet(source)\n",
    "    .filter(pl.col(\"id\") < 100)\n",
    "    .select(\"id\", \"value\")\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write\n",
    "using: \n",
    "- `s3fs` for **S3**, \n",
    "- `adlfs` for **Azure Blob Storage**\n",
    "- `gcsfs` for **Google Cloud Storage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import s3fs\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"foo\": [\"a\", \"b\", \"c\", \"d\", \"d\"],\n",
    "        \"bar\": [1, 2, 3, 4, 5],\n",
    "    }\n",
    ")\n",
    "\n",
    "fs = s3fs.S3FileSystem()\n",
    "destination = \"s3://bucket/my_file.parquet\"\n",
    "\n",
    "# write parquet\n",
    "with fs.open(destination, mode=\"wb\") as f:\n",
    "    df.write_parquet(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Perform a query.\n",
    "QUERY = (\n",
    "    \"SELECT name FROM `bigquery-public-data.usa_names.usa_1910_2013` \"\n",
    "    'WHERE state = \"TX\" '\n",
    "    \"LIMIT 100\"\n",
    ")\n",
    "query_job = client.query(QUERY)  # API request\n",
    "rows = query_job.result()  # Waits for query to finish\n",
    "\n",
    "df = pl.from_arrow(rows.to_arrow())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import io\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Write DataFrame to stream as parquet file; does not hit disk\n",
    "with io.BytesIO() as stream:\n",
    "    df.write_parquet(stream)\n",
    "    stream.seek(0)\n",
    "    job = client.load_table_from_file(\n",
    "        stream,\n",
    "        destination=\"tablename\",\n",
    "        project=\"projectname\",\n",
    "        job_config=bigquery.LoadJobConfig(\n",
    "            source_format=bigquery.SourceFormat.PARQUET,\n",
    "        ),\n",
    "    )\n",
    "job.result()  # Waits for the job to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face\n",
    "https://docs.pola.rs/user-guide/io/hugging-face/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 4)\n",
      "┌────────────────┬────────────┬────────┬────────┐\n",
      "│ name           ┆ birthdate  ┆ weight ┆ height │\n",
      "│ ---            ┆ ---        ┆ ---    ┆ ---    │\n",
      "│ str            ┆ date       ┆ f64    ┆ f64    │\n",
      "╞════════════════╪════════════╪════════╪════════╡\n",
      "│ Alice Archer   ┆ 1997-01-10 ┆ 57.9   ┆ 1.56   │\n",
      "│ Ben Brown      ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
      "│ Chloe Cooper   ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   │\n",
      "│ Daniel Donovan ┆ 1981-04-30 ┆ 83.1   ┆ 1.75   │\n",
      "└────────────────┴────────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from datetime import date\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"name\": [\n",
    "            \"Alice Archer\",\n",
    "            \"Ben Brown\",\n",
    "            \"Chloe Cooper\",\n",
    "            \"Daniel Donovan\",\n",
    "        ],\n",
    "        \"birthdate\": [\n",
    "            date(1997, 1, 10),\n",
    "            date(1985, 2, 15),\n",
    "            date(1983, 3, 22),\n",
    "            date(1981, 4, 30),\n",
    "        ],\n",
    "        \"weight\": [57.9, 72.5, 53.6, 83.1],  # (kg)\n",
    "        \"height\": [1.56, 1.77, 1.65, 1.75],  # (m)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(col(\"weight\")) / (col(\"height\").pow([dyn int: 2]))]\n"
     ]
    }
   ],
   "source": [
    "bmi_expr = pl.col(\"weight\") / (pl.col(\"height\") ** 2)\n",
    "print(bmi_expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `bmi_expr` just is an expressions with lazy, no computations have taken place yet. That's what we need contexts for by `select`, `with_columns`, `filter`, `group_by`, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select and create\n",
    "\n",
    "**`select`**\n",
    "\n",
    "Select column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "┌────────┬────────────────┐\n",
      "│ weight ┆ name           │\n",
      "│ ---    ┆ ---            │\n",
      "│ f64    ┆ str            │\n",
      "╞════════╪════════════════╡\n",
      "│ 57.9   ┆ Alice Archer   │\n",
      "│ 72.5   ┆ Ben Brown      │\n",
      "│ 53.6   ┆ Chloe Cooper   │\n",
      "│ 83.1   ┆ Daniel Donovan │\n",
      "└────────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "subdf = df.select(pl.col(\"weight\"), pl.col(\"name\"))\n",
    "print(subdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf2 = df.select([\"weight\", \"name\"])\n",
    "subdf2.equals(subdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>weight</th></tr><tr><td>f64</td></tr></thead><tbody><tr><td>57.9</td></tr><tr><td>72.5</td></tr><tr><td>53.6</td></tr><tr><td>83.1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 1)\n",
       "┌────────┐\n",
       "│ weight │\n",
       "│ ---    │\n",
       "│ f64    │\n",
       "╞════════╡\n",
       "│ 57.9   │\n",
       "│ 72.5   │\n",
       "│ 53.6   │\n",
       "│ 83.1   │\n",
       "└────────┘"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "produce new columns / series that are ***aggregations***, ***combinations*** of other `columns`, or `literals` and same lenght with df or must be a scalar:\n",
    "  - Scalars will be broadcast to match the length of the remaining series\n",
    "  - Literals, like the number used above, are also broadcast\n",
    "  - Broadcasting can also occur within expressions\n",
    "\n",
    "> `select` only includes the columns selected by its input expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 4)\n",
      "┌───────────┬───────────┬───────────────┬───────────┐\n",
      "│ bmi       ┆ avg_bmi   ┆ ideal_max_bmi ┆ deviation │\n",
      "│ ---       ┆ ---       ┆ ---           ┆ ---       │\n",
      "│ f64       ┆ f64       ┆ i32           ┆ f64       │\n",
      "╞═══════════╪═══════════╪═══════════════╪═══════════╡\n",
      "│ 23.791913 ┆ 23.438973 ┆ 25            ┆ 0.115645  │\n",
      "│ 23.141498 ┆ 23.438973 ┆ 25            ┆ -0.097471 │\n",
      "│ 19.687787 ┆ 23.438973 ┆ 25            ┆ -1.22912  │\n",
      "│ 27.134694 ┆ 23.438973 ┆ 25            ┆ 1.210946  │\n",
      "└───────────┴───────────┴───────────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\n",
    "    bmi=bmi_expr,\n",
    "    avg_bmi=bmi_expr.mean(),\n",
    "    ideal_max_bmi=25,\n",
    "    deviation=(bmi_expr - bmi_expr.mean()) / bmi_expr.std(),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### by datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "┌────────┬────────┐\n",
      "│ weight ┆ height │\n",
      "│ ---    ┆ ---    │\n",
      "│ f64    ┆ f64    │\n",
      "╞════════╪════════╡\n",
      "│ 57.9   ┆ 1.56   │\n",
      "│ 72.5   ┆ 1.77   │\n",
      "│ 53.6   ┆ 1.65   │\n",
      "│ 83.1   ┆ 1.75   │\n",
      "└────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "float_df = df.select(pl.col(pl.Float64))\n",
    "print(float_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### by pattern matching in columns name\n",
    "\n",
    "- `^` : start\n",
    "- `$` : end \n",
    "- `*` : multi-characters\n",
    "- `.` : single-character\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "┌────────┬────────┐\n",
      "│ weight ┆ height │\n",
      "│ ---    ┆ ---    │\n",
      "│ f64    ┆ f64    │\n",
      "╞════════╪════════╡\n",
      "│ 57.9   ┆ 1.56   │\n",
      "│ 72.5   ┆ 1.77   │\n",
      "│ 53.6   ┆ 1.65   │\n",
      "│ 83.1   ┆ 1.75   │\n",
      "└────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\"^*ght$\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 4)\n",
      "┌────────────────┬────────────┬────────┬────────┐\n",
      "│ name           ┆ birthdate  ┆ weight ┆ height │\n",
      "│ ---            ┆ ---        ┆ ---    ┆ ---    │\n",
      "│ str            ┆ date       ┆ f64    ┆ f64    │\n",
      "╞════════════════╪════════════╪════════╪════════╡\n",
      "│ Alice Archer   ┆ 1997-01-10 ┆ 57.9   ┆ 1.56   │\n",
      "│ Ben Brown      ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
      "│ Chloe Cooper   ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   │\n",
      "│ Daniel Donovan ┆ 1981-04-30 ┆ 83.1   ┆ 1.75   │\n",
      "└────────────────┴────────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(pl.all())\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### exclude columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "┌────────────────┬────────────┐\n",
      "│ name           ┆ birthdate  │\n",
      "│ ---            ┆ ---        │\n",
      "│ str            ┆ date       │\n",
      "╞════════════════╪════════════╡\n",
      "│ Alice Archer   ┆ 1997-01-10 │\n",
      "│ Ben Brown      ┆ 1985-02-15 │\n",
      "│ Chloe Cooper   ┆ 1983-03-22 │\n",
      "│ Daniel Donovan ┆ 1981-04-30 │\n",
      "└────────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(pl.all().exclude(\"^*ght$\"))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`with_columns`**\n",
    "\n",
    "very similar to the context `select`, but `with_columns` creates a new dataframe that contains the columns from the original dataframe and the new columns according to its input expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 8)\n",
      "┌───────────────┬────────────┬────────┬────────┬───────────┬───────────┬───────────────┬───────────┐\n",
      "│ name          ┆ birthdate  ┆ weight ┆ height ┆ bmi       ┆ avg_bmi   ┆ ideal_max_bmi ┆ deviation │\n",
      "│ ---           ┆ ---        ┆ ---    ┆ ---    ┆ ---       ┆ ---       ┆ ---           ┆ ---       │\n",
      "│ str           ┆ date       ┆ f64    ┆ f64    ┆ f64       ┆ f64       ┆ i32           ┆ f64       │\n",
      "╞═══════════════╪════════════╪════════╪════════╪═══════════╪═══════════╪═══════════════╪═══════════╡\n",
      "│ Alice Archer  ┆ 1997-01-10 ┆ 57.9   ┆ 1.56   ┆ 23.791913 ┆ 23.438973 ┆ 25            ┆ 0.115645  │\n",
      "│ Ben Brown     ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   ┆ 23.141498 ┆ 23.438973 ┆ 25            ┆ -0.097471 │\n",
      "│ Chloe Cooper  ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   ┆ 19.687787 ┆ 23.438973 ┆ 25            ┆ -1.22912  │\n",
      "│ Daniel        ┆ 1981-04-30 ┆ 83.1   ┆ 1.75   ┆ 27.134694 ┆ 23.438973 ┆ 25            ┆ 1.210946  │\n",
      "│ Donovan       ┆            ┆        ┆        ┆           ┆           ┆               ┆           │\n",
      "└───────────────┴────────────┴────────┴────────┴───────────┴───────────┴───────────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.with_columns(\n",
    "    bmi=bmi_expr,\n",
    "    avg_bmi=bmi_expr.mean(),\n",
    "    ideal_max_bmi=25,\n",
    "    deviation=(bmi_expr - bmi_expr.mean()) / bmi_expr.std(),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`alias`**\n",
    "\n",
    "set name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n",
      "┌───────────┬───────────┬───────────┐\n",
      "│ bmi       ┆ avg_bmi   ┆ deviation │\n",
      "│ ---       ┆ ---       ┆ ---       │\n",
      "│ f64       ┆ f64       ┆ f64       │\n",
      "╞═══════════╪═══════════╪═══════════╡\n",
      "│ 23.791913 ┆ 23.438973 ┆ 0.115645  │\n",
      "│ 23.141498 ┆ 23.438973 ┆ -0.097471 │\n",
      "│ 19.687787 ┆ 23.438973 ┆ -1.22912  │\n",
      "│ 27.134694 ┆ 23.438973 ┆ 1.210946  │\n",
      "└───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\n",
    "    bmi_expr.alias(\"bmi\"),\n",
    "    bmi_expr.mean().alias(\"avg_bmi\"),\n",
    "    ((bmi_expr - bmi_expr.mean()) / bmi_expr.std()).alias(\"deviation\"),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### prefixing and suffixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n",
      "┌────────────────────┬────────────────────┬────────────────┐\n",
      "│ 10_multiple_weight ┆ 10_multiple_height ┆ birthdate_year │\n",
      "│ ---                ┆ ---                ┆ ---            │\n",
      "│ f64                ┆ f64                ┆ i32            │\n",
      "╞════════════════════╪════════════════════╪════════════════╡\n",
      "│ 579.0              ┆ 15.6               ┆ 1997           │\n",
      "│ 725.0              ┆ 17.7               ┆ 1985           │\n",
      "│ 536.0              ┆ 16.5               ┆ 1983           │\n",
      "│ 831.0              ┆ 17.5               ┆ 1981           │\n",
      "└────────────────────┴────────────────────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\n",
    "    (pl.col(\"^*ight$\") * 10).name.prefix(\"10_multiple_\"),\n",
    "    (pl.col(\"birthdate\").dt.year()).name.suffix(\"_year\"),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 4)\n",
      "┌────────────────┬────────────┬────────┬────────┐\n",
      "│ NAME           ┆ BIRTHDATE  ┆ WEIGHT ┆ HEIGHT │\n",
      "│ ---            ┆ ---        ┆ ---    ┆ ---    │\n",
      "│ str            ┆ date       ┆ f64    ┆ f64    │\n",
      "╞════════════════╪════════════╪════════╪════════╡\n",
      "│ Alice Archer   ┆ 1997-01-10 ┆ 57.9   ┆ 1.56   │\n",
      "│ Ben Brown      ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
      "│ Chloe Cooper   ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   │\n",
      "│ Daniel Donovan ┆ 1981-04-30 ┆ 83.1   ┆ 1.75   │\n",
      "└────────────────┴────────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# There is also `.name.to_uppercase`, so this usage of `.map` is moot.\n",
    "result = df.select(pl.all().name.map(str.upper))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter\n",
    "\n",
    "**`filter`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 4)\n",
      "┌───────────┬────────────┬────────┬────────┐\n",
      "│ name      ┆ birthdate  ┆ weight ┆ height │\n",
      "│ ---       ┆ ---        ┆ ---    ┆ ---    │\n",
      "│ str       ┆ date       ┆ f64    ┆ f64    │\n",
      "╞═══════════╪════════════╪════════╪════════╡\n",
      "│ Ben Brown ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
      "└───────────┴────────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.filter(\n",
    "    pl.col(\"birthdate\").is_between(date(1982, 12, 31), date(1996, 1, 1)),\n",
    "    pl.col(\"height\") > 1.7,\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌──────┬───────┬──────────┬────────┐\n",
      "│ nrs  ┆ names ┆ random   ┆ groups │\n",
      "│ ---  ┆ ---   ┆ ---      ┆ ---    │\n",
      "│ i64  ┆ str   ┆ f64      ┆ str    │\n",
      "╞══════╪═══════╪══════════╪════════╡\n",
      "│ 1    ┆ foo   ┆ 0.37454  ┆ A      │\n",
      "│ 2    ┆ ham   ┆ 0.950714 ┆ A      │\n",
      "│ 3    ┆ spam  ┆ 0.731994 ┆ B      │\n",
      "│ null ┆ egg   ┆ 0.598658 ┆ A      │\n",
      "│ 5    ┆ spam  ┆ 0.156019 ┆ B      │\n",
      "└──────┴───────┴──────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)  # For reproducibility.\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"nrs\": [1, 2, 3, None, 5],\n",
    "        \"names\": [\"foo\", \"ham\", \"spam\", \"egg\", \"spam\"],\n",
    "        \"random\": np.random.rand(5),\n",
    "        \"groups\": [\"A\", \"A\", \"B\", \"A\", \"B\"],\n",
    "    }\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 6)\n",
      "┌─────────┬──────────┬─────────────┬──────────────┬──────────┬──────────┐\n",
      "│ nrs > 1 ┆ nrs >= 3 ┆ random < .2 ┆ random <= .5 ┆ nrs != 1 ┆ nrs == 1 │\n",
      "│ ---     ┆ ---      ┆ ---         ┆ ---          ┆ ---      ┆ ---      │\n",
      "│ bool    ┆ bool     ┆ bool        ┆ bool         ┆ bool     ┆ bool     │\n",
      "╞═════════╪══════════╪═════════════╪══════════════╪══════════╪══════════╡\n",
      "│ false   ┆ false    ┆ false       ┆ true         ┆ false    ┆ true     │\n",
      "│ true    ┆ false    ┆ false       ┆ false        ┆ true     ┆ false    │\n",
      "│ true    ┆ true     ┆ false       ┆ false        ┆ true     ┆ false    │\n",
      "│ null    ┆ null     ┆ false       ┆ false        ┆ null     ┆ null     │\n",
      "│ true    ┆ true     ┆ true        ┆ true         ┆ true     ┆ false    │\n",
      "└─────────┴──────────┴─────────────┴──────────────┴──────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\n",
    "    (pl.col(\"nrs\") > 1).alias(\"nrs > 1\"),  # .gt\n",
    "    (pl.col(\"nrs\") >= 3).alias(\"nrs >= 3\"),  # ge\n",
    "    (pl.col(\"random\") < 0.2).alias(\"random < .2\"),  # .lt\n",
    "    (pl.col(\"random\") <= 0.5).alias(\"random <= .5\"),  # .le\n",
    "    (pl.col(\"nrs\") != 1).alias(\"nrs != 1\"),  # .ne\n",
    "    (pl.col(\"nrs\") == 1).alias(\"nrs == 1\"),  # .eq\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the operators `&`, `|`, and `~`, for the Boolean operations “and”, “or”, and “not”, respectively, or the functions of the same name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌─────────────────────────────┬─────────────────────────┬─────────────┐\n",
      "│ number not null and group A ┆ random < 0.5 or group B ┆ group not B │\n",
      "│ ---                         ┆ ---                     ┆ ---         │\n",
      "│ bool                        ┆ bool                    ┆ bool        │\n",
      "╞═════════════════════════════╪═════════════════════════╪═════════════╡\n",
      "│ true                        ┆ true                    ┆ true        │\n",
      "│ true                        ┆ false                   ┆ true        │\n",
      "│ false                       ┆ true                    ┆ false       │\n",
      "│ false                       ┆ false                   ┆ true        │\n",
      "│ false                       ┆ true                    ┆ false       │\n",
      "└─────────────────────────────┴─────────────────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Boolean operators & | ~\n",
    "result = df.select(\n",
    "    ((~pl.col(\"nrs\").is_null()) & (pl.col(\"groups\") == \"A\")).alias(\n",
    "        \"number not null and group A\"\n",
    "    ),\n",
    "    ((pl.col(\"random\") < 0.5) | (pl.col(\"groups\") == \"B\")).alias(\n",
    "        \"random < 0.5 or group B\"\n",
    "    ),\n",
    "    (pl.col(\"groups\") != \"B\").alias(\"group not B\"),\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Corresponding named functions `and_`, `or_`, and `not_`.\n",
    "result2 = df.select(\n",
    "    (pl.col(\"nrs\").is_null().not_().and_(pl.col(\"groups\") == \"A\")).alias(\n",
    "        \"number not null and group A\"\n",
    "    ),\n",
    "    ((pl.col(\"random\") < 0.5).or_(pl.col(\"groups\") == \"B\")).alias(\n",
    "        \"random < 0.5 or group B\"\n",
    "    ),\n",
    ")\n",
    "print(result.equals(result2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `n_unique`: exact number but may be slow for large dataset\n",
    "- `approx_n_unique`: approximation by uses the algorithm [HyperLogLog++](https://en.wikipedia.org/wiki/HyperLogLog) to estimate the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 2)\n",
      "┌──────────┬─────────────────┐\n",
      "│ n_unique ┆ approx_n_unique │\n",
      "│ ---      ┆ ---             │\n",
      "│ u32      ┆ u32             │\n",
      "╞══════════╪═════════════════╡\n",
      "│ 63218    ┆ 63784           │\n",
      "└──────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "long_df = pl.DataFrame({\"numbers\": np.random.randint(0, 100_000, 100_000)})\n",
    "\n",
    "result = long_df.select(\n",
    "    pl.col(\"numbers\").n_unique().alias(\"n_unique\"),\n",
    "    pl.col(\"numbers\").approx_n_unique().alias(\"approx_n_unique\"),\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `value_counts`: unique values and their counts as `structs` datatype\n",
    "- `unique`: return only unique value\n",
    "- `unique_counts`: return only unique value count (need `unique(maintain_order=True)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n",
      "┌──────────────┬────────┬───────────────┐\n",
      "│ value_counts ┆ unique ┆ unique_counts │\n",
      "│ ---          ┆ ---    ┆ ---           │\n",
      "│ struct[2]    ┆ str    ┆ u32           │\n",
      "╞══════════════╪════════╪═══════════════╡\n",
      "│ {\"spam\",2}   ┆ foo    ┆ 1             │\n",
      "│ {\"foo\",1}    ┆ ham    ┆ 1             │\n",
      "│ {\"ham\",1}    ┆ spam   ┆ 2             │\n",
      "│ {\"egg\",1}    ┆ egg    ┆ 1             │\n",
      "└──────────────┴────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select()\n",
    "\n",
    "result = df.select(\n",
    "    pl.col(\"names\").value_counts(sort=True).alias(\"value_counts\"),\n",
    "    pl.col(\"names\").unique(maintain_order=True).alias(\"unique\"),\n",
    "    pl.col(\"names\").unique_counts().alias(\"unique_counts\"),\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional (when - then - else)\n",
    "- `when`: accept predicate expression (True/False seri)\n",
    "- `then`: corresponding values of the expression inside if when = `True`\n",
    "- `otherwise`: corresponding values of the expression inside if when = `False`, or `null` if not provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌──────┬─────────┐\n",
      "│ nrs  ┆ Collatz │\n",
      "│ ---  ┆ ---     │\n",
      "│ i64  ┆ i64     │\n",
      "╞══════╪═════════╡\n",
      "│ 1    ┆ 2       │\n",
      "│ 2    ┆ 8       │\n",
      "│ 3    ┆ 27      │\n",
      "│ null ┆ 9999    │\n",
      "│ 5    ┆ 125     │\n",
      "└──────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\n",
    "    pl.col(\"nrs\"),\n",
    "    pl.when(pl.col(\"nrs\") == 1)\n",
    "    .then(pl.col(\"nrs\") + 1)\n",
    "    .otherwise(\n",
    "        pl.when(pl.col(\"nrs\").is_null())\n",
    "        .then(9999)\n",
    "        .otherwise(pl.col(\"nrs\") ** 3)\n",
    "    )\n",
    "    .alias(\"Collatz\"),\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expression expansion\n",
    "\n",
    "a shorthand notation for when you want to apply the same transformation to multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌────────┬───────────────────┬────────┬──────────┬─────────┬───────────┬──────────┐\n",
      "│ ticker ┆ company_name      ┆ price  ┆ day_high ┆ day_low ┆ year_high ┆ year_low │\n",
      "│ ---    ┆ ---               ┆ ---    ┆ ---      ┆ ---     ┆ ---       ┆ ---      │\n",
      "│ str    ┆ str               ┆ f64    ┆ f64      ┆ f64     ┆ f64       ┆ f64      │\n",
      "╞════════╪═══════════════════╪════════╪══════════╪═════════╪═══════════╪══════════╡\n",
      "│ AAPL   ┆ Apple             ┆ 229.9  ┆ 231.31   ┆ 228.6   ┆ 237.23    ┆ 164.08   │\n",
      "│ NVDA   ┆ NVIDIA            ┆ 138.93 ┆ 139.6    ┆ 136.3   ┆ 140.76    ┆ 39.23    │\n",
      "│ MSFT   ┆ Microsoft         ┆ 420.56 ┆ 424.04   ┆ 417.52  ┆ 468.35    ┆ 324.39   │\n",
      "│ GOOG   ┆ Alphabet (Google) ┆ 166.41 ┆ 167.62   ┆ 164.78  ┆ 193.31    ┆ 121.46   │\n",
      "│ AMZN   ┆ Amazon            ┆ 188.4  ┆ 189.83   ┆ 188.44  ┆ 201.2     ┆ 118.35   │\n",
      "└────────┴───────────────────┴────────┴──────────┴─────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {  # As of 14th October 2024, ~3pm UTC\n",
    "        \"ticker\": [\"AAPL\", \"NVDA\", \"MSFT\", \"GOOG\", \"AMZN\"],\n",
    "        \"company_name\": [\n",
    "            \"Apple\",\n",
    "            \"NVIDIA\",\n",
    "            \"Microsoft\",\n",
    "            \"Alphabet (Google)\",\n",
    "            \"Amazon\",\n",
    "        ],\n",
    "        \"price\": [229.9, 138.93, 420.56, 166.41, 188.4],\n",
    "        \"day_high\": [231.31, 139.6, 424.04, 167.62, 189.83],\n",
    "        \"day_low\": [228.6, 136.3, 417.52, 164.78, 188.44],\n",
    "        \"year_high\": [237.23, 140.76, 468.35, 193.31, 201.2],\n",
    "        \"year_low\": [164.08, 39.23, 324.39, 121.46, 118.35],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example: compute the mean value of the columns “price” and “year_high” and will rename them as “avg_year_high” and “avg_year_high”, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>avg_price</th><th>avg_year_high</th></tr><tr><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>228.84</td><td>248.17</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 2)\n",
       "┌───────────┬───────────────┐\n",
       "│ avg_price ┆ avg_year_high │\n",
       "│ ---       ┆ ---           │\n",
       "│ f64       ┆ f64           │\n",
       "╞═══════════╪═══════════════╡\n",
       "│ 228.84    ┆ 248.17        │\n",
       "└───────────┴───────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# instead of\n",
    "[\n",
    "    pl.col(\"price\").mean().alias(\"avg_price\"),\n",
    "    pl.col(\"year_high\").mean().alias(\"avg_year_high\"),\n",
    "]\n",
    "\n",
    "# using\n",
    "expr = pl.col(\"price\", \"year_high\").mean().name.prefix(\"avg_\")\n",
    "df.select(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 5)\n",
      "┌───────────┬──────────────┬─────────────┬───────────────┬──────────────┐\n",
      "│ price*1.1 ┆ day_high*1.1 ┆ day_low*1.1 ┆ year_high*1.1 ┆ year_low*1.1 │\n",
      "│ ---       ┆ ---          ┆ ---         ┆ ---           ┆ ---          │\n",
      "│ f64       ┆ f64          ┆ f64         ┆ f64           ┆ f64          │\n",
      "╞═══════════╪══════════════╪═════════════╪═══════════════╪══════════════╡\n",
      "│ 252.89    ┆ 254.441      ┆ 251.46      ┆ 260.953       ┆ 180.488      │\n",
      "│ 152.823   ┆ 153.56       ┆ 149.93      ┆ 154.836       ┆ 43.153       │\n",
      "│ 462.616   ┆ 466.444      ┆ 459.272     ┆ 515.185       ┆ 356.829      │\n",
      "│ 183.051   ┆ 184.382      ┆ 181.258     ┆ 212.641       ┆ 133.606      │\n",
      "│ 207.24    ┆ 208.813      ┆ 207.284     ┆ 221.32        ┆ 130.185      │\n",
      "└───────────┴──────────────┴─────────────┴───────────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# multiply all columns with data type Float64 by 1.1\n",
    "expr = (pl.col(pl.Float64) * 1.1).name.suffix(\"*1.1\")\n",
    "result = df.select(expr)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How to select columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### by columns name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌────────┬───────────────────┬───────┬──────────┬─────────┬───────────┬──────────┐\n",
      "│ ticker ┆ company_name      ┆ price ┆ day_high ┆ day_low ┆ year_high ┆ year_low │\n",
      "│ ---    ┆ ---               ┆ ---   ┆ ---      ┆ ---     ┆ ---       ┆ ---      │\n",
      "│ str    ┆ str               ┆ f64   ┆ f64      ┆ f64     ┆ f64       ┆ f64      │\n",
      "╞════════╪═══════════════════╪═══════╪══════════╪═════════╪═══════════╪══════════╡\n",
      "│ AAPL   ┆ Apple             ┆ 191.6 ┆ 192.8    ┆ 190.5   ┆ 197.7     ┆ 136.7    │\n",
      "│ NVDA   ┆ NVIDIA            ┆ 115.8 ┆ 116.3    ┆ 113.6   ┆ 117.3     ┆ 32.7     │\n",
      "│ MSFT   ┆ Microsoft         ┆ 350.5 ┆ 353.4    ┆ 347.9   ┆ 390.3     ┆ 270.3    │\n",
      "│ GOOG   ┆ Alphabet (Google) ┆ 138.7 ┆ 139.7    ┆ 137.3   ┆ 161.1     ┆ 101.2    │\n",
      "│ AMZN   ┆ Amazon            ┆ 157.0 ┆ 158.2    ┆ 157.0   ┆ 167.7     ┆ 98.6     │\n",
      "└────────┴───────────────────┴───────┴──────────┴─────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "eur_usd_rate = 1.2\n",
    "\n",
    "result = df.with_columns(\n",
    "    (\n",
    "        pl.col(\n",
    "            \"price\",\n",
    "            \"day_high\",\n",
    "            \"day_low\",\n",
    "            \"year_high\",\n",
    "            \"year_low\",\n",
    "        )\n",
    "        / eur_usd_rate\n",
    "    ).round(1)\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### by datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌────────┬───────────────────┬────────┬──────────┬─────────┬───────────┬──────────┐\n",
      "│ ticker ┆ company_name      ┆ price  ┆ day_high ┆ day_low ┆ year_high ┆ year_low │\n",
      "│ ---    ┆ ---               ┆ ---    ┆ ---      ┆ ---     ┆ ---       ┆ ---      │\n",
      "│ str    ┆ str               ┆ f64    ┆ f64      ┆ f64     ┆ f64       ┆ f64      │\n",
      "╞════════╪═══════════════════╪════════╪══════════╪═════════╪═══════════╪══════════╡\n",
      "│ AAPL   ┆ Apple             ┆ 191.58 ┆ 192.76   ┆ 190.5   ┆ 197.69    ┆ 136.73   │\n",
      "│ NVDA   ┆ NVIDIA            ┆ 115.78 ┆ 116.33   ┆ 113.58  ┆ 117.3     ┆ 32.69    │\n",
      "│ MSFT   ┆ Microsoft         ┆ 350.47 ┆ 353.37   ┆ 347.93  ┆ 390.29    ┆ 270.33   │\n",
      "│ GOOG   ┆ Alphabet (Google) ┆ 138.68 ┆ 139.68   ┆ 137.32  ┆ 161.09    ┆ 101.22   │\n",
      "│ AMZN   ┆ Amazon            ┆ 157.0  ┆ 158.19   ┆ 157.03  ┆ 167.67    ┆ 98.63    │\n",
      "└────────┴───────────────────┴────────┴──────────┴─────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "result2 = df.with_columns(\n",
    "    (\n",
    "        pl.col(\n",
    "            pl.Float32,\n",
    "            pl.Float64,\n",
    "        )\n",
    "        / eur_usd_rate\n",
    "    ).round(2)\n",
    ")\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### by pattern matching in columns name\n",
    "\n",
    "- `^` : start\n",
    "- `$` : end \n",
    "- `*` : multi-characters\n",
    "- `.` : single-character\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 5)\n",
      "┌────────┬──────────┬───────────┬─────────┬──────────┐\n",
      "│ ticker ┆ day_high ┆ year_high ┆ day_low ┆ year_low │\n",
      "│ ---    ┆ ---      ┆ ---       ┆ ---     ┆ ---      │\n",
      "│ str    ┆ f64      ┆ f64       ┆ f64     ┆ f64      │\n",
      "╞════════╪══════════╪═══════════╪═════════╪══════════╡\n",
      "│ AAPL   ┆ 231.31   ┆ 237.23    ┆ 228.6   ┆ 164.08   │\n",
      "│ NVDA   ┆ 139.6    ┆ 140.76    ┆ 136.3   ┆ 39.23    │\n",
      "│ MSFT   ┆ 424.04   ┆ 468.35    ┆ 417.52  ┆ 324.39   │\n",
      "│ GOOG   ┆ 167.62   ┆ 193.31    ┆ 164.78  ┆ 121.46   │\n",
      "│ AMZN   ┆ 189.83   ┆ 201.2     ┆ 188.44  ┆ 118.35   │\n",
      "└────────┴──────────┴───────────┴─────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(pl.col(\"ticker\", \"^.*_high$\", \"^.*_low$\"))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate expressions\n",
    "\n",
    "Instead of `Way 1`, should do by `Way 2` to:\n",
    "- do a better job at optimising the query\n",
    "- parallelise the execution of the actual computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 9)\n",
      "┌────────┬──────────────┬────────┬──────────┬───┬───────────┬──────────┬─────────────┬─────────────┐\n",
      "│ ticker ┆ company_name ┆ price  ┆ day_high ┆ … ┆ year_high ┆ year_low ┆ day_amplitu ┆ year_amplit │\n",
      "│ ---    ┆ ---          ┆ ---    ┆ ---      ┆   ┆ ---       ┆ ---      ┆ de          ┆ ude         │\n",
      "│ str    ┆ str          ┆ f64    ┆ f64      ┆   ┆ f64       ┆ f64      ┆ ---         ┆ ---         │\n",
      "│        ┆              ┆        ┆          ┆   ┆           ┆          ┆ f64         ┆ f64         │\n",
      "╞════════╪══════════════╪════════╪══════════╪═══╪═══════════╪══════════╪═════════════╪═════════════╡\n",
      "│ AAPL   ┆ Apple        ┆ 229.9  ┆ 231.31   ┆ … ┆ 237.23    ┆ 164.08   ┆ 2.71        ┆ 73.15       │\n",
      "│ NVDA   ┆ NVIDIA       ┆ 138.93 ┆ 139.6    ┆ … ┆ 140.76    ┆ 39.23    ┆ 3.3         ┆ 101.53      │\n",
      "│ MSFT   ┆ Microsoft    ┆ 420.56 ┆ 424.04   ┆ … ┆ 468.35    ┆ 324.39   ┆ 6.52        ┆ 143.96      │\n",
      "│ GOOG   ┆ Alphabet     ┆ 166.41 ┆ 167.62   ┆ … ┆ 193.31    ┆ 121.46   ┆ 2.84        ┆ 71.85       │\n",
      "│        ┆ (Google)     ┆        ┆          ┆   ┆           ┆          ┆             ┆             │\n",
      "│ AMZN   ┆ Amazon       ┆ 188.4  ┆ 189.83   ┆ … ┆ 201.2     ┆ 118.35   ┆ 1.39        ┆ 82.85       │\n",
      "└────────┴──────────────┴────────┴──────────┴───┴───────────┴──────────┴─────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Way 1:\n",
    "result = df\n",
    "for tp in [\"day\", \"year\"]:\n",
    "    result = result.with_columns(\n",
    "        (pl.col(f\"{tp}_high\") - pl.col(f\"{tp}_low\")).alias(f\"{tp}_amplitude\")\n",
    "    )\n",
    "\n",
    "\n",
    "# Way 2 (should do):\n",
    "def amplitude_expressions(time_periods):\n",
    "    for tp in time_periods:\n",
    "        yield (pl.col(f\"{tp}_high\") - pl.col(f\"{tp}_low\")).alias(\n",
    "            f\"{tp}_amplitude\"\n",
    "        )\n",
    "\n",
    "\n",
    "result = df.with_columns(amplitude_expressions([\"day\", \"year\"]))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatype Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌────────┬───────────────────┬────────┬──────────┬─────────┬───────────┬──────────┐\n",
      "│ ticker ┆ company_name      ┆ price  ┆ day_high ┆ day_low ┆ year_high ┆ year_low │\n",
      "│ ---    ┆ ---               ┆ ---    ┆ ---      ┆ ---     ┆ ---       ┆ ---      │\n",
      "│ str    ┆ str               ┆ f64    ┆ i64      ┆ i64     ┆ i64       ┆ i64      │\n",
      "╞════════╪═══════════════════╪════════╪══════════╪═════════╪═══════════╪══════════╡\n",
      "│ AAPL   ┆ Apple             ┆ 229.9  ┆ 231      ┆ 228     ┆ 237       ┆ 164      │\n",
      "│ NVDA   ┆ NVIDIA            ┆ 138.93 ┆ 139      ┆ 136     ┆ 140       ┆ 39       │\n",
      "│ MSFT   ┆ Microsoft         ┆ 420.56 ┆ 424      ┆ 417     ┆ 468       ┆ 324      │\n",
      "│ GOOG   ┆ Alphabet (Google) ┆ 166.41 ┆ 167      ┆ 164     ┆ 193       ┆ 121      │\n",
      "│ AMZN   ┆ Amazon            ┆ 188.4  ┆ 189      ┆ 188     ┆ 201       ┆ 118      │\n",
      "└────────┴───────────────────┴────────┴──────────┴─────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {  # As of 14th October 2024, ~3pm UTC\n",
    "        \"ticker\": [\"AAPL\", \"NVDA\", \"MSFT\", \"GOOG\", \"AMZN\"],\n",
    "        \"company_name\": [\n",
    "            \"Apple\",\n",
    "            \"NVIDIA\",\n",
    "            \"Microsoft\",\n",
    "            \"Alphabet (Google)\",\n",
    "            \"Amazon\",\n",
    "        ],\n",
    "        \"price\": [229.9, 138.93, 420.56, 166.41, 188.4],\n",
    "        \"day_high\": [231, 139, 424, 167, 189],\n",
    "        \"day_low\": [228, 136, 417, 164, 188],\n",
    "        \"year_high\": [237, 140, 468, 193, 201],\n",
    "        \"year_low\": [164, 39, 324, 121, 118],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Casting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `cast`\n",
    " - `strict` that determines how Polars behaves when it encounters a value that cannot be converted from the source data type to the target data type\n",
    "   - `strict=True`: raise if error\n",
    "   - `strict=False`: `null` if error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌──────────────────────────┬─────────────────────────────┐\n",
      "│ price_integers_as_floats ┆ day_high_floats_as_integers │\n",
      "│ ---                      ┆ ---                         │\n",
      "│ f32                      ┆ i32                         │\n",
      "╞══════════════════════════╪═════════════════════════════╡\n",
      "│ 229.899994               ┆ 231                         │\n",
      "│ 138.929993               ┆ 139                         │\n",
      "│ 420.559998               ┆ 424                         │\n",
      "│ 166.410004               ┆ 167                         │\n",
      "│ 188.399994               ┆ 189                         │\n",
      "└──────────────────────────┴─────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\n",
    "    pl.col(\"price\").cast(pl.Float32).name.suffix(\"_integers_as_floats\"),\n",
    "    pl.col(\"day_high\").cast(pl.Int32).name.suffix(\"_floats_as_integers\"),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### downcasting numerical\n",
    "\n",
    "Reduce the memory footprint of a column by changing the precision associated with its numeric data type:\n",
    "- `Int64` --> `Int16` \n",
    "- `Float64` --> `Float32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before downcasting: 263 bytes\n",
      "After downcasting: 229 bytes\n",
      "shape: (5, 8)\n",
      "┌────────┬────────────────┬────────────┬──────────┬─────────┬───────────┬──────────┬───────────────┐\n",
      "│ ticker ┆ company_name   ┆ price      ┆ day_high ┆ day_low ┆ year_high ┆ year_low ┆ year_low_conv │\n",
      "│ ---    ┆ ---            ┆ ---        ┆ ---      ┆ ---     ┆ ---       ┆ ---      ┆ ert_with_stri │\n",
      "│ str    ┆ str            ┆ f32        ┆ i32      ┆ i64     ┆ i64       ┆ i64      ┆ ct            │\n",
      "│        ┆                ┆            ┆          ┆         ┆           ┆          ┆ ---           │\n",
      "│        ┆                ┆            ┆          ┆         ┆           ┆          ┆ i8            │\n",
      "╞════════╪════════════════╪════════════╪══════════╪═════════╪═══════════╪══════════╪═══════════════╡\n",
      "│ AAPL   ┆ Apple          ┆ 229.899994 ┆ 231      ┆ 228     ┆ 237       ┆ 164      ┆ null          │\n",
      "│ NVDA   ┆ NVIDIA         ┆ 138.929993 ┆ 139      ┆ 136     ┆ 140       ┆ 39       ┆ 39            │\n",
      "│ MSFT   ┆ Microsoft      ┆ 420.559998 ┆ 424      ┆ 417     ┆ 468       ┆ 324      ┆ null          │\n",
      "│ GOOG   ┆ Alphabet       ┆ 166.410004 ┆ 167      ┆ 164     ┆ 193       ┆ 121      ┆ 121           │\n",
      "│        ┆ (Google)       ┆            ┆          ┆         ┆           ┆          ┆               │\n",
      "│ AMZN   ┆ Amazon         ┆ 188.399994 ┆ 189      ┆ 188     ┆ 201       ┆ 118      ┆ 118           │\n",
      "└────────┴────────────────┴────────────┴──────────┴─────────┴───────────┴──────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before downcasting: {df.estimated_size()} bytes\")\n",
    "result = df.with_columns(\n",
    "    pl.col(\"price\").cast(pl.Float32),\n",
    "    pl.col(\"day_high\").cast(pl.Int32),\n",
    "    pl.col(\"year_low\")\n",
    "    .cast(pl.Int8, strict=False)\n",
    "    .alias(\"year_low_convert_with_strict\"),\n",
    ")\n",
    "print(f\"After downcasting: {result.estimated_size()} bytes\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### strings to numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Math (number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌─────────┬─────────┬─────────┬──────────────┬──────────────┬──────────┬─────────┐\n",
      "│ raw_nrs ┆ nrs + 5 ┆ nrs - 5 ┆ nrs * random ┆ nrs / random ┆ nrs ** 2 ┆ nrs % 3 │\n",
      "│ ---     ┆ ---     ┆ ---     ┆ ---          ┆ ---          ┆ ---      ┆ ---     │\n",
      "│ i64     ┆ i64     ┆ i64     ┆ f64          ┆ f64          ┆ i64      ┆ i64     │\n",
      "╞═════════╪═════════╪═════════╪══════════════╪══════════════╪══════════╪═════════╡\n",
      "│ 1       ┆ 6       ┆ -4      ┆ 0.37454      ┆ 2.669941     ┆ 1        ┆ 1       │\n",
      "│ 2       ┆ 7       ┆ -3      ┆ 1.901429     ┆ 2.103681     ┆ 4        ┆ 2       │\n",
      "│ 3       ┆ 8       ┆ -2      ┆ 2.195982     ┆ 4.098395     ┆ 9        ┆ 0       │\n",
      "│ null    ┆ null    ┆ null    ┆ null         ┆ null         ┆ null     ┆ null    │\n",
      "│ 5       ┆ 10      ┆ 0       ┆ 0.780093     ┆ 32.047453    ┆ 25       ┆ 2       │\n",
      "└─────────┴─────────┴─────────┴──────────────┴──────────────┴──────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\n",
    "    pl.col(\"nrs\").alias(\"raw_nrs\"),\n",
    "    (pl.col(\"nrs\") + 5).alias(\"nrs + 5\"),\n",
    "    (pl.col(\"nrs\") - 5).alias(\"nrs - 5\"),\n",
    "    (pl.col(\"nrs\") * pl.col(\"random\")).alias(\"nrs * random\"),\n",
    "    (pl.col(\"nrs\") / pl.col(\"random\")).alias(\"nrs / random\"),\n",
    "    (pl.col(\"nrs\") ** 2).alias(\"nrs ** 2\"),\n",
    "    (pl.col(\"nrs\") % 3).alias(\"nrs % 3\"),\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use **named functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Python only:\n",
    "result_named_operators = df.select(\n",
    "    pl.col(\"nrs\").alias(\"raw_nrs\"),\n",
    "    (pl.col(\"nrs\").add(5)).alias(\"nrs + 5\"),\n",
    "    (pl.col(\"nrs\").sub(5)).alias(\"nrs - 5\"),\n",
    "    (pl.col(\"nrs\").mul(pl.col(\"random\"))).alias(\"nrs * random\"),\n",
    "    (pl.col(\"nrs\").truediv(pl.col(\"random\"))).alias(\"nrs / random\"),\n",
    "    (pl.col(\"nrs\").pow(2)).alias(\"nrs ** 2\"),\n",
    "    (pl.col(\"nrs\").mod(3)).alias(\"nrs % 3\"),\n",
    ")\n",
    "\n",
    "print(result.equals(result_named_operators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lists and array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical and enums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 4)\n",
      "┌────────────────┬────────────┬────────┬────────┐\n",
      "│ name           ┆ birthdate  ┆ weight ┆ height │\n",
      "│ ---            ┆ ---        ┆ ---    ┆ ---    │\n",
      "│ str            ┆ date       ┆ f64    ┆ f64    │\n",
      "╞════════════════╪════════════╪════════╪════════╡\n",
      "│ Alice Archer   ┆ 1997-01-10 ┆ 57.9   ┆ 1.56   │\n",
      "│ Ben Brown      ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
      "│ Chloe Cooper   ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   │\n",
      "│ Daniel Donovan ┆ 1981-04-30 ┆ 83.1   ┆ 1.75   │\n",
      "└────────────────┴────────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`group_by`**\n",
    "\n",
    "After using `group_by` we use `agg` to apply aggregating expressions to the groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "┌────────┬─────────────────────────────────┐\n",
      "│ decade ┆ name                            │\n",
      "│ ---    ┆ ---                             │\n",
      "│ i32    ┆ list[str]                       │\n",
      "╞════════╪═════════════════════════════════╡\n",
      "│ 1990   ┆ [\"Alice Archer\"]                │\n",
      "│ 1980   ┆ [\"Ben Brown\", \"Chloe Cooper\", … │\n",
      "└────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.group_by(\n",
    "    (pl.col(\"birthdate\").dt.year() // 10 * 10).alias(\n",
    "        \"decade\"\n",
    "    ),  # group by label 1\n",
    ").agg(pl.col(\"name\"))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> the groups of that column as lists\n",
    "\n",
    "For multi-label of grouper and multi expressions each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 6)\n",
      "┌────────┬────────┬─────┬─────────┬────────────┬────────────┐\n",
      "│ decade ┆ short? ┆ len ┆ tallest ┆ avg_weight ┆ avg_height │\n",
      "│ ---    ┆ ---    ┆ --- ┆ ---     ┆ ---        ┆ ---        │\n",
      "│ i32    ┆ bool   ┆ u32 ┆ f64     ┆ f64        ┆ f64        │\n",
      "╞════════╪════════╪═════╪═════════╪════════════╪════════════╡\n",
      "│ 1980   ┆ true   ┆ 1   ┆ 1.65    ┆ 53.6       ┆ 1.65       │\n",
      "│ 1990   ┆ true   ┆ 1   ┆ 1.56    ┆ 57.9       ┆ 1.56       │\n",
      "│ 1980   ┆ false  ┆ 2   ┆ 1.77    ┆ 77.8       ┆ 1.76       │\n",
      "└────────┴────────┴─────┴─────────┴────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.group_by(\n",
    "    (pl.col(\"birthdate\").dt.year() // 10 * 10).alias(\n",
    "        \"decade\"\n",
    "    ),  # group by label 1\n",
    "    (pl.col(\"height\") < 1.7).alias(\"short?\"),  # group by label 2\n",
    ").agg(\n",
    "    pl.len(),\n",
    "    pl.col(\"height\").max().alias(\"tallest\"),\n",
    "    pl.col(\"weight\", \"height\").mean().name.prefix(\"avg_\"),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folds functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
