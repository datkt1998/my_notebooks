{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps end-to-end system on GCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLOps fundamentals\n",
    "\n",
    "<img src=\"_image\\mlops_funda.webp\">\n",
    "\n",
    "**MLOps** is a set of principles and best practices that ensure efficient and reliable ML systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modularity: loosely coupled architecture\n",
    "\n",
    "ML system should be build as a set of modulars (**Modularity** - loosely coupled), refers to developing system based on **independence components**, each one with its own specific function or task. This facilitates the scalability and reusability of solutions, as well as the flexible integration of these single components to build more complete systems.\n",
    "\n",
    "Each step of pipeline should be build independence (Even if input or output as the same. Ex: training pipeline and inference pipeline). Each of module could be reused identical steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines Orchestration and Automation\n",
    "\n",
    "Pipeline ML là chuỗi các nhiệm vụ liên kết với nhau để tạo ra một quy trình làm việc hoàn chỉnh. Trong MLOps, cần có sự **tự động hóa** và **điều phối** pipeline này để chúng hoạt động một cách mượt mà.\n",
    "\n",
    "Cụ thể:\n",
    "- Pipeline có thể tự động trigger bởi 1 action hoặc 1 event hoặc 1 lịch cụ thể nào đó\n",
    "- Data được điều phối một cách tự động trong code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Integration and Delivery (CI/CD) pipelines\n",
    "\n",
    "**CI/CD pipelines** help automate tasks that previously needed to be done manually. With GCP, using **Cloud Build** which is the serverless CI/CD platform of GCP, we have constructed several workflows that enhance functional particularities and optimize frequent procedures.\n",
    "\n",
    "Hệ thống sử dụng **Cloud Build** để tự động tạo các phiên bản cập nhật của Docker image và triển khai lên các dịch vụ như Cloud Run hoặc Artifact Registry.\n",
    "\n",
    "**1. Trainer Image CI/CD workflow**\n",
    "\n",
    "Triggered by a push commit that involves changes in **trainer source code**, or **trainer dependencies**, or **trainer Dockerfile definition**\n",
    "\n",
    "- (1) Automate build an updated version of trainer docker image\n",
    "- (2) Then automate push image to Artifact Registry\n",
    "\n",
    "`cloudbuild-trainer-image-workflow.yaml`\n",
    "```yaml\n",
    "steps:\n",
    "- id: 'Clone Cloud Source Repository'\n",
    "  name: 'gcr.io/cloud-builders/gcloud'\n",
    "  args: ['source', 'repos', 'clone',\n",
    "         '${_CLOUD_SOURCE_REPOSITORY}',\n",
    "         '--project=${PROJECT_ID}'\n",
    "         ] \n",
    "         \n",
    "- id: 'Build updated Trainer Docker image'\n",
    "  name: 'gcr.io/cloud-builders/docker'\n",
    "  args: ['build',\n",
    "         '-f', '${_DOCKERFILE_NAME}',\n",
    "         '-t', '${_ARTIFACT_REGISTRY_REPO_LOCATION}-docker.pkg.dev/${PROJECT_ID}/${_ARTIFACT_REGISTRY_REPO_NAME}/${_TRAINER_IMAGE_NAME}:${_TRAINER_IMAGE_TAG}',\n",
    "         '.'\n",
    "        ]\n",
    "  # workdir to execute this step from\n",
    "  dir: '${_CLOUD_SOURCE_REPOSITORY}/training-pipeline'\n",
    "\n",
    "substitutions:\n",
    "    _CLOUD_SOURCE_REPOSITORY: 'poc-mlops-asset'\n",
    "    _CLOUD_SOURCE_REPOSITORY_URI: 'workspace/${_CLOUD_SOURCE_REPOSITORY}'\n",
    "    _ARTIFACT_REGISTRY_REPO_LOCATION: 'us-central1'\n",
    "    _ARTIFACT_REGISTRY_REPO_NAME: 'poc-mlops-asset'\n",
    "    _TRAINER_IMAGE_NAME: 'time-series-trainer'\n",
    "    _TRAINER_IMAGE_TAG: 'latest'\n",
    "    _DOCKERFILE_NAME: 'trainer.Dockerfile'                          \n",
    "\n",
    "options:\n",
    "    dynamicSubstitutions: true\n",
    "    logging: CLOUD_LOGGING_ONLY\n",
    "\n",
    "tags: ['training-pipeline']\n",
    "\n",
    "# This automatically pushes the built image to Artifact Registry\n",
    "images: ['${_ARTIFACT_REGISTRY_REPO_LOCATION}-docker.pkg.dev/${PROJECT_ID}/${_ARTIFACT_REGISTRY_REPO_NAME}/${_TRAINER_IMAGE_NAME}:${_TRAINER_IMAGE_TAG}']\n",
    "```\n",
    "\n",
    "**2. Dashboard UI continuous deployment workflow**\n",
    "\n",
    "Triggered by a pushed commit that involves changes in **customized Grafana instance Dockerfile**, **predefined dashboard and datasources configuration**, or **provisioned dashboards**\n",
    "- (1) builds an updated version of the Dashboard UI Docker image, \n",
    "- (2) pushes it to our Artifact Registry\n",
    "- (3) seamlessly deploys a new Cloud Run revision based on this updated version.\n",
    "\n",
    "\n",
    "**3. (Training / Inference) YAML pipeline templates workflow**\n",
    "\n",
    "Triggered by a pushed commit that includes a new compiled version of a pipeline template in the pipeline templates directories\n",
    "\n",
    "- (1) extracts the pipeline version using regex from the filename\n",
    "- (2) tags the template file with the version\n",
    "- (3) pushes it to our associated Kubeflow Pipelines Artifact Registry.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment tracking\n",
    "\n",
    "**Experiment tracking** giúp lưu trữ và so sánh các lần chạy pipeline, giúp khám phá hiệu suất của các mô hình với các tham số khác nhau. **Vertex AI Experiments** được sử dụng để theo dõi các thông số và kết quả của các lần chạy huấn luyện để phân tích hiệu suất.\n",
    "\n",
    "<img src= \"_image\\tracking.webp\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## task.py snippet from Trainer source code\n",
    "aiplatform.init(project=PROJECT_ID, experiment=EXPERIMENT_NAME)\n",
    "    with aiplatform.start_run(PIPELINE_RUN_NAME):\n",
    "        # Log training params\n",
    "        aiplatform.log_params(xgb_params)\n",
    "        # ...\n",
    "        # Log training performance (TensorBoard)\n",
    "        for i, rmse in enumerate(val_error):\n",
    "            aiplatform.log_time_series_metrics({'rmse': rmse}, step=i)\n",
    "        # ...\n",
    "        # Log training metrics\n",
    "        aiplatform.log_metrics({\"mse_train\": mse_train,\n",
    "                                \"mse_test\": mse_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Registry\n",
    "\n",
    "Easier **model management** and **versioning**, **acts as a repository** for ML models, and it represents the connection between our training (which registers the model) and inference (which retrieves the model) pipelines.\n",
    "\n",
    "Vertex AI Model Registry được sử dụng để lưu trữ các mô hình dự báo, và các artifacts của mô hình được lưu trong Google Cloud Storage (GCS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Pipeline components should be designed so that they can be tested using **unit tests**. Hệ thống sử dụng **pytest** để kiểm tra các thành phần pipeline ML, đôi khi cần mô phỏng (mock) dữ liệu đầu vào và đầu ra khi kiểm thử."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Metadata and Logging\n",
    "\n",
    "Việc quản lý vòng đời của metadata từ các quy trình ML rất quan trọng để hỗ trợ gỡ lỗi khi có vấn đề. Dịch vụ **Vertex AI Metadata** và **Google Cloud Storage (GCS)**, **Logs Explorer** được dùng để lưu trữ các logs và metadata của các pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous monitoring\n",
    "\n",
    "Build hệ thống monitoring\n",
    "\n",
    "Tracking:\n",
    "- data value and concept drift\n",
    "- label drift\n",
    "- model performance\n",
    "\n",
    "<img src= \"_image\\monitoring.webp\">\n",
    "\n",
    "tham khảo platform: https://www.evidentlyai.com/pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versioning and reproducibility\n",
    "\n",
    "- **Versioning** không chỉ áp dụng cho **source code** mà còn cho cả các **pipeline**, **docker image**, **model** và **train data**. Việc này giúp quản lý toàn bộ chu kỳ phát triển ML và hỗ trợ quá trình gỡ lỗi khi có sự cố.\n",
    "Các pipeline và mô hình được lưu trữ và phiên bản hóa trong Artifact Registry, trong khi Vertex AI Datasets được sử dụng để phiên bản hóa các tập dữ liệu huấn luyện.\n",
    "\n",
    "In GCP:\n",
    "- **Pipeline templates** (both training and inference) and **trainer Docker images** are versioned and stored using a **Kubeflow Pipelines repository** and a **Docker repository** in **Artifact Registry**. \n",
    "- **ML models** versioning in **Vertex AI Model Registry**. \n",
    "- **Vertex AI Datasets** is in charge of versioning **training datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use-case\n",
    "\n",
    "Detailed overview of our newly designed MLOps forecasting system, which covers the entire data science lifecycle (DSLC), from data collection and training a model to enabling batch inference and monitoring model performance over time.\n",
    "\n",
    "<img src=\"_image\\ml_wf.gif\">\n",
    "\n",
    "---\n",
    "\n",
    "**Used GCP services**\n",
    "\n",
    "<div style=\"display: flex; align-items: center;\">\n",
    "\n",
    "<div style=\"flex: 1;\">\n",
    "  \n",
    "- `BigQuery`: for time-series data storage, predictions storage and training/inference processed datasets storage\n",
    "- `Vertex AI`: Vertex AI Pipelines (training and inference pipelines), Vertex AI Experiments (comparing training runs), Vertex AI Model Registry (versioning and storing forecasting models), Vertex AI Datasets (versioning and storing datasets), Vertex AI Metadata (pipelines metadata)\n",
    "- `Artifact Registry`: registry and versioning of Docker images (Trainer and Cloud Run Dashboard UI) and Kubeflow Pipelines templates (training/inference)\n",
    "- `Google Cloud Storage`: for pipeline artifacts storage, model artifacts storage, exploratory data analysis reports storage\n",
    "- `Cloud Scheduler`: scheduled data collection and functions with specific purpose (e.g., generating daily monitoring reports)\n",
    "- `Cloud Build`: CI/CD pipelines and other workflows\n",
    "- `Cloud Run Functions`: for hosting our visualization dashboard (based on Grafana)\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"flex: 1; text-align: right;\">\n",
    "  \n",
    "  <img src=\"_image\\gcp_service.webp\" alt=\"Description\"/>\n",
    "  \n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Monorepo-based strategy**\n",
    "\n",
    "All built modules are hosted in a single source code repository. This has allowed us to collaborate smoothly, manage the entire project modules in a centralized way and share codebases easier\n",
    "\n",
    "Several support tools:\n",
    "- [DevContainers](https://code.visualstudio.com/docs/devcontainers/containers) for module development environments management\n",
    "- [Poetry](https://python-poetry.org/) for dependency management (and packaging)\n",
    "- [Cloud Build](https://cloud.google.com/build?hl=en) for tasks automation as CI/CD pipelines\n",
    "- [just](https://just.systems/) for quick, useful shortcuts while developing and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
