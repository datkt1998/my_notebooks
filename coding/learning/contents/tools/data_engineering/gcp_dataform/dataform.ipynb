{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataform Overview\n",
    "\n",
    "**Dataform** is a serverless service for data analysts to develop and deploy tables, incremental tables, or views to BigQuery. Dataform offers a web environment for SQL workflow development, connection with GitHub, GitLab, Azure DevOps Services, and Bitbucket, continuous integration, continuous deployment, and workflow execution.\n",
    "\n",
    "**Dataform** lets you manage data transformation in the Extraction, Loading, and Transformation (ELT) process for data integration. After raw data is extracted from source systems and loaded into BigQuery, Dataform helps you to transform it into a well-defined, tested, and documented suite of data tables.\n",
    "\n",
    "**Main features**:\n",
    "- Develop and execute SQL workflows for data transformation.\n",
    "- Collaborate with team members on SQL workflow development through Git.\n",
    "- Manage a large number of tables and their dependencies.\n",
    "- Declare source data and manage table dependencies.\n",
    "- View a visualization of the dependency tree of your SQL workflow.\n",
    "- Manage data with SQL code in a central repository.\n",
    "- Reuse code with JavaScript.\n",
    "- Test data correctness with quality tests on source and output tables.\n",
    "- Version control SQL code.\n",
    "- Document data tables inside SQL code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repository Project**\n",
    "\n",
    "**1. Types of files:** (should be put in folder with same name)\n",
    "\n",
    "- **Config files** (`JSON` or `SQLX` files): let you configure your SQL workflows. They contain general configuration, execution schedules, or schema for creating new tables and views.\n",
    "- **Definitions**: are `SQLX` and `JavaScript` files that define new tables, views, and additional SQL operations to run in BigQuery.\n",
    "- **Includes**: are JavaScript files where you can define variables and functions to use in your project.\n",
    "\n",
    "**2. Workflow development and version control**\n",
    "\n",
    "In Dataform, the **workflow development** is the same local development, then you can pull changes from the repository, commit all or selected changes, and push them to Git branches of the repository.\n",
    "\n",
    "In Workflow development, you can:\n",
    "\n",
    "- Develop the following SQL workflow actions\n",
    "  - Source data declarations\n",
    "  - Tables and views\n",
    "  - Incremental tables\n",
    "  - Table partitions and clusters\n",
    "  - Dependencies between actions\n",
    "  - Documentation of tables\n",
    "  - Custom SQL operations\n",
    "  - BigQuery labels\n",
    "  - BigQuery policy tags\n",
    "  - Dataform tags\n",
    "  - Data quality tests, called assertions\n",
    "- Use JavaScript to reuse your Dataform SQL workflow code.\n",
    "  - Across a file with code encapsulation\n",
    "  - Across a repository with includes\n",
    "  - Across repositories with packages\n",
    "\n",
    "**3. Workflow compilation**\n",
    "\n",
    "**4. Workflow execution**\n",
    "\n",
    "- You can schedule Dataform executions in BigQuery in the following ways:\n",
    "  - Create workflow configurations to schedule executions of compilation results created in release configurations\n",
    "  - Schedule executions with Cloud Composer\n",
    "  - Schedule executions with Workflows and Cloud Scheduler\n",
    "\n",
    "- To debug errors, you can monitor executions in the following ways:\n",
    "  - View detailed Dataform execution logs\n",
    "  - View audit logs for Dataform\n",
    "  - View Cloud Logging logs for Dataform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terms\n",
    "\n",
    "1. **Release configuration**: let you configure how Dataform should compile the code of your repository. If your repository is connected to a remote git repository, you can create release configurations from different branches. Dataform will pull code from your remote git repository before compiling it\n",
    "2. **Workflow configurations**: let you schedule workflow executions\n",
    "3. **Development Workspace**: Is the same local development branch (git) in google cloud web workspace\n",
    "4. **Dataform core package**: Is the same python version when develop python programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Administer & Control Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Repository\n",
    "\n",
    "https://cloud.google.com/dataform/docs/create-repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to GIT repository\n",
    "\n",
    "https://cloud.google.com/dataform/docs/connect-repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config Dataform Settings \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `workflow_settings.yaml`\n",
    "Repository Workflow setting `workflow_settings.yaml` stores Dataform workflow settings in the `YAML` format.\n",
    "\n",
    "```yaml\n",
    "defaultProject: my-gcp-project-id             # BigQuery Google Cloud project ID\n",
    "defaultDataset: dataform                      # BigQuery dataset in which Dataform creates assets\n",
    "defaultLocation: asia-southeast1              # default BigQuery dataset region\n",
    "defaultAssertionDataset: dataform_assertions  # BigQuery dataset in which Dataform creates views with assertion results\n",
    "vars:\n",
    "  executionSetting: dev\n",
    "  environmentName: development\n",
    "```\n",
    "\n",
    "See all [configs reference for workflow settings](https://dataform-co.github.io/dataform/docs/configs-reference#workflowsettings)\n",
    "\n",
    "**Access the properties in Dataform code**\n",
    "from `workflow_settings.yaml` options to the code accessible `dataform.projectConfig` options apply:\n",
    "- `defaultProject` => `defaultDatabase`.\n",
    "- `defaultDataset` => `defaultSchema`.\n",
    "- `defaultAssertionDataset` => `assertionSchema`.\n",
    "- `projectSuffix` => `databaseSuffix`.\n",
    "- `datasetSuffix` => `schemaSuffix`.\n",
    "- `namePrefix` => `tablePrefix`.\n",
    "\n",
    "use clause:\n",
    "```SQL\n",
    "${when(dataform.projectConfig.vars.\"YOUR_VARIABLE\" === \"SET_VALUE\", \"CONDITION\", \"ELSE\")}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "  config { type: \"view\" }\n",
    "  SELECT ${when(\n",
    "    !dataform.projectConfig.tablePrefix,\n",
    "    \"table prefix is set!\",\n",
    "    \"table prefix is not set!\"\n",
    "  )}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "  select\n",
    "    *\n",
    "  from ${ref(\"data\")}\n",
    "  ${when(\n",
    "    dataform.projectConfig.vars.executionSetting === \"staging\",\n",
    "    \"where mod(farm_fingerprint(id) / 10) = 0\",\n",
    "  )}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage Core Packages\n",
    "\n",
    "- If **Only Dataform core package + No addition packages**: put `Dataform core package` in the `workflow_settings.yaml`\n",
    "\n",
    "```yaml\n",
    "dataformCoreVersion: \"3.0.0\"        # As a best practice, always use the latest available version of the Dataform core framework                \n",
    "defaultProject: my-gcp-project-id   # BigQuery Google Cloud project ID\n",
    "defaultDataset: dataform            # BigQuery dataset in which Dataform creates assets\n",
    "```\n",
    "- If  **Dataform core package + Addition packages**: put `Dataform core package` + `addition packages` in the `package.json`\n",
    "\n",
    " ```json\n",
    " {\n",
    "   \"name\": \"repository-name\",\n",
    "   \"dependencies\": {\n",
    "     \"@dataform/core\": \"3.0.0\",\n",
    "     \"dataform-scd\": \"https://github.com/dataform-co/dataform-scd/archive/0.3.tar.gz\"\n",
    "   }\n",
    " }\n",
    " ```\n",
    "   > remove `dataformCoreVersion` in `workflow_settings.yaml`\n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control Access\n",
    "\n",
    "https://cloud.google.com/dataform/docs/required-access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datafrom Core (SQLX)\n",
    "\n",
    "Dataform core for the following purposes:\n",
    "- Defining tables, views, materialized views, or incremental tables.\n",
    "- Defining data transformation logic.\n",
    "- Declaring source data and managing table dependencies.\n",
    "- Documenting table and column descriptions inside code.\n",
    "- Reusing functions and variables across different queries.\n",
    "- Writing data assertions to ensure data consistency.\n",
    "\n",
    ">You can compile and run Dataform core locally through the Dataform CLI outside of Google Cloud.\n",
    "\n",
    "A SQLX file consists of a **config block** and a **body**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config block\n",
    "\n",
    "In the config block, you can perform the following actions:\n",
    "- **Specify query metadata**: configure how Dataform materializes queries into BigQuery, for example the output table type, the target database, or labels using the config metadata.\n",
    "- **Document data**: document your tables and their fields directly\n",
    "- **Define data quality tests** (called `assertions`): check for uniqueness, null values, or a custom condition that run after table creation (also define assertions outside the config block, in a separate SQLX file.)\n",
    "> All config properties, and the config block itself, are optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config {\n",
    "  type: \"table\",\n",
    "    description: \"This table joins orders information from OnlineStore & payment information from PaymentApp\",\n",
    "  columns: {\n",
    "    order_date: \"The date when a customer placed their order\",\n",
    "    id: \"Order ID as defined by OnlineStore\",\n",
    "    order_status: \"The status of an order e.g. sent, delivered\",\n",
    "    customer_id: \"Unique customer ID\",\n",
    "    payment_status: \"The status of a payment e.g. pending, paid\",\n",
    "    payment_method: \"How the customer chose to pay\",\n",
    "    item_count: \"The number of items the customer ordered\",\n",
    "    amount: \"The amount the customer paid\"\n",
    "  },\n",
    "    assertions: {\n",
    "    uniqueKey: [\"id\"]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLX body\n",
    "\n",
    "following actions:\n",
    "- **Define a table and its dependencies**: use SQL `SELECT` statements and the `ref` function\n",
    "\n",
    "`ref` function use to **build a dependency tree of all the tables** to be created or updated, lets you **reference tables defined in project instead of hard coding** the schema and table name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config { type: \"table\" }\n",
    "\n",
    "SELECT\n",
    "  order_date AS date,\n",
    "  order_id AS order_id,\n",
    "  order_status AS order_status,\n",
    "  SUM(item_count) AS item_count,\n",
    "  SUM(amount) AS revenue\n",
    "\n",
    "FROM ${ref(\"store_clean\")}\n",
    "\n",
    "GROUP BY 1, 2, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After compilation, the SQL code is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE\n",
    "OR REPLACE TABLE Dataform.orders AS\n",
    "SELECT\n",
    "    order_date AS date,\n",
    "    order_id AS order_id,\n",
    "    order_status AS order_status,\n",
    "    SUM(item_count) AS item_count,\n",
    "    SUM(amount) AS revenue\n",
    "FROM\n",
    "    Dataform_stg.store_clean\n",
    "GROUP BY\n",
    "    1,\n",
    "    2,\n",
    "    3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Define additional SQL operations to run in BigQuery**: configure Dataform to execute one or more SQL statements before or after creating a table or view, you can [specify pre-query and post-query operations](https://cloud.google.com/dataform/docs/custom-sql).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM ...\n",
    "\n",
    "post_operations {\n",
    "  GRANT `roles/bigquery.dataViewer` ON TABLE ${self()} TO \"group:someusers@dataform.co\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Generate SQL code with JavaScript Block**: define reusable functions to generate repetitive parts of SQL code\n",
    "\n",
    "Note: Reuse code defined in a **JavaScript block only inside the SLQX file where the block is defined**. For global, to reuse code across your entire repository, you can create **includes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "js {\n",
    "  const columnName = \"foo\";\n",
    "}\n",
    "\n",
    "SELECT 1 AS ${columnName} FROM \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept of workspace\n",
    "\n",
    "**Compiled graph**\n",
    "\n",
    "Filter the graph by the following properties:\n",
    "- Name\n",
    "- Tag\n",
    "- Type\n",
    "    - Assertion\n",
    "    - Declaration\n",
    "    - Incremental Table\n",
    "    - Materialized view\n",
    "    - Operations\n",
    "    - Table\n",
    "    - Unknown\n",
    "    - View\n",
    "You can select multiple filters at once. Dataform will apply them with the `OR` condition.\n",
    "\n",
    "**Repository Structure**\n",
    "\n",
    "- `definitions/`: a directory for asset definitions, in Dataform core or JavaScript.\n",
    "- `includes/`: an empty directory for scripts and variables that you can reuse across the repository.\n",
    "- `workflow_settings.yaml`(`dataform.json` for early version 3.0.0): the default Dataform configuration file containing the Google Cloud project ID and BigQuery schema to publish assets in. You can override the default settings to customize them to your needs, but it's not a requirement to begin using Dataform.\n",
    "- `package.json`: the default Dataform dependencies configuration file with the latest version of @dataform/core. You can use this file to import packages.\n",
    "- `definitions/sample.sqlx`: a sample SQLX file to help you get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataform Tables\n",
    "\n",
    "https://cloud.google.com/dataform/docs/tables\n",
    "\n",
    "**1. type of table**\n",
    "- `table`: a regular table.\n",
    "- `incremental`: an incremental table  must include a `where` clause (updated table by insert new records by date)\n",
    "- `view`: a table view\n",
    "    - `materialized`: store underlying data under view (combine `table` and `view` --> increase performance and cost, but need to refresh continuously)\n",
    "\n",
    "> Other value of `type`: `operations`, `declaration`, `assertion`,...\n",
    "\n",
    "**2. [Partitions and clusters](https://cloud.google.com/dataform/docs/partitions-clusters)**\n",
    "\n",
    "**3. [Table/Field description](https://cloud.google.com/dataform/docs/document-tables)**\n",
    "\n",
    "**4. [Assertions](https://cloud.google.com/dataform/docs/assertions)**\n",
    "- Test and validate output table. Dataform runs assertions every time it updates your SQL workflow and alerts you if any assertions fail.\n",
    "\n",
    "**5. [Config additional table settings](https://cloud.google.com/dataform/docs/table-settings)**\n",
    "- Override default table settings, such as database or schema, and disable table creation, or execute a SQL statement before or after table creation\n",
    "\n",
    "**6. [Table labels](https://cloud.google.com/dataform/docs/labels)**\n",
    "\n",
    "**7. [Setting column-level access control](https://cloud.google.com/bigquery/docs/column-level-security-intro)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create table\n",
    "\n",
    "**1. `ref`** function: reference and automatically depend on the following objects defined in your Dataform SQL workflow instead of hard coding the schema and table names\n",
    "\n",
    "- ${ref(\"database\", \"schema\", \"name\")} : project_id.schema.name\n",
    "- ${ref(\"schema\", \"name\")} : default_project_id.schema.name\n",
    "- ${ref(\"name\")}: default_project_id.default_schema.name\n",
    "\n",
    "**2. `resolve`** : similar `ref` but not set the table as a dependency to this action \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config { \n",
    "    type: \"table\",\n",
    "    bigquery: {\n",
    "        partitionBy: \"DATETIME_TRUNC(order_date, DAY)\",\n",
    "        requirePartitionFilter : true,\n",
    "        partitionExpirationDays: 14,\n",
    "        clusterBy: [\"order_id\"]\n",
    "    },\n",
    "    dependencies: [ \"store_clean\", \"some_other_table\" ] \n",
    "}\n",
    "\n",
    "SELECT\n",
    "  order_date AS order_date,\n",
    "  order_id AS order_id,\n",
    "  order_status AS order_status,\n",
    "  SUM(item_count) AS item_count,\n",
    "  SUM(amount) AS revenue\n",
    "\n",
    "FROM ${ref(\"store_clean\")}\n",
    "\n",
    "GROUP BY 1, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incremental table\n",
    "\n",
    "**Incremental table** is the table that was updated/inserted new rows instead rebuild table from the scratch each operation time:\n",
    "- Builds the incremental table from scratch only for the first time. \n",
    "- During subsequent executions, Dataform only inserts or merges new rows into the incremental table according to the conditions that you configure.\n",
    "> Dataform inserts new rows only into columns that already exist in the incremental table. If you make changes to the incremental table definition query — for example, add a new column — you must rebuild the table from scratch. To do so, the next time you trigger an execution of the table, select the Run with full refresh option.\n",
    "\n",
    "**Use case of Incremetal table**\n",
    "- Performance optimization: want to only process new records instead of reprocessing the entire table (web logs or analytics data,...) \n",
    "- Latency reduction: execute workflows quickly but frequently, reducing the downstream latency of the output tables.\n",
    "- Daily snapshots: create daily snapshots of the table data, for example, for longitudinal analysis of user settings stored in a production database.\n",
    "\n",
    "**`WHERE` clause** \n",
    "specify an incremental condition and a non-incremental condition. Dataform applies \n",
    "- **incremental condition** during table execution **without a full refresh**\n",
    "- **non-incremental condition** during execution with a **full refresh**.\n",
    "\n",
    "```bash\n",
    "config { type: \"incremental\" }\n",
    "\n",
    "<SELECT_STATEMENT>  # the SELECT statement that defines your table\n",
    "\n",
    "${when(\n",
    "    incremental(), \n",
    "    `WHERE <INCREMENTAL_CONDITION>`,    # select rows for Dataform to process during table execution without a full refresh\n",
    "    `WHERE <NON_INCREMENTAL_CONDITION>` # select rows for Dataform to process during table execution with a full refresh\n",
    "    ) }\n",
    "```\n",
    "`\n",
    "\n",
    "When you select the `full refresh option` in execution, Dataform ignores the `${when(incremental(), ... }` if not set `protected = True` in the config block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config { type: \"incremental\" }\n",
    "\n",
    "-- Fetches the columns timestamp and message from the source table logs located in the database/schema productiondb.\n",
    "SELECT timestamp, message FROM ${ref(\"productiondb\", \"logs\")}\n",
    "\n",
    "${when(incremental(),\n",
    "    -- Incremental Mode: appends only rows with a date > the maximum date refers to the current table + country = \"UK\".\n",
    "   `WHERE date > (SELECT MAX(date) FROM ${self()}) AND country = \"UK\"`,\n",
    "   \n",
    "    -- Full Refresh Mode: table is rebuilt from scratch, appends all rows with country = \"UK\".\n",
    "   `WHERE country = \"UK\"`)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Merge rows in an incremental table](https://cloud.google.com/dataform/docs/incremental-tables#merge_rows_in_an_incremental_table)**\n",
    "\n",
    "When updating the table, Dataform merges rows with `uniqueKey` instead of appending them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config {\n",
    "  type: \"incremental\",\n",
    "  uniqueKey: [\"transaction_id\"]\n",
    "}\n",
    "\n",
    "SELECT timestamp, action FROM weblogs.user_actions\n",
    "${ when(incremental(), `WHERE timestamp > (SELECT MAX(timestamp) FROM ${self()})`) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Filter rows in an incremental table](https://cloud.google.com/dataform/docs/incremental-tables#filter_rows_in_an_incremental_table)**\n",
    "\n",
    "To avoid Dataform scanning the whole table to find matching rows, set `updatePartitionFilter` to only consider a **subset of records**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config {\n",
    "  type: \"incremental\",\n",
    "  uniqueKey: [\"transaction_id\"],\n",
    "  bigquery: {\n",
    "    partitionBy: \"DATE(timestamp)\",\n",
    "    updatePartitionFilter:  -- filter to update only the last 24 hours\n",
    "        \"timestamp >= timestamp_sub(current_timestamp(), interval 24 hour)\"\n",
    "  }\n",
    "}\n",
    "\n",
    "SELECT timestamp, action FROM weblogs.user_actions\n",
    "${ when(incremental(), `WHERE timestamp > (SELECT MAX(timestamp) FROM ${self()})`) }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Avoid full table scans](https://cloud.google.com/dataform/docs/incremental-tables#avoid_full_table_scans_when_ingesting_from_a_partitioned_table)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config {\n",
    "  type: \"incremental\",\n",
    "}\n",
    "\n",
    "pre_operations {\n",
    "  DECLARE event_timestamp_checkpoint DEFAULT (\n",
    "    ${when(incremental(),\n",
    "    `SELECT max(event_timestamp) FROM ${self()}`,\n",
    "    `SELECT timestamp(\"2000-01-01\")`)}\n",
    "  )\n",
    "}\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ${ref(\"raw_events\")}\n",
    "WHERE event_timestamp > event_timestamp_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Protect an incremental table from full refresh**\n",
    "\n",
    "In the config block, enter `protected: true`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config {\n",
    "  type: \"incremental\",\n",
    "  protected: true\n",
    "}\n",
    "SELECT ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config {\n",
    "  type: \"table\",\n",
    "  description: \"Description of the table.\",\n",
    "  columns: {\n",
    "    column1_name: \"Description of the first column\",\n",
    "    column2_name: \"Description of the second column\",\n",
    "    column3_name: \"Description of the third column\",\n",
    "    record_name: {\n",
    "      description: \"Description of the record.\",\n",
    "      columns: {\n",
    "       record_column1_name: \"Description of the first record column\",\n",
    "       record_column2_name: \"Description of the second record column\",\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "SELECT\n",
    "  \"first_column_value\" AS column_1_name,\n",
    "  \"second_column_value\" AS column_2_name,\n",
    "  \"third_column_value\" AS column_3_name,\n",
    "  STRUCT(\"first\" AS record_column1_name,\n",
    "    \"second\" AS record_column2_name) AS record_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reuse column documentation in Dataform with **includes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "--// filename is includes/docs.js\n",
    "\n",
    "const user_id = `A unique identifier for a user`;\n",
    "const age = `The age of a user`;\n",
    "const creation_date = `The date this user signed up`;\n",
    "const user_tenure = `The number of years since the user's creation date`;\n",
    "const badge_count = `The all-time number of badges the user has received`;\n",
    "const questions_and_answer_count = `The all-time number of questions and answers the user has created`;\n",
    "const question_count = `The all-time number of questions the user has created`;\n",
    "const answer_count = `The all-time number of answers the user has created`;\n",
    "const last_badge_received_at = `The time the user received their most recent badge`;\n",
    "const last_posted_at = `The time the user last posted a question or answer`;\n",
    "const last_question_posted_at = `The time the user last posted an answer`;\n",
    "const last_answer_posted_at = `The time the user last posted a question`;\n",
    "\n",
    "module.exports = {\n",
    "   user_id,\n",
    "   age,\n",
    "   creation_date,\n",
    "   user_tenure,\n",
    "   badge_count,\n",
    "   questions_and_answer_count,\n",
    "   question_count,\n",
    "   answer_count,\n",
    "   last_badge_received_at,\n",
    "   last_posted_at,\n",
    "   last_question_posted_at,\n",
    "   last_answer_posted_at,\n",
    "};\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config {\n",
    "  type: \"table\",\n",
    "  description: \"Table description.\",\n",
    "  columns: {\n",
    "    user_id: docs.user_id,\n",
    "    column2_name: \"Description of the second column\",\n",
    "    column3_name: \"Description of the third column\",\n",
    "    age: docs.age,\n",
    "  }\n",
    "}\n",
    "\n",
    "SELECT ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define whole table document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "// filename is includes/docs.js\n",
    "\n",
    "const columns = {\n",
    "    user_id = `A unique identifier for a user`,\n",
    "    age = `The age of a user`,\n",
    "    creation_date = `The date this user signed up`,\n",
    "    user_tenure = `The number of years since the user's creation date`,\n",
    "    badge_count = `The all-time number of badges the user has received`,\n",
    "    questions_and_answer_count = `The all-time number of questions and answers the user has created`,\n",
    "    question_count = `The all-time number of questions the user has created`,\n",
    "    answer_count = `The all-time number of answers the user has created`,\n",
    "    last_badge_received_at = `The time the user received their most recent badge`,\n",
    "    last_posted_at = `The time the user last posted a question or answer`,\n",
    "    last_question_posted_at = `The time the user last posted an answer`,\n",
    "    last_answer_posted_at = `The time the user last posted a question`,\n",
    "}\n",
    "\n",
    "\n",
    "module.exports = {\n",
    "  columns\n",
    "};\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config { type: \"table\",\n",
    "description: \"My table description\",\n",
    "columns: docs.columns\n",
    "}\n",
    "\n",
    "SELECT 1 AS one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Override the schema, database, and name of a selected table**\n",
    "\n",
    "By default, a table follows the schema and database configuration you set in `dataform.json`/`workflow_settings.yaml`. The name of a table is the same as the name of the table definition SQLX file.\n",
    "\n",
    "To override the schema and name of a selected table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    " -- config block\n",
    " {\n",
    "   schema: \"OVERRIDDEN_SCHEMA\",\n",
    "   database: \"OVERRIDDEN_DATABASE\",\n",
    "   name: \"OVERRIDDEN_NAME\"\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a SQL statement to be executed before table creation**\n",
    "\n",
    "Use `pre_operations` block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "  pre_operations {\n",
    "    CREATE TEMP FUNCTION AddFourAndDivide(x INT64, y INT64)\n",
    "      RETURNS FLOAT64\n",
    "      AS ((x + 4) / y);\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a SQL statement to be executed after table creation**\n",
    "\n",
    "Use `post_operations` block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "    post_operations {\n",
    "      GRANT `roles/bigquery.dataViewer`\n",
    "      ON\n",
    "      TABLE ${self()}\n",
    "      TO \"group:allusers@example.com\", \"user:otheruser@example.com\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disable table creation**\n",
    "- keeps a disabled table in the dependency graph\n",
    "- but does not compile and create it\n",
    "\n",
    "for example: if a table fails and you don't want your whole workflow to fail while you fix the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "  config {\n",
    "    type: \"table\",\n",
    "    disabled: true\n",
    "  }\n",
    "\n",
    "  select * from ${ref(\"source_data\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies\n",
    "- use `ref`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "// filename is incremental_table.sqlx\n",
    "\n",
    "config { type: \"incremental\" }\n",
    "\n",
    "SELECT * FROM ${ref(\"source_data\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use config block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config { dependencies: [ \"some_table\", \"some_assertion\" ] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config {\n",
    "  type: \"view\",\n",
    "  name: \"user_counts\",\n",
    "  tags: [\"daily\", \"hourly\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table labels\n",
    "\n",
    "https://cloud.google.com/dataform/docs/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config {\n",
    "  type: \"table\",\n",
    "  bigquery: {\n",
    "    partitionBy: \"DATE(ts)\",\n",
    "    labels: {\n",
    "      department: \"shipping\",\n",
    "      \"cost-center\": \"logistics\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "SELECT CURRENT_TIMESTAMP() AS ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Workflow, Variables & Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable & Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "js {\n",
    " const foo = 1;\n",
    " function bar(number){\n",
    "     return number+1;\n",
    " }\n",
    "}\n",
    "\n",
    "select\n",
    " ${foo} as one,\n",
    " ${bar(foo)} as two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Re-use across a single SQLX file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- // filename is includes/customize.js\n",
    "const launch_date = \"11.11.2011\";\n",
    "const PROJECT_ID = \"my_project_name\";\n",
    "\n",
    "function renderScript(table, dimensions, metrics) {\n",
    "return `\n",
    "    select\n",
    "    ${dimensions.map(field => `${field} as ${field}`).join(\",\")},\n",
    "    ${metrics.map(field => `sum(${field}) as ${field}`).join(\",\\n\")}\n",
    "    from ${table}\n",
    "    group by ${dimensions.map((field, i) => `${i + 1}`).join(\", \")}\n",
    "  `;\n",
    "}\n",
    "\n",
    "module.exports = { launch_date, PROJECT_ID , renderScript };"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Use the constants in the SQL file\n",
    "config {type: \"table\"}\n",
    "\n",
    "SELECT * \n",
    "FROM ${customize.PROJECT_ID}.my_schema_name.my_table_name \n",
    "WHERE date > ${customize.launch_date}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Use the renderScript function to generate a SQL query\n",
    "config {\n",
    "  type: \"table\",\n",
    "  tags: [\"advanced\", \"hourly\"],\n",
    "  disabled: true\n",
    "}\n",
    "\n",
    "${customize.renderScript(ref(\"source_table\"),\n",
    "                            [\"country\", \"device_type\"],\n",
    "                            [\"revenue\", \"pageviews\", \"sessions\"]\n",
    "                            )}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reuse across with includes\n",
    "\n",
    "https://cloud.google.com/dataform/docs/reuse-code-includes\n",
    "\n",
    "**Includes** are JavaScript constants or functions global to your repository. You define includes in the includes directory of your repository. You can then reuse them across your repository in **JavaScript** and **SQLX files**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL Operator\n",
    "\n",
    "file `.sqlx` with `config { type: \"operations\" }`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use Case 1: Xóa dữ liệu cũ trong bảng**\n",
    "- **Kịch bản**: Bạn có một bảng lưu trữ các bản ghi giao dịch và muốn xóa tất cả dữ liệu đã quá 2 năm để giảm chi phí lưu trữ.\n",
    "- **Giải pháp**: Dùng tệp `.sqlx` với `type: operations` để thực hiện lệnh SQL `DELETE`.\n",
    "- **Lý do** dùng `type: operations`:\n",
    "    - Việc xóa dữ liệu không phải là quy trình ETL thông thường (như tạo bảng hay view).\n",
    "    - Cần thực hiện trực tiếp thao tác quản lý dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config { type: \"operations\" }\n",
    "\n",
    "DELETE FROM dataset.table WHERE country = 'GB';\n",
    "\n",
    "DELETE FROM dataset.table WHERE country = 'FR';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use Case 2: Tạo bảng tạm (Temporary Table) để sử dụng ở các bước khác**\n",
    "- **Kịch bản**: Bạn muốn chuẩn bị một bảng tổng hợp tạm thời để sử dụng trong nhiều bước khác trong pipeline của Dataform.\n",
    "- **Giải pháp**: Tạo bảng tạm bằng một tệp `.sqlx` và thiết lập `hasOutput: true`.\n",
    "- **Lý do** dùng `type: operations`: Bảng tạm này không cần định nghĩa như một \"target\" chuẩn trong Dataform, nhưng vẫn phải tồn tại để phục vụ các bước khác."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "--file: definitions/your_file_name.sqlx\n",
    "\n",
    "config { type: \"operations\", hasOutput: true }\n",
    "\n",
    "CREATE OR REPLACE TABLE ${self()} AS\n",
    "SELECT customer_id, COUNT(*) AS order_count\n",
    "FROM my_project.my_dataset.orders\n",
    "WHERE order_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 1 YEAR)\n",
    "GROUP BY customer_id;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- In Other File\n",
    "\n",
    "SELECT *\n",
    "FROM ${ref(\"your_file_name\")}\n",
    "WHERE order_count > 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use Case 3: Chạy lệnh DDL (Data Definition Language) để tạo một bảng mới**\n",
    "- **Kịch bản**: Bạn cần tạo bảng mới hoặc chỉnh sửa schema của bảng hiện có, điều không thể thực hiện qua các mô hình chuẩn của Dataform.\n",
    "- **Giải pháp**: Dùng tệp .sqlx để chạy lệnh DDL.\n",
    "- **Lý do**:\n",
    "    - Lệnh DDL không phù hợp để mô hình hóa như bảng hay view trong Dataform.\n",
    "    - Bạn cần tự thiết kế schema hoặc chạy các thao tác thay đổi bảng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config { type: \"operations\" }\n",
    "\n",
    "CREATE OR REPLACE TABLE my_project.my_dataset.new_table (\n",
    "  id INT64,\n",
    "  name STRING,\n",
    "  created_at TIMESTAMP\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use Case 4: Tích hợp kiểm tra dữ liệu tùy chỉnh**\n",
    "- **Kịch bản**: Bạn muốn kiểm tra xem dữ liệu trong một bảng có bất kỳ giá trị NULL nào trong cột bắt buộc không.\n",
    "- **Giải pháp**: Dùng type: operations để viết logic kiểm tra dữ liệu.\n",
    "- **Lý do**: Kiểm tra dữ liệu không tạo output cố định, mà chỉ thực hiện logic kiểm tra và báo lỗi nếu cần."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config { type: \"operations\" }\n",
    "\n",
    "DECLARE null_count INT64;\n",
    "\n",
    "SET null_count = (\n",
    "  SELECT COUNT(*)\n",
    "  FROM my_project.my_dataset.users\n",
    "  WHERE email IS NULL\n",
    ");\n",
    "\n",
    "IF null_count > 0 THEN\n",
    "  RAISE ERROR 'Validation failed: NULL values found in \"email\" column';\n",
    "END IF;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use Case 5: Chạy nhiều lệnh SQL cùng lúc**\n",
    "- **Kịch bản**: Bạn cần chạy một loạt lệnh SQL trong một bước duy nhất, ví dụ: xóa dữ liệu cũ và sau đó cập nhật trạng thái dữ liệu.\n",
    "- **Giải pháp**: Dùng tệp .sqlx để chạy nhiều lệnh.\n",
    "- **Lý do**: Dễ dàng thực hiện nhiều thao tác SQL mà không cần chia thành các bước riêng biệt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config { type: \"operations\" }\n",
    "\n",
    "-- Xóa dữ liệu cũ\n",
    "DELETE FROM my_project.my_dataset.logs\n",
    "WHERE log_date < DATE_SUB(CURRENT_DATE(), INTERVAL 1 YEAR);\n",
    "\n",
    "-- Cập nhật trạng thái\n",
    "UPDATE my_project.my_dataset.logs\n",
    "SET status = 'archived'\n",
    "WHERE log_date < CURRENT_DATE();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "source": [
    "#### Assertion\n",
    "\n",
    "An assertion is a data quality test query that finds rows that violate one or more conditions specified in the query. **If the query returns any rows, the assertion fails**. Dataform runs assertions every time it updates your SQL workflow and it alerts you if any assertions fail.\n",
    "\n",
    "Dataform automatically creates views (in BigQuery assertions schema) that contain the results of compiled assertion queries.\n",
    "\n",
    "Assertions for all Dataform table types: tables, incremental tables, views, and materialized views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Built-in assertions\n",
    "Add built-in assertions to the **config block** of a table. Dataform runs these assertions after table creation\n",
    "\n",
    "This condition asserts that all table rows follow the custom logic you define. The assertion fails if any table row results in `false`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "config {\n",
    "  type: \"table\",\n",
    "  assertions: {\n",
    "    -- assert that the column is not duplicated (single column)\n",
    "    uniqueKey: [\"user_id\"],\n",
    "\n",
    "    -- assert that the columns is not duplicated (multiple columns)\n",
    "    uniqueKeys: [\n",
    "        [\"user_id\"], -- unique \"user_id\" for the table\n",
    "        [\"signup_date\", \"customer_id\"] -- unique \"customer_id\" + \"signup_date\" for the table\n",
    "        ],\n",
    "\n",
    "    -- assert that the columns is not null\n",
    "    nonNull: [\"user_id\", \"customer_id\"],\n",
    "\n",
    "    -- assert that the columns is not duplicated\n",
    "    rowConditions: [\n",
    "      'signup_date is null or signup_date > \"2019-01-01\"',\n",
    "      'email like \"%@%.%\"'\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "SELECT ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manual assertions\n",
    "Add manual assertions in a separate `SQLX` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- definitions/custom_assertion.sqlx\n",
    "\n",
    "config { type: \"assertion\" }\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ${ref(\"sometable\")}\n",
    "WHERE\n",
    "  a IS NULL\n",
    "  OR b IS NULL\n",
    "  OR c IS NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set assertions as dependencies\n",
    "\n",
    "https://cloud.google.com/dataform/docs/assertions#add_assertions_as_dependencies\n",
    "\n",
    "When workflow action **B** depends on workflow action **A** that has assertions, failure of assertions of action **A** does not block Dataform from executing action **B**. To execute action **B** only if assertions of action **A** pass, you need to set assertions of action **A** as dependencies of action **B**.\n",
    "\n",
    "1. [Set selected assertions as dependencies](https://cloud.google.com/dataform/docs/assertions#selected-assertions): manually set selected assertions as dependencies by adding them to `dependencies: [ \"\" ]` in the config block\n",
    "    ```bash\n",
    "    config {\n",
    "      dependencies: [\"assertion_name\"]\n",
    "    }\n",
    "    ```\n",
    "\n",
    "\n",
    "\n",
    "2. [Set assertions of a selected dependency action as dependencies](https://cloud.google.com/dataform/docs/assertions#selected-action-assertions):  set the `includeDependentAssertions` parameter to automatically **set all direct assertions of a selected dependency** workflow action as dependencies of the edited action\n",
    "\n",
    "    ```bash\n",
    "    config {\n",
    "      dependencies: [{ action: \"actionA\", includeDependentAssertions: true }]\n",
    "    }\n",
    "    ```\n",
    "\n",
    "\n",
    "\n",
    "3. [Set assertions of all dependency actions as dependencies](https://cloud.google.com/dataform/docs/assertions#all-dependency-assertions): set the dependOnDependencyAssertions parameter to automatically **set all direct assertions from all dependency actions** of the edited action as additional dependencies of the edited action\n",
    "\n",
    "\n",
    "    ```bash\n",
    "    config {\n",
    "      dependOnDependencyAssertions: true\n",
    "    }\n",
    "    ```\n",
    "\n",
    "\n",
    "\n",
    "Lưu ý rằng khi bạn thiết lập cả `dependOnDependencyAssertions` và `includeDependentAssertions` trong cùng một tệp, tham số `includeDependentAssertions` sẽ được ưu tiên. Điều này có nghĩa là nếu bạn thiết lập `dependOnDependencyAssertions` là `true`, nhưng cũng thiết lập `includeDependentAssertions` là `false` cho một hành động phụ thuộc cụ thể, Dataform sẽ không thêm các assertion của hành động đó vào phụ thuộc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "--Set selected assertions as dependencies\n",
    "config {\n",
    "  type: \"table\",\n",
    "  dependencies: [ \"manual_assertion\",  \"dataform_sometable_assertions_nonNull\" ,  \"dataform_sometable_assertions_rowConditions\"]\n",
    "}\n",
    "\n",
    "SELECT * FROM ${ref(\"referenced_table\")} LEFT JOIN ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Set assertions of a selected dependency action as dependencies\n",
    "config { type: \"ACTION_TYPE\" }\n",
    "\n",
    "SELECT * FROM ${ref({name: \"DEPENDENCY_ACTION_NAME\", includeDependentAssertions: true})}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Set assertions of all dependency actions as dependencies\n",
    "--// filename is sometableE.sqlx\n",
    "\n",
    "config {\n",
    "type: \"table\",\n",
    "dependOnDependencyAssertions: true,\n",
    "dependencies: [ \"sometableA\", \"sometableB\" ]\n",
    "}\n",
    "\n",
    "SELECT * FROM ${ref(\"sometableC\")}\n",
    "SELECT * FROM ${ref(\"sometableD\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workspace compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution & Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schedule Execution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practice\n",
    "\n",
    "\n",
    "#### Development\n",
    "\n",
    "1. Having `npm`, `node.js`, `gcloud` installed\n",
    "2. Install `dataform/cli` and `dataform/core`\n",
    "\n",
    "```bash\n",
    "$ npm i -g @dataform/cli\n",
    "$ npm i -g @dataform/core\n",
    "```\n",
    "\n",
    "3. Install dependencies\n",
    "\n",
    "```bash\n",
    "# inside the project folder:\n",
    "$ dataform install\n",
    "```\n",
    "\n",
    "4. Open source code with `VS Code` (install extension: `Dataform` for syntax highlighting)\n",
    "\n",
    "#### Test and compile code\n",
    "\n",
    "To check your code:\n",
    "\n",
    "```bash\n",
    "$ dataform compile\n",
    "\n",
    "# to view the output of compilation\n",
    "$ dataform compile --json > compile.json\n",
    "\n",
    "# to view the output of compilation with custom variables\n",
    "$ dataform compile --vars={custom_var_name}={customer_var_value} --json > compile.json\n",
    "```\n",
    "\n",
    "To execute your code in your data warehouse\n",
    "\n",
    "```bash\n",
    "# Init credential\n",
    "$ dataform init-creds  # use ADC authen as default\n",
    "```\n",
    "\n",
    "```bash\n",
    "$ dataform run\n",
    "$ dataform run --vars={custom_var_name}={customer_var_value}\n",
    "\n",
    "# to run all tables from the scratch (the incremental tables)\n",
    "$ dataform run --full-refresh\n",
    "\n",
    "# to see the final compiled SQL code without actually executing it\n",
    "$ datafrom run --dry-run\n",
    "```\n",
    "\n",
    "Remember to run `dataform format` before committing your code.\n",
    "\n",
    "**Notes**:\n",
    "\n",
    "- Do not use database credential files, use `gcloud auth login ` instead.\n",
    "- Table documentation should be defined separatedly, in `includes` folder with the naming convention: `docs_{table_name}.js`.\n",
    "- Fields with date/datetime/timestamp should have clear sufix: `{field_name}_date`/`field_name}_datetime`/`field_name}_timestamp`\n",
    "\n",
    "#### How to collaborate in GCP Dataform\n",
    "\n",
    "**In Google Cloud Console**:\n",
    "\n",
    "1. Open Dataform in Google Cloud Console: [Dataform](https://console.cloud.google.com/bigquery/dataform?project=ext-pinetree-dw)\n",
    "2. Click to a repository that you intend to work on, for example: [dw-ods](https://console.cloud.google.com/bigquery/dataform/locations/asia-southeast1/repositories/dw-ods/details/workspaces?project=ext-pinetree-dw), noted that on `dw-ods` the default branch is `master`, you must not commit and push to `master` directly.\n",
    "3. Click the button: `Create Development Workspace` in the screen (this step is equivalent to create a local branch since Development Workspace in Dataform equals to local branch in git)\n",
    "4. Name your new development workspace (this name should be simple yet self-explained)\n",
    "5. Open your new development workspace, commit and push it to github\n",
    "6. Start coding, either directly in Google Cloud Console (Dataform) or in your local machine\n",
    "\n",
    "Otherwise, you can create a branch in your local machine, push to remote git repository then create dataform Developement Workspace (with the same name) later.\n",
    "\n",
    "**Rule**:\n",
    "\n",
    "- During development, you only push to your corresponding development branch, not the default branch. After development completed, create a pull request in github to default branch. Your pull request must be reviewed and approved by another team member\n",
    "- After golive, you have to delete manually your development branch in GCP Dataform to avoid redundant `development workspace` in GCP Dataform project\n",
    "\n",
    "- Get an aggreement on how to manage code lifecycle the right way at:\n",
    "    - [GCP document: Managing code lifecycle](https://cloud.google.com/dataform/docs/managing-code-lifecycle)\n",
    "    - [GCP document: Overview of best practices](https://cloud.google.com/dataform/docs/best-practices)\n",
    "\n",
    "#### Naming conventions\n",
    "\n",
    "##### Objects Action\n",
    "\n",
    "**Object Name Format:**\n",
    "\n",
    "```txt\n",
    "<zone>_<business_domain>_<table_role>_<update_frequency>_<execution_type>_<table_name>\n",
    "```\n",
    "\n",
    "1. **Zone** (`<zone>`): Indicates the stage of the data pipeline.\n",
    "\n",
    "    - `stg` for staging.\n",
    "    - `prep` for preprocessing.\n",
    "    - `ft` for feature engineering.\n",
    "    - `hlp` for helper datasets.\n",
    "    - `vld` for assertions.\n",
    "\n",
    "2. **Business Domain** (`<business_domain>`): Represents the functional or business domain.\n",
    "\n",
    "    - `info`: Account information\n",
    "    - `trm`: Trading management\n",
    "    - `avb`: App event behavior\n",
    "    - `tra`: Trading activity\n",
    "    - `mki`: Market information\n",
    "    - `oth`: Others\n",
    "\n",
    "3. **Table Role** (`<table_role>`)\n",
    "\n",
    "    - `dim`: Contain descriptive, categorical data\n",
    "    - `fact`: Contain measurable, numerical data\n",
    "    - `lkp`: Contain mappings or relationships.\n",
    "    - `agg`: Contain pre-aggregated data for performance optimization.\n",
    "\n",
    "4. **Frequency** (`<update_frequency>`): Indicates the update cadence.\n",
    "\n",
    "    - `daily`\n",
    "    - `weekly`\n",
    "    - `monthly`\n",
    "    - `adhoc`\n",
    "\n",
    "5. **Execution Type** (`<execution_type>`): Specifies how the table is built.\n",
    "\n",
    "   - `lastest` for full data loads.\n",
    "   - `incr` for incremental updates.\n",
    "   - `batch` for batch processing.\n",
    "   - `stream` for streaming pipelines.\n",
    "\n",
    "6. **Table Name** (`<table_name>`): Describes the content or purpose of the table.\n",
    "Use snake_case for readability.\n",
    "\n",
    "    - customer_transactions\n",
    "    - product_recommendations.\n",
    "\n",
    "##### Tags & Labels\n",
    "\n",
    "Dataform objects must have at least one tag for dynamic execution.\n",
    "\n",
    "``` yaml\n",
    "labels:\n",
    "  loading-type: # {frequency}-{type of execution}\n",
    "    frequency:\n",
    "      - daily\n",
    "      - weekly\n",
    "      - monthly\n",
    "      - quarterly\n",
    "      - yearly\n",
    "    type of execution:\n",
    "      - full_load\n",
    "      - incremental_load\n",
    "  domain: \n",
    "    - trading_management\n",
    "    - account_info\n",
    "    - app_event\n",
    "    - market_info\n",
    "    - trading_activity\n",
    "  model:\n",
    "    - product_recommendations\n",
    "  layer:\n",
    "    - staging\n",
    "    - preprocessing\n",
    "    - features\n",
    "\n",
    "```\n",
    "\n",
    "``` yaml\n",
    "tags:\n",
    "  domain: # domain-{domain name}\n",
    "    - domain-account_info\n",
    "    - domain-app_event\n",
    "    - domain-market_info\n",
    "    - domain-trading_activity\n",
    "    - domain-trading_management\n",
    "    - model-product_recommendations\n",
    "  env:\n",
    "    - env-train_dataset\n",
    "    - env-full_dev\n",
    "    - env-full_production\n",
    "    - `env-full_${constants.ENV}`\n",
    "  layer:\n",
    "    - layer-udf\n",
    "    - layer-helper\n",
    "    - layer-staging\n",
    "    - layer-preprocessing\n",
    "    - layer-feature\n",
    "  schedule: # scheduler-{time}\n",
    "  - \"scheduler-after_dwh\"\n",
    "  - \"scheduler-backdate\"\n",
    "  - \"scheduler-initial_setup\"\n",
    "```\n",
    "\n",
    "### References\n",
    "\n",
    "1. [Use the open source dataform/cli](https://cloud.google.com/dataform/docs/use-dataform-cli)\n",
    "2. [How-to: Configure additional table settings in table definition files](https://cloud.google.com/dataform/docs/table-settings)\n",
    "\n",
    "Relates to naming convention, coding style guide:\n",
    "\n",
    "1. [SQL style guide | Gitlab](https://about.gitlab.com/handbook/business-technology/data-team/platform/sql-style-guide/)\n",
    "2. [Best practices guides from dbt project](https://docs.getdbt.com/guides/best-practices)\n",
    "3. [dbt guides | Gitlab](https://about.gitlab.com/handbook/business-technology/data-team/platform/dbt-guide/)\n",
    "4. [dbt style guide | dbt labs](https://github.com/dbt-labs/corp/blob/main/dbt_style_guide.md)\n",
    "\n",
    "### Projects\n",
    "\n",
    "1. Feature Engineering (Pinetree): https://github.com/datkt1998/trading-aiml-feature_engineering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
