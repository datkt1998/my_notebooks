{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b613810-a275-4312-bbfc-d28867a9dc38",
   "metadata": {},
   "source": [
    "# Variable Overview\n",
    "\n",
    "**1. Types of variables**\n",
    "- Numeric\n",
    "    - discrete\n",
    "    - continuous\n",
    "- Categorical\n",
    "    - Ordinal\n",
    "    - Nominal\n",
    "- Datetime\n",
    "    - Date only\n",
    "    - Time only\n",
    "    - Datetime\n",
    "- Mix-type\n",
    "\n",
    "**2. Variable Characteristics**\n",
    "\n",
    "***2.1 Missing values***\n",
    "- Cause\n",
    "    - Forgotten, lost, not stored\n",
    "    - value does not exist\n",
    "    - Unknown/not identified values\n",
    "- Missing data mechanisms\n",
    "    - Missing completely at random (MCAR)\n",
    "    - Missing at random (MAR)\n",
    "    - Missing not at random (MNAR)\n",
    "- Imputation Techniques\n",
    "    - Numerical Variables\n",
    "        - Mean/median imputation\n",
    "        - Arbitrary value imputation\n",
    "        - End of tail imputation\n",
    "    - Categorical Variables\n",
    "        - Frequent category\n",
    "        - Adding new \"missing\" category\n",
    "    - Both\n",
    "        - Complete Case Analysis\n",
    "        - Adding new \"missing\" category\n",
    "        - Random sample imputation\n",
    "\n",
    "***2.2 Cardinality for categorical variables***\n",
    "- High cardinality problem\n",
    "    - Not cover all labels, dominate by a only few labels ( decision tree-based )\n",
    "    - Make noise\n",
    "    - distribution variables of train and test are not the same, tend to not capture in model, or not recognize with new pattern and overfitting\n",
    "    - Difficult to transform in preprocessing\n",
    "\n",
    "***2.3 Rare labels for categorical variables***\n",
    "- Lead to overfitting in tree-base models\n",
    "- maybe add noise, cause of overfitting\n",
    "    - Should create new_label by grouped all rare label\n",
    "    - Or remove rare label if it make noise or be non-representative\n",
    "- rare labels make train and test distribution is not the same (could appear only one of all)\n",
    "\n",
    "***2.4 Outliers***\n",
    "- Identify by Extreme value analysis\n",
    "    - For normal distribution\n",
    "        - outliers = mean +/- 3* std.\n",
    "    - For skewed distribution\n",
    "        - outliers out of upper/lower boundary\n",
    "            - Upper boundary = 75th quantile + (IQR * 1.5)\n",
    "            - Lower boundary = 25th quantile - (IQR * 1.5)\n",
    "        - extreme case\n",
    "            - Upper boundary = 75th quantile + (IQR * 3)\n",
    "            - Lower boundary = 25th quantile - (IQR * 3)\n",
    "\n",
    "***2.5 Linear model assumption***\n",
    "- Assumption\n",
    "    - Linearity: There is a linear relationship between predictors and target\n",
    "    - No perfect multicollinearity: there are no perfect /high linear relationship between 2 or more of the predictors\n",
    "    - Normally distributed errors: The residuals are random and normally distributed with a mean of 0\n",
    "    - Homoscedasticity: at each level of the predictor variables, the variance of the error should be constant\n",
    "- linear models\n",
    "    - Linear regression\n",
    "    - Logistic regression\n",
    "    - Linear discriminant analysis - LDA\n",
    "    - ...\n",
    "- Evaluate model performance\n",
    "    - Check the residuals distribution with zero-mean normal by Q-Q plot, or KS-test\n",
    "    - Check there is a linear relationship between X and Y, X and other X\n",
    "    - Variance inflation factor (VIF) to check multi-collinearity\n",
    "\n",
    "***2.6 Variable magnitude***\n",
    "- What is matters ?\n",
    "    - The regression coefficient bị ảnh hưởng trực tiếp từ scale của variable\n",
    "    - Variables with a larger magnitude dominate those with a smaller magnitude\n",
    "    - Gradient descent, SVM converges fast with scaled variables\n",
    "    - Euclidean distance are sensitive to feature magnitude\n",
    "- ML model\n",
    "    - ML model are affected\n",
    "        - Linear/ Logistic Regression\n",
    "        - Neural Networks\n",
    "        - SVMs\n",
    "        - kNN\n",
    "        - Kmeans\n",
    "        - LDA\n",
    "        - PCA\n",
    "    - Not be affected\n",
    "        - Tree-base model\n",
    "            - Classification tree\n",
    "            - Regression tree\n",
    "            - Random Forests\n",
    "            - Gradient Boosted trees\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30f2f52f-ee89-44a8-b3c7-dbb535248a0a",
   "metadata": {},
   "source": [
    "## Datatypes detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e46f646-6ebf-45dd-a5d1-e80c09fc7e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_datatypes(df, discrete_nunique_max = 10, mixed_detection = []):\n",
    "    # numerical: discrete vs continuous\n",
    "    num = df.select_dtypes(include=[np.number, bool]).columns.tolist()\n",
    "    discrete = [var for var in num if df[var].nunique() <= discrete_nunique_max]\n",
    "    continuous = [var for var in num if var not in discrete]\n",
    "\n",
    "    # categorical\n",
    "    categorical = [var for var in df.columns if var not in (mixed_detection + num)]\n",
    "    res = (discrete, continuous, categorical, mixed_detection)\n",
    "    \n",
    "    for t, n in zip(res, ['discrete', 'continuous', 'categorical', 'mixed']) :\n",
    "        print(f'{len(t)} {n} variables: ', \", \".join(t))\n",
    "    return discrete, continuous, categorical, mixed_detection\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ca9317c-5cfc-4468-85a9-3f78417bc0c1",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a67fd4-f4d8-4425-81d0-0f633a50198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PairGridCorr(X, y = None, corr = 'pearson'):\n",
    "    def corrdot(*args, **kwargs):\n",
    "        corr_r = args[0].corr(args[1], corr)\n",
    "        corr_text = f\"{corr_r:2.2f}\".replace(\"0.\", \".\")\n",
    "        ax = plt.gca()\n",
    "        ax.set_axis_off()\n",
    "        marker_size = abs(corr_r) * 10000\n",
    "        ax.scatter([.5], [.5], marker_size, [corr_r], alpha=0.6, cmap=\"coolwarm\",\n",
    "                   vmin=-1, vmax=1, transform=ax.transAxes)\n",
    "        font_size = abs(corr_r) * 50 + 5\n",
    "        ax.annotate(corr_text, [.5, .5,],  xycoords=\"axes fraction\",\n",
    "                    ha='center', va='center', fontsize=font_size)\n",
    "\n",
    "    def annotate_colname(x, **kws):\n",
    "        ax = plt.gca()\n",
    "        ax.annotate(x.name, xy=(0.5, 0.9), xycoords=ax.transAxes, fontweight='bold')\n",
    "\n",
    "    sns.set(style='white', font_scale=1.3)\n",
    "    # sns.set_theme( style=\"whitegrid\")\n",
    "    g = sns.PairGrid(X, aspect=1.4, diag_sharey=False)\n",
    "    g.map_lower(sns.scatterplot, hue = y )\n",
    "    g.map_diag(sns.histplot,)\n",
    "    g.map_diag(annotate_colname)\n",
    "    g.map_upper(corrdot)\n",
    "    return g"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
