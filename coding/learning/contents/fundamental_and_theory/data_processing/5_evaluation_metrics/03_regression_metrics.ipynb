{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c34487c5-7c60-4994-86cb-ae3e110d5244",
   "metadata": {},
   "source": [
    "# Regression metrics\n",
    "\n",
    "**Chú ý** : Bài toán **logistic** bản chất là 1 bài toán `regression` bới output của model là dự báo xác suất (giá trị `continuous`), kết hợp cùng với `cutpoint` để phân loại nhành kết quả nhị phân `Positive`/`Negetive`. Tuy nhiên `target` của bài toán là nhị phân 0/1 nên kết hợp điều chỉnh `cutpoint` và đánh giá kết hợp theo nhiều metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "0243fd5b-71e3-4806-a90f-a321cc2fde49",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62740d79-1620-4532-b493-8b2faefa44be",
   "metadata": {},
   "source": [
    "## Variance metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ee0b6fb-ccd5-4560-9e70-b9e0d73eed1f",
   "metadata": {},
   "source": [
    "### R square\n",
    "- `R-square` / `adjusted R-square`: tỷ lệ variation được giải thích bởi model, from 0 to 1, dùng trong việc model giải thích tốt được bao nhiêu % trong hồi quy. Trong đó, `adjusted R-square` điều chỉnh lại R2 bằng số lượng biến trong model, vì càng nhiều biến multicorrlinearity dẫn tới overfitting, R2 càng cao, cần phải được điều chỉnh.\n",
    "$$R^2 = 1-\\frac{\\sum_{i=1}^{n}(y_{i}-\\hat{y}_{i})^{2}}{\\sum_{i=1}^{n}(y_{i}-\\bar{y}_{i})^{2}}$$\n",
    "\n",
    "$$R_{adj}^2 = 1-(1-R^2)\\frac{n-1}{n-p-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "4927d003-08eb-4994-8a4a-96eb438c332a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9486081370449679"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_true, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28a86a74-487c-4721-bc06-9fc747f60215",
   "metadata": {},
   "source": [
    "### explained variance score\n",
    "The Explained Variance score is similar to the R^2 score, with the notable difference that it does not account for systematic offsets in the prediction. Most often the R^2 score should be preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "531d2c36-8c21-45f6-8569-d1ba8b97a4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9571734475374732"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "explained_variance_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf3b0e4-109c-4091-8aa4-6d4658253ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26d24c1f-a984-43c9-a0d6-16357990eaa0",
   "metadata": {},
   "source": [
    "## Error metrics\n",
    "\n",
    "Trong bài toán dự báo thì chúng ta muốn sai số giữa giá trị dự báo và giá trị thực tế là nhỏ nhất thường lựa chọn các metrics:\n",
    "\n",
    "* MSE: Trung bình tổng bình phương sai số giữa giá trị dự báo và thực tế.\n",
    "$$\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n} (y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "* RMSE: Khai căn bậc hai của MSE và nó đại diện cho độ lệch giữa giá trị dự báo và thực tế.\n",
    "$$\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n} (y_i-\\hat{y}_i)^2)}$$\n",
    "\n",
    "* MAE: Trung bình trị tuyệt đối của sai số giữa giá trị dự báo và thực tế.\n",
    "$$\\text{MAE} = \\frac{1}{n}\\sum_{i=1}^{n} |y_i-\\hat{y}_i|$$\n",
    "\n",
    "* MAPE: Trung bình của tỷ lệ phần trăm sai số tuyệt đối giữa giá trị dự báo và thực tế.\n",
    "$$\\text{MAPE} = \\frac{1}{n}\\sum_{i=1}^{n} |\\frac{y_i-\\hat{y}_i}{y_i}|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "10a0b802-41d4-4d23-8742-24ef05dcee3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 0.375\n",
      "RMSE 0.6123724356957945\n",
      "MAE 0.5\n",
      "MAPE 0.3273809523809524\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# MSE\n",
    "print('MSE', mean_squared_error(y_true, y_pred, squared=True))\n",
    "\n",
    "# RMSE\n",
    "print('RMSE', mean_squared_error(y_true, y_pred, squared=False))\n",
    "\n",
    "# MAE\n",
    "print('MAE', mean_absolute_error(y_true, y_pred))\n",
    "\n",
    "# MAPE\n",
    "print('MAPE', mean_absolute_percentage_error(y_true, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "caf796d3-c575-461a-92d7-14e7b477866b",
   "metadata": {},
   "source": [
    "## Model selection\n",
    "\n",
    "Model R2 and RMSE always become better when adding more variables, but that is not alway get better model. Need to use metric to assessing \"add more variable effection\" or use all variable possible is better ?\n",
    "\n",
    "Method to find all model possible with large dataset is stepwise regression: start at full model and drop the variables that dont contribute meanningfully\n",
    "\n",
    "- `adjusted R-square`\n",
    "- $\\mathrm{AIC}=2P+n\\log(\\mathrm{RSS}/n)$\n",
    "    - `AICc` is suitable for small dataset\n",
    "    - `BIC` is Stronger penalty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9938c48-aadc-4210-a5db-596cde2ba43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
