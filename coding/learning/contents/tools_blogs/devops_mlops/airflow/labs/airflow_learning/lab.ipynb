{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airflow Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\datkt\\Desktop\\Working\\00_My Notebooks\\coding\\learning\\contents\\tools\\devops_mlops\\airflow\\labs\\airflow_learning\n"
     ]
    }
   ],
   "source": [
    "%cd contents\\tools\\devops_mlops\\airflow\\labs\\airflow_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1: Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write python constraint.txt (requirements.txt for specific python and airflow version)\n",
    "\n",
    "get constraint file with format:\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/apache/airflow/constraints-<airflow version>/constraints-<python version>.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://raw.githubusercontent.com/apache/airflow/constraints-2.0.2/constraints-3.8.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- entrypoint.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing entrypoint.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile entrypoint.sh\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "# Initiliase the metastore\n",
    "airflow db init\n",
    "\n",
    "# Run the scheduler in background\n",
    "airflow scheduler &> /dev/null &\n",
    "\n",
    "# Create user\n",
    "airflow users create -u admin -p admin -r Admin -e admin@admin.com -f admin -l admin\n",
    "\n",
    "# Run the web server in foreground (for docker logs)\n",
    "exec airflow webserver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "# Base Image\n",
    "FROM python:3.8-slim\n",
    "LABEL maintainer=\"MarcLamberti\"\n",
    "\n",
    "# Arguments that can be set with docker build\n",
    "ARG AIRFLOW_VERSION=2.0.2\n",
    "ARG AIRFLOW_HOME=/opt/airflow\n",
    "\n",
    "# Export the environment variable AIRFLOW_HOME where airflow will be installed\n",
    "ENV AIRFLOW_HOME=${AIRFLOW_HOME}\n",
    "\n",
    "# Install dependencies and tools\n",
    "RUN apt-get update -yqq && \\\n",
    "    apt-get upgrade -yqq && \\\n",
    "    apt-get install -yqq --no-install-recommends \\ \n",
    "    wget \\\n",
    "    libczmq-dev \\\n",
    "    curl \\\n",
    "    libssl-dev \\\n",
    "    git \\\n",
    "    inetutils-telnet \\\n",
    "    bind9utils freetds-dev \\\n",
    "    libkrb5-dev \\\n",
    "    libsasl2-dev \\\n",
    "    libffi-dev libpq-dev \\\n",
    "    freetds-bin build-essential \\\n",
    "    default-libmysqlclient-dev \\\n",
    "    apt-utils \\\n",
    "    rsync \\\n",
    "    zip \\\n",
    "    unzip \\\n",
    "    gcc \\\n",
    "    vim \\\n",
    "    locales \\\n",
    "    && apt-get clean\n",
    "\n",
    "COPY ./constraints-3.8.txt /constraints-3.8.txt\n",
    "\n",
    "# Upgrade pip\n",
    "# Create airflow user \n",
    "# Install apache airflow with subpackages\n",
    "RUN pip install --upgrade pip && \\\n",
    "    useradd -ms /bin/bash -d ${AIRFLOW_HOME} airflow && \\\n",
    "    pip install apache-airflow[postgres]==${AIRFLOW_VERSION} --constraint /constraints-3.8.txt\n",
    "\n",
    "# Copy the entrypoint.sh from host to container (at path AIRFLOW_HOME)\n",
    "COPY ./entrypoint.sh ./entrypoint.sh\n",
    "\n",
    "# Set the entrypoint.sh file to be executable\n",
    "RUN chmod +x ./entrypoint.sh\n",
    "\n",
    "# Set the owner of the files in AIRFLOW_HOME to the user airflow\n",
    "RUN chown -R airflow: ${AIRFLOW_HOME}\n",
    "\n",
    "# Set the username to use\n",
    "USER airflow\n",
    "\n",
    "# Set workdir (it's like a cd inside the container)\n",
    "WORKDIR ${AIRFLOW_HOME}\n",
    "\n",
    "# Create the dags folder which will contain the DAGs\n",
    "RUN mkdir dags\n",
    "\n",
    "# Expose ports (just to indicate that this container needs to map port)\n",
    "EXPOSE 8080\n",
    "\n",
    "# Execute the entrypoint.sh\n",
    "ENTRYPOINT [ \".\\entrypoint.sh\" ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build a docker image from the Dockerfile in the current directory (airflow-materials/airflow-basic)  and name it airflow-basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "docker build -t airflow-basic .\n",
    "docker run --rm -d -p 8080:8080 airflow-basic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
